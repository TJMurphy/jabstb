# One-way ANOVA Completely Randomized {#onewayanova}

```{r echo=TRUE, message=FALSE, warning=FALSE}
library(magrittr)
library(tidyverse)
library(ggformula)
library(DescTools)
library(ez)
library(lsr)
```

You probably should read about the [ANOVA big picture](\#introanova)).

## Using `ezANOVA`

R has several functions to run ANOVA. We are mostly going to use `ezANOVA` from the `ez` package in this course. The syntax for defining the ANOVA analysis is a bit more clear in `ez`, especially if we are new to ANOVA.

This chapter runs through an analysis of a one-way completely randomized ANOVA data set as 'how to' example.

## The chickwt data set 

This data set is in R's base. It compares the influence of 6 different types of food sources on chick weight. We have one predictor variable, the factor 'feed', which is tested at 6 different levels (the various food sources). 

There is one continuous outcome variable (weight). We assume the chicks are out bred, and thus not intrinsically-related, and that they have been randomly assigned to a level of feed, and have been weighed after a period of time consuming that feed. 

This is a classic one-way completely randomized ANOVA design. 

This chapter illustrates how to go through an analysis of the data.

### Inspect the data

The next few scripts involve inspecting the data set, which should always be done prior to running any statistical tests.

```{r}
data(chickwts)
#take a look at the data structure, depending upon how you like to view data
str(chickwts)
chickwts
```

It is also helpful to calculate some descriptive stats for inspection. Since the design is obviously about testing the different levels of feed, use the `group_by` function of tidyverse to summarize by feed level. The `kable` function from `knitr` makes a nicer output.

```{r}
cw1 <- chickwts %>%
  group_by(feed) %>%
  summarise(
    mean= mean(weight),
    median=median(weight),
    sd= sd(weight),
    n = n(),
    var=var(weight)
    )
knitr::kable(cw1, caption="Descriptive statistics for the chickwts dataset.")
```

We can see that the means and medians are about equal within each group. That's a quick way to suggest no skew. Overall sample size is 71, distributed as 10-14 replicates per group, it's a little unbalanced. But within acceptable limits. The variances are not equivalent, but are they unequal? Levene's test in the ANOVA will provide that answer. But this is a pretty small sample size. Whatever that output we will take it with salt.

Plot the data for a look. Simply looking at the data graphically goes a long way to ensuring this is a one-way ANOVA design. Jitter plots are a great way to see group data like this. I like the `crossbar` geom to overlay some summary stats.

```{r}
ggplot(chickwts, aes(feed, weight))+
  geom_jitter(width = 0.2, size=2) +
  stat_summary(fun.data = mean_sdl, 
               fun.args = list(mult=1), 
               geom="crossbar", 
               width=0.2, 
               color="red"
               ) + 
  theme_classic()

```

## Run the ANOVA

We can imagine designing an experiment like this with either of 3 experimental objectives in mind.

1) Perhaps we're interested mostly in whether any feeds are better than others for achieving weight gain? We could answer that by making all possible pairwise comparisons. Since there are 6 levels of the factor feed, that would involve $m=\frac{6(6-1)}{2}=15$ comparisons.

2) Imagine casein is the standard feed, and we wish to know if any of the other feeds differ from this standard? We would compare casein to every feed. That would involve only 5 comparisons.

3) Perhaps we just want to know if any of the feeds differ in causing weight gain, but we aren't interested in which specific feeds differ? We could answer that question using the F-test result, and not comparing any groups post hoc.

Each of those objectives are scientifically-driven. They should be declared *before* running an experiment so that an unbiased analysis is conducted *after* the data are in. 

Other than, perhaps, how we order our data in the data set, which of these objectives is true doesn't influence how we run the `ezANOVA` function per se. However, the objective will influence which post hoc analysis is performed.

### Run the chickwts One Way ANOVA

First, ezANOVA requires a 'wid', which is a unique ID variable for each independent replicate. 

We need to add one to the chickwts data set. Since all the measures are independent, we'll just do that by row number. At the same time we'll convert the integer to a factor so ezANOVA won't bark at us. 

```{r}
chickwts$ID <- as.factor(1:nrow(chickwts))
```

You should look at R's help for ezANOVA `?ezANOVA` to understand these test arguments. The help page is pretty clear for most of these. 

Since we don't use the term 'dependent variable' much in this course, to be clear, 'dv' is the outcome response variable..the dependent variable. We have to specify it in the `ezANOVA` arguments.

If measurements for levels of the factor are not intrinsically-linked, if they are distributed to each replicate independently, the design is completely randomized. That factor should be listed in the function using a `between` argument.

If measurements for levels of the factor are intrinsically-linked, it is a related/repeated measures design. List it as a 'within' argument, rather than 'between'. 

Here, the `feed` factor is `between`. Every chick was randomly assigned a level of feed.

Notice that `ezANOVA` is a function. Use it to create a list object called `my.ezaov`, which has all of the output information. We can call all of the output at once, or we can call specific elements from the `my.ezaov` object to see the results.

```{r paged.print=FALSE}
my.ezaov <- ezANOVA(
            data = chickwts, 
            wid = ID, 
            dv = weight, 
            between = feed,
            type = 2, 
            return_aov = T, 
            detailed = T)
my.ezaov

# my.ezaov$ANOVA, this is a dataframe
# my.ezaov$Levene, this is also a dataframe
# my.ezaov$aov, this is an aov object that we can pass into posthoc functions. 
```

### Interpreting the One-Way CR ANOVA Output

The ezANOVA output prints 3 list objects by default:

* $ANOVA (which is the first data frame)
* $`Levene's Test for Homogeneity of Variance` (which is the 2nd data frame)
* $aov (which is the end of the console output and is an important statistical object)

In fact, there is a great deal more computed that is not printed, which you can visualize in the console by typing `str(my.ezaov)`.

#### $ANOVA: The ANOVA table

For a CR one way ANOVA design, the SS are partitioned as follows, in general: $SS_{total}=SS_{model}+SS_{residual}$. 

In this example, $SS_{model}= SS_{feed}$.

Thus, the ANOVA table summarizes the feed model.

The DFn = 5 corresponds to the 6 groups, less 1 degree of freedom (one is lost to calculate mean of groups (sort of)) for the model source of variance.

The DFn = 65 corresponds to the degrees of freedom for the residuals (one df is lost per group to calculate group means). 

Therefore, this ANOVA tests a feed model against a null F distribution with 5 and 65 degrees of freedom.

$F=MS_{feed}/MS_{residual}=15.3648$, where $MS = SS/df$. The SS can be found in the $aov output.

* ges = [generalized eta-squared](https://link.springer.com/article/10.3758/BF03192707). 

`ges` is an effect size parameter for ANOVA. For this particular experimental design, $ges=\frac{SS_n}{SS_n+SS_d}$. In other words, `ges` summarizes the variation associated with the model as a fraction of the total variation in the data. 

Thus, 54.16% of the variation in weight is attributable to the different levels of feed in the experiment. In other words, the model explains 54.16% of the variation in the data.

Think of eta-squared, partial eta-squared, and generalized eta-squared as all related to the more commonly understood $R^2$, the so-called coefficient of regression. They are each calculated differently, but are related as estimates for how much of the variation is due to the model. `ges` takes on values from 0 to 1. Higher values indicate a greater degree of the overall variation is due to the factor tested in the experiment.

Having said that, it's a bit of a Goldilocks statistics by itself. It has more value as a way to describe fits of nested models.

#### $aov

This table is an important object because it can be passed into certain posthoc tests, facilitating analysis.

It provides the accounting for the sum of squares and degrees of freedom, while calculating the residual standard error. It is somewhat redundant with the $ANOVA table, though the residual standard error can come in handy.

* DFn=degrees freedom for numerator. k-1, where k = levels of factor.
* DFd=degrees freedom for denominator. n-k, where n = number of independent replicates.
* SSn & SSd = sum of squares for model and residual, respectively
* Residual standard error is a parameter that estimates the precision by which the data fit the model, and is in units of the outcome variable, weight. $SE$ is the square root of the residual variance: $S_{y.x}=\sqrt{\frac{SS_{residual}}{df_{residual}}}$

If $S_{y.x}$ were zero, there would be no residuals. The data points would all rest at the value of the group means. The data would fit perfectly to a model of 6 group means at their observed values. $S_{y.x}$ therefore is a descriptive statistic that declares how much error, or the degree by which the data is unexplained by the model. It has some utility for calculating confidence intervals and power analysis as well.

#### The F test

The scientific prediction for this experiment is that chick weights will vary depending upon the type of feed they are grown on. The null is that their weights will be roughly the same, irrespective of food source.

ANOVA tests this hypothesis through the variance parameter. The question at hand is whether the variance associated with the model, one of 6 different feed group means, is fractionally greater than the residual variance in the sample.

The null statistical hypothesis is that the variance associated with the different levels of feed is less than or equal to the residual variance. Therefore, the alternate hypothesis is the variance associated with feed is greater than residual variance.

$H_0: MS_{feed}\le MS_{residual}$, $H_1: MS_{feed}>MS_{residual}$

Because of the relationship of group means to variance, it is just as valid to express the null hypothesis in terms of the group means, and that can be proven mathematically by a competent statistician (of which I am not):

$H_0: \mu_a=\mu_b=\mu_c=\mu_d=\mu_e=\mu_f$ 

Though, strictly, rejecting the null doesn't mean that all group means differ from each other, it just means that some of them differ. $H_1: \mu_a\ne\mu_b\ne\mu_c\ne\mu_d\ne\mu_e\ne\mu_f$

The F statistic of 15.3648 is extreme for a null F distribution of 5 and 65 degrees of freedom. The very low p-value illustrates this extremeness. 

We can reject the null and conclude that differences in effect on chick weights exist between this group of feeds.

#### Levene's test for homogeneity of variance

Levene's test determines whether there is a substantial level of differences in variance *between* groups. Levene's test is run as a check to determine if the groups variance is homogeneous, as homoskedasticity is one of the validity assumptions of ANOVA.

Levene's test statistic is calculated as follows:

\[W=\frac{(n-k)}{(k-1)}\frac{\sum\limits_{i=1}^{k}n_i(\bar Z_i-\bar Z)^2}{\sum\limits_{i=1}^{k}\sum\limits_{j=1}^{n_i}(Z_{ij}-\bar Z_i)^2}\]

where $Z_{ij}=|x_{ij}-\bar x_i|$ and $Z_i$ are the group means and $\bar Z$ is the overall mean of $Z_{ij}$. 

The null hypothesis of the Levene test is rejected when $W>F_{(\alpha,\ k-1,\ n-k)}$, where the F is the critical value.

Levene's test output is a 2nd ANOVA table, and can easily be confused with the ANOVA output. Levene's test lacks a $ges$ parameter, nor does it have a column that lists the factor name.

If the Levene's F value is low and the p-values is high, as is the case here, we can't reject the null that the variances are the same. In this way, the variance homogeneity assumption is validated.

If this were not the case, we have two options. 

Option 1: Simply ignore the result. The luck of the draw with small samples can explain group differences in variance, where none really exists. It is hard to gauge the impact of any one violation on our inference. It may be very modest or it may be substantial. With data in hand, it is too late to come up with an on-the-fly solution if not specified in the planning stages. 

Option 2:  Transform the data to homogenize outliers and variance, or switch the analysis to a Kruskal-Wallis nonparametric test. 

## Post hoc pairwise comparisons

When the ANOVA F test for the factor is extreme we may be interested in knowing which treatments differ. That's achieved by conducting post hoc analysis. These typically involves multiple group comparisons.

There are two fundamental options for CR posthoc testing: p-value adjustment or a range test. Each are illustrated below, but only one method should be conducted in real life. That method is chosen in advance during the planning stages.

For the adjusted p-value method, use the `pairwise.t.test` function set up a matrix of all possible group comparisons. The Bonferroni p-value adjustment procedure is selected for best possible control of type1 error. This may miss some true differences.

For each comparison we are testing the null hypothesis that the two group means are the same: \[H_0: \bar y_i = \bar y_j\]

```{r}
allPairs <- pairwise.t.test(chickwts$weight, chickwts$feed, paired=FALSE, alternative="two.sided", pooled.sd=TRUE, p.adjust= "bonf")
allPairs
```

To quickly scan which comparisons are below the p < 0.05 threshold we apply a simple custom `extreme` function across the matrix:

```{r}
extreme <- function(x){
  ifelse(x < 0.05, TRUE, FALSE)
}

apply(allPairs$p.value, c(1, 2), extreme)
```

With the Bonferroni correction we are able to reject 8 of the 15 null hypotheses. For each comparison corresponding to a value of TRUE we can reject the null and conclude that their means are not equivalent.

**Adjusting p-values for subsets of comparisons**

Often, we don't want to burn so much type1 error making scientifically uninteresting comparisons. In such cases, we instead want to compare subsets. For example, perhaps all we wanted to do was compare each of the feeds to casein.

Here's a three step procedure for doing just that. 

Step1: First, run the `pairwise.t.test` function, setting the argument `p.adjust="none"`. The output includes a matrix of p-values we'll name `allPairsn`, providing all possible comparisons.

```{r}
#just repeating from above
allPairsn <- pairwise.t.test(chickwts$weight, chickwts$feed, p.adjust= "none")
```

Step2: Select from the `allPairs` matrix only the p-values that correspond to the comparisons you'd like to make. Name that vector of unadjusted p-values, `selectPairs`. This takes a bit of cleverness depending on what you want to grab from the matrix.

For example, we only want to compare all of the diets to casein. The comparisons we want are all in the first column. Use your matrix indexing skillz to grab only the unadjusted p-values from that first column:

```{r}
selectPairsn <- allPairsn$p.value[, 1]
selectPairsn
selectPairsn < 0.05
```

Step3: Now pass these unadjusted p-values in the `selectPairs` vector into the `p.adjust` function.

The output of this step is a vector of adjusted p-values for the selected group of comparisons.

```{r}
adjustedPvalues <- p.adjust(selectPairsn, method="bonferroni")
adjustedPvalues
```

Which of these are extreme? If it's not clear by inspection (or too large), use a simple Boolean: 

```{r}
adjustedPvalues < 0.05
```

Although the p-values differ in this selected group compared to the full matrix, the inference remains the same. We can conclude that chick weights on horsebean, linseed and soybean feeds differ from that on casein feed.

### Range tests

One way completely randomized ANOVAs, as opposed to related measures ANOVA, lend themselves well to range tests because the questions revolve around the differences between group means.

In these designs we are frequently interested in a comparison back to a control value. These are referred to as dependent comparisons, because every comparison is back to the same group mean.  Dunnett's test was created for exactly this type of situation.

Let's imagine the researcher is interested in knowing if any of the feeds cause difference in chick weights compared to the casein feed.  

```{r}
DunnettTest(weight ~ feed, control="casein", data = chickwts)
```

Note how the R method is to subtract the casein control from the test groups. We can reject the null that chick weight on casein is the same as on horsebean, linseed and soybean. There is no evidence that chick weight differs on meatmeal and sunflower compared to casein.

## Reporting the result

If you have CI's, flaunt them.

When using Dunnett's there is no need to report both the 95% CI and the p-value, since they effectively show the same thing (any adjusted p-value above 0.05 will also have a 95% CI that includes the value of zero). We use either for inference.

__"Chick weights differ on feed type (one-way completely randomized ANOVA, F(5, 65)=15.36, p=5.9e-10). Specifically, posthoc Dunnett's test show group mean chick weights differ between casein compared to horsebean (-163, adjusted 95%CI -223 to -102), linseed(-104, adjusted 95%CI -162 to -42), and soybean (-77,adjusted 95%CI -132 to -21)"__



