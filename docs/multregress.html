<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 38 Multiple regression | JABSTB: Statistical Design and Analysis of Experiments with R</title>
  <meta name="description" content="Experimental biostatistics using R.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 38 Multiple regression | JABSTB: Statistical Design and Analysis of Experiments with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Experimental biostatistics using R." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 38 Multiple regression | JABSTB: Statistical Design and Analysis of Experiments with R" />
  
  <meta name="twitter:description" content="Experimental biostatistics using R." />
  

<meta name="author" content="TJ Murphy PhD, Department of Pharmacology and Chemical Biology, School of Medicine, Emory University, Atlanta, GA biostats538@gmail.com">


<meta name="date" content="2019-04-09">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="nonlinearreplicates.html">
<link rel="next" href="logregress.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">JABSTB</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="author.html"><a href="author.html"><i class="fa fa-check"></i><b>1</b> About the author</a></li>
<li class="chapter" data-level="2" data-path="history.html"><a href="history.html"><i class="fa fa-check"></i><b>2</b> A Brief History of Experimental Design</a></li>
<li class="chapter" data-level="3" data-path="software.html"><a href="software.html"><i class="fa fa-check"></i><b>3</b> Software</a><ul>
<li class="chapter" data-level="3.1" data-path="software.html"><a href="software.html#my-code-is-your-code"><i class="fa fa-check"></i><b>3.1</b> My code is your code</a></li>
<li class="chapter" data-level="3.2" data-path="software.html"><a href="software.html#install-r-and-rstudio"><i class="fa fa-check"></i><b>3.2</b> Install R and RStudio</a></li>
<li class="chapter" data-level="3.3" data-path="software.html"><a href="software.html#getting-started-with-r"><i class="fa fa-check"></i><b>3.3</b> Getting started with R</a></li>
<li class="chapter" data-level="3.4" data-path="software.html"><a href="software.html#other-resources"><i class="fa fa-check"></i><b>3.4</b> Other resources</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="bigpic.html"><a href="bigpic.html"><i class="fa fa-check"></i><b>4</b> The Big Picture</a><ul>
<li class="chapter" data-level="4.1" data-path="bigpic.html"><a href="bigpic.html#what-are-experimental-statistics"><i class="fa fa-check"></i><b>4.1</b> What are experimental statistics?</a><ul>
<li class="chapter" data-level="4.1.1" data-path="bigpic.html"><a href="bigpic.html#descriptive-modeling"><i class="fa fa-check"></i><b>4.1.1</b> Descriptive modeling</a></li>
<li class="chapter" data-level="4.1.2" data-path="bigpic.html"><a href="bigpic.html#statistical-inference"><i class="fa fa-check"></i><b>4.1.2</b> Statistical inference</a></li>
<li class="chapter" data-level="4.1.3" data-path="bigpic.html"><a href="bigpic.html#experimental-design"><i class="fa fa-check"></i><b>4.1.3</b> Experimental design</a></li>
<li class="chapter" data-level="4.1.4" data-path="bigpic.html"><a href="bigpic.html#statistics-as-an-anti-bias-framework"><i class="fa fa-check"></i><b>4.1.4</b> Statistics as an anti-bias framework</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="sampling.html"><a href="sampling.html"><i class="fa fa-check"></i><b>5</b> Statistical Sampling</a><ul>
<li class="chapter" data-level="5.1" data-path="sampling.html"><a href="sampling.html#experimental-units"><i class="fa fa-check"></i><b>5.1</b> Experimental units</a><ul>
<li class="chapter" data-level="5.1.1" data-path="sampling.html"><a href="sampling.html#a-simple-test-to-define-the-experimental-unit"><i class="fa fa-check"></i><b>5.1.1</b> A simple test to define the experimental unit</a></li>
<li class="chapter" data-level="5.1.2" data-path="sampling.html"><a href="sampling.html#blocking"><i class="fa fa-check"></i><b>5.1.2</b> Blocking</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="sampling.html"><a href="sampling.html#independent-replicates"><i class="fa fa-check"></i><b>5.2</b> Independent Replicates</a><ul>
<li class="chapter" data-level="5.2.1" data-path="sampling.html"><a href="sampling.html#a-simple-test-for-independence"><i class="fa fa-check"></i><b>5.2.1</b> A simple test for independence</a></li>
<li class="chapter" data-level="5.2.2" data-path="sampling.html"><a href="sampling.html#some-replication-examples"><i class="fa fa-check"></i><b>5.2.2</b> Some replication examples</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="sampling.html"><a href="sampling.html#random-process"><i class="fa fa-check"></i><b>5.3</b> Random process</a></li>
<li class="chapter" data-level="5.4" data-path="sampling.html"><a href="sampling.html#statistically-valid-samples"><i class="fa fa-check"></i><b>5.4</b> Statistically valid samples</a><ul>
<li class="chapter" data-level="5.4.1" data-path="sampling.html"><a href="sampling.html#select-random-subjects"><i class="fa fa-check"></i><b>5.4.1</b> Select random subjects</a></li>
<li class="chapter" data-level="5.4.2" data-path="sampling.html"><a href="sampling.html#randomize-to-sequence"><i class="fa fa-check"></i><b>5.4.2</b> Randomize to sequence</a></li>
<li class="chapter" data-level="5.4.3" data-path="sampling.html"><a href="sampling.html#randomize-to-location"><i class="fa fa-check"></i><b>5.4.3</b> Randomize to location</a></li>
<li class="chapter" data-level="5.4.4" data-path="sampling.html"><a href="sampling.html#randomize-to-block"><i class="fa fa-check"></i><b>5.4.4</b> Randomize to block</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="sampling.html"><a href="sampling.html#independence-of-replicates"><i class="fa fa-check"></i><b>5.5</b> Independence of replicates</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>6</b> Data Classification</a><ul>
<li class="chapter" data-level="6.1" data-path="data.html"><a href="data.html#dependent-and-independent-variables"><i class="fa fa-check"></i><b>6.1</b> Dependent and independent variables</a><ul>
<li class="chapter" data-level="6.1.1" data-path="data.html"><a href="data.html#when-there-is-no-independent-variable"><i class="fa fa-check"></i><b>6.1.1</b> When there is no independent variable</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="data.html"><a href="data.html#discrete-or-continuous-variables"><i class="fa fa-check"></i><b>6.2</b> Discrete or continuous variables</a><ul>
<li class="chapter" data-level="6.2.1" data-path="data.html"><a href="data.html#measured-variables"><i class="fa fa-check"></i><b>6.2.1</b> Measured variables</a></li>
<li class="chapter" data-level="6.2.2" data-path="data.html"><a href="data.html#discrete-categorical-and-ordinal-variables"><i class="fa fa-check"></i><b>6.2.2</b> Discrete categorical and ordinal variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="dispersion.html"><a href="dispersion.html"><i class="fa fa-check"></i><b>7</b> Variability, Accuracy and Precision</a><ul>
<li class="chapter" data-level="7.1" data-path="dispersion.html"><a href="dispersion.html#variance-quantifying-variation-by-least-squares"><i class="fa fa-check"></i><b>7.1</b> Variance: Quantifying variation by least squares</a></li>
<li class="chapter" data-level="7.2" data-path="dispersion.html"><a href="dispersion.html#standard-deviation"><i class="fa fa-check"></i><b>7.2</b> Standard deviation</a><ul>
<li class="chapter" data-level="7.2.1" data-path="dispersion.html"><a href="dispersion.html#what-does-the-standard-deviation-tell-us"><i class="fa fa-check"></i><b>7.2.1</b> What does the standard deviation tell us</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="dispersion.html"><a href="dispersion.html#other-ways-of-describing-variability"><i class="fa fa-check"></i><b>7.3</b> Other ways of describing variability</a></li>
<li class="chapter" data-level="7.4" data-path="dispersion.html"><a href="dispersion.html#precision-and-accuracy"><i class="fa fa-check"></i><b>7.4</b> Precision and Accuracy</a></li>
<li class="chapter" data-level="7.5" data-path="dispersion.html"><a href="dispersion.html#standard-error"><i class="fa fa-check"></i><b>7.5</b> Standard error</a><ul>
<li class="chapter" data-level="7.5.1" data-path="dispersion.html"><a href="dispersion.html#what-exactly-does-the-standard-error-represent"><i class="fa fa-check"></i><b>7.5.1</b> What exactly does the standard error represent?</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="dispersion.html"><a href="dispersion.html#confidence-intervals"><i class="fa fa-check"></i><b>7.6</b> Confidence intervals</a><ul>
<li class="chapter" data-level="7.6.1" data-path="dispersion.html"><a href="dispersion.html#simulations"><i class="fa fa-check"></i><b>7.6.1</b> Simulations</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="dispersion.html"><a href="dispersion.html#key-take-aways"><i class="fa fa-check"></i><b>7.7</b> Key take aways</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="hypotheses.html"><a href="hypotheses.html"><i class="fa fa-check"></i><b>8</b> Framing statistical hypotheses</a><ul>
<li class="chapter" data-level="8.1" data-path="hypotheses.html"><a href="hypotheses.html#the-decision-process"><i class="fa fa-check"></i><b>8.1</b> The decision process</a></li>
<li class="chapter" data-level="8.2" data-path="hypotheses.html"><a href="hypotheses.html#popper-and-falsification"><i class="fa fa-check"></i><b>8.2</b> Popper and falsification</a></li>
<li class="chapter" data-level="8.3" data-path="hypotheses.html"><a href="hypotheses.html#statistical-hypothesis-rubric"><i class="fa fa-check"></i><b>8.3</b> Statistical hypothesis rubric</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="error.html"><a href="error.html"><i class="fa fa-check"></i><b>9</b> Error</a><ul>
<li class="chapter" data-level="9.1" data-path="error.html"><a href="error.html#setting-type-1-and-type-2-error-thresholds"><i class="fa fa-check"></i><b>9.1</b> Setting type 1 and type 2 error thresholds</a><ul>
<li class="chapter" data-level="9.1.1" data-path="error.html"><a href="error.html#setting-alpha-the-type-1-error"><i class="fa fa-check"></i><b>9.1.1</b> Setting alpha-the type 1 error</a></li>
<li class="chapter" data-level="9.1.2" data-path="error.html"><a href="error.html#power-setting-beta-the-type-2-error"><i class="fa fa-check"></i><b>9.1.2</b> Power: Setting beta-the type 2 error</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="error.html"><a href="error.html#striking-the-right-balance"><i class="fa fa-check"></i><b>9.2</b> Striking the right balance</a></li>
<li class="chapter" data-level="9.3" data-path="error.html"><a href="error.html#false-discovery-rate"><i class="fa fa-check"></i><b>9.3</b> False discovery rate</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="pvalues.html"><a href="pvalues.html"><i class="fa fa-check"></i><b>10</b> P Values</a><ul>
<li class="chapter" data-level="10.1" data-path="pvalues.html"><a href="pvalues.html#how-p-values-are-calculated"><i class="fa fa-check"></i><b>10.1</b> How p-values are calculated</a></li>
<li class="chapter" data-level="10.2" data-path="pvalues.html"><a href="pvalues.html#how-p-values-should-be-interpreted"><i class="fa fa-check"></i><b>10.2</b> How p-values should be interpreted</a></li>
<li class="chapter" data-level="10.3" data-path="pvalues.html"><a href="pvalues.html#interpretation"><i class="fa fa-check"></i><b>10.3</b> Interpretation</a></li>
<li class="chapter" data-level="10.4" data-path="pvalues.html"><a href="pvalues.html#criticisms-of-p-values"><i class="fa fa-check"></i><b>10.4</b> Criticisms of p-values</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="jaxwest7.html"><a href="jaxwest7.html"><i class="fa fa-check"></i><b>11</b> Reproducible Data Munging in R</a><ul>
<li class="chapter" data-level="11.1" data-path="jaxwest7.html"><a href="jaxwest7.html#jaxwest7-glucose-data"><i class="fa fa-check"></i><b>11.1</b> Jaxwest7 glucose data</a><ul>
<li class="chapter" data-level="11.1.1" data-path="jaxwest7.html"><a href="jaxwest7.html#inspect-the-jaxwest7-data"><i class="fa fa-check"></i><b>11.1.1</b> Inspect the Jaxwest7 data</a></li>
<li class="chapter" data-level="11.1.2" data-path="jaxwest7.html"><a href="jaxwest7.html#munge-the-glucose-concentration-data-into-r"><i class="fa fa-check"></i><b>11.1.2</b> Munge the glucose concentration data into R</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="jaxwest7.html"><a href="jaxwest7.html#explore-the-jaxwest7-data"><i class="fa fa-check"></i><b>11.2</b> Explore the Jaxwest7 data</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="binomial.html"><a href="binomial.html"><i class="fa fa-check"></i><b>12</b> The Binomial Distribution</a><ul>
<li class="chapter" data-level="12.1" data-path="binomial.html"><a href="binomial.html#dbinom"><i class="fa fa-check"></i><b>12.1</b> dbinom</a></li>
<li class="chapter" data-level="12.2" data-path="binomial.html"><a href="binomial.html#pbinom"><i class="fa fa-check"></i><b>12.2</b> pbinom</a></li>
<li class="chapter" data-level="12.3" data-path="binomial.html"><a href="binomial.html#qbinom"><i class="fa fa-check"></i><b>12.3</b> qbinom</a></li>
<li class="chapter" data-level="12.4" data-path="binomial.html"><a href="binomial.html#rbinom"><i class="fa fa-check"></i><b>12.4</b> rbinom</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="poisson.html"><a href="poisson.html"><i class="fa fa-check"></i><b>13</b> The Poisson Distribution</a><ul>
<li class="chapter" data-level="13.1" data-path="poisson.html"><a href="poisson.html#poisson-events"><i class="fa fa-check"></i><b>13.1</b> Poisson Events</a></li>
<li class="chapter" data-level="13.2" data-path="poisson.html"><a href="poisson.html#dpois"><i class="fa fa-check"></i><b>13.2</b> dpois</a></li>
<li class="chapter" data-level="13.3" data-path="poisson.html"><a href="poisson.html#ppois"><i class="fa fa-check"></i><b>13.3</b> ppois</a></li>
<li class="chapter" data-level="13.4" data-path="poisson.html"><a href="poisson.html#rpois"><i class="fa fa-check"></i><b>13.4</b> rpois</a></li>
<li class="chapter" data-level="13.5" data-path="poisson.html"><a href="poisson.html#overdispersion"><i class="fa fa-check"></i><b>13.5</b> Overdispersion</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="normal.html"><a href="normal.html"><i class="fa fa-check"></i><b>14</b> The Normal Distribution</a><ul>
<li class="chapter" data-level="14.0.1" data-path="normal.html"><a href="normal.html#the-standard-normal"><i class="fa fa-check"></i><b>14.0.1</b> The Standard Normal</a></li>
<li class="chapter" data-level="14.1" data-path="normal.html"><a href="normal.html#dnorm"><i class="fa fa-check"></i><b>14.1</b> dnorm</a></li>
<li class="chapter" data-level="14.2" data-path="normal.html"><a href="normal.html#pnorm"><i class="fa fa-check"></i><b>14.2</b> pnorm</a><ul>
<li class="chapter" data-level="" data-path="normal.html"><a href="normal.html#calculating-p-values-using-pnorm"><i class="fa fa-check"></i>Calculating “p-values”&quot; using pnorm</a></li>
<li class="chapter" data-level="" data-path="normal.html"><a href="normal.html#calculating-percentiles-using-pnorm"><i class="fa fa-check"></i>Calculating percentiles using pnorm</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="normal.html"><a href="normal.html#qnorm"><i class="fa fa-check"></i><b>14.3</b> qnorm</a></li>
<li class="chapter" data-level="14.4" data-path="normal.html"><a href="normal.html#rnorm"><i class="fa fa-check"></i><b>14.4</b> rnorm</a><ul>
<li class="chapter" data-level="14.4.1" data-path="normal.html"><a href="normal.html#plotting-histograms-of-some-rnorm-samples"><i class="fa fa-check"></i><b>14.4.1</b> Plotting histograms of some rnorm samples</a></li>
<li class="chapter" data-level="14.4.2" data-path="normal.html"><a href="normal.html#bins-and-binwidth"><i class="fa fa-check"></i><b>14.4.2</b> Bins and Binwidth</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="categorical.html"><a href="categorical.html"><i class="fa fa-check"></i><b>15</b> Statistics for Categorical Data</a><ul>
<li class="chapter" data-level="15.1" data-path="categorical.html"><a href="categorical.html#types-of-categorical-data"><i class="fa fa-check"></i><b>15.1</b> Types of categorical data</a><ul>
<li class="chapter" data-level="15.1.1" data-path="categorical.html"><a href="categorical.html#proportions"><i class="fa fa-check"></i><b>15.1.1</b> Proportions</a></li>
<li class="chapter" data-level="15.1.2" data-path="categorical.html"><a href="categorical.html#frequencies"><i class="fa fa-check"></i><b>15.1.2</b> Frequencies</a></li>
<li class="chapter" data-level="15.1.3" data-path="categorical.html"><a href="categorical.html#associations"><i class="fa fa-check"></i><b>15.1.3</b> Associations</a></li>
<li class="chapter" data-level="15.1.4" data-path="categorical.html"><a href="categorical.html#statistics-covered-here"><i class="fa fa-check"></i><b>15.1.4</b> Statistics Covered Here</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="categorical.html"><a href="categorical.html#exact-v-asymptotic-calculations-of-p-values"><i class="fa fa-check"></i><b>15.2</b> Exact v Asymptotic Calculations of p-values</a><ul>
<li class="chapter" data-level="15.2.1" data-path="categorical.html"><a href="categorical.html#choosing-exact-or-asymptotic"><i class="fa fa-check"></i><b>15.2.1</b> Choosing exact or asymptotic</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="categorical.html"><a href="categorical.html#overview-of-the-types-of-hypothesis-testing"><i class="fa fa-check"></i><b>15.3</b> Overview of the types of hypothesis testing</a><ul>
<li class="chapter" data-level="15.3.1" data-path="categorical.html"><a href="categorical.html#proportion-analysis"><i class="fa fa-check"></i><b>15.3.1</b> Proportion analysis</a></li>
<li class="chapter" data-level="15.3.2" data-path="categorical.html"><a href="categorical.html#goodness-of-fit-testing"><i class="fa fa-check"></i><b>15.3.2</b> Goodness of fit testing</a></li>
<li class="chapter" data-level="15.3.3" data-path="categorical.html"><a href="categorical.html#contingency-analysis"><i class="fa fa-check"></i><b>15.3.3</b> Contingency Analysis</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="categorical.html"><a href="categorical.html#comparing-proportions"><i class="fa fa-check"></i><b>15.4</b> Comparing proportions</a><ul>
<li class="chapter" data-level="15.4.1" data-path="categorical.html"><a href="categorical.html#a-mouse-t-cell-pilot-experiment-the-cytokine-inducible-antigen-gradstudin"><i class="fa fa-check"></i><b>15.4.1</b> A Mouse T Cell Pilot Experiment: The Cytokine-inducible antigen gradstudin</a></li>
<li class="chapter" data-level="15.4.2" data-path="categorical.html"><a href="categorical.html#calculating-proportions"><i class="fa fa-check"></i><b>15.4.2</b> Calculating Proportions</a></li>
<li class="chapter" data-level="15.4.3" data-path="categorical.html"><a href="categorical.html#what-a-proportion-estimates"><i class="fa fa-check"></i><b>15.4.3</b> What A Proportion Estimates</a></li>
<li class="chapter" data-level="15.4.4" data-path="categorical.html"><a href="categorical.html#confidence-intervals-of-proportions"><i class="fa fa-check"></i><b>15.4.4</b> Confidence Intervals of Proportions</a></li>
<li class="chapter" data-level="15.4.5" data-path="categorical.html"><a href="categorical.html#a-one-sample-proportion-test"><i class="fa fa-check"></i><b>15.4.5</b> A One-Sample Proportion Test</a></li>
<li class="chapter" data-level="15.4.6" data-path="categorical.html"><a href="categorical.html#comparing-two-proportions"><i class="fa fa-check"></i><b>15.4.6</b> Comparing Two Proportions</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="categorical.html"><a href="categorical.html#exact-tests-for-two-proportions"><i class="fa fa-check"></i><b>15.5</b> Exact tests for two proportions</a></li>
<li class="chapter" data-level="15.6" data-path="categorical.html"><a href="categorical.html#goodness-of-fit-tests"><i class="fa fa-check"></i><b>15.6</b> Goodness of fit Tests</a><ul>
<li class="chapter" data-level="15.6.1" data-path="categorical.html"><a href="categorical.html#an-exact-goodness-of-fit-test"><i class="fa fa-check"></i><b>15.6.1</b> An Exact Goodness of Fit test</a></li>
<li class="chapter" data-level="15.6.2" data-path="categorical.html"><a href="categorical.html#an-approximate-goodness-of-fit-test"><i class="fa fa-check"></i><b>15.6.2</b> An Approximate Goodness of Fit test</a></li>
</ul></li>
<li class="chapter" data-level="15.7" data-path="categorical.html"><a href="categorical.html#contingency-testing"><i class="fa fa-check"></i><b>15.7</b> Contingency Testing</a><ul>
<li class="chapter" data-level="15.7.1" data-path="categorical.html"><a href="categorical.html#intepretation-of-contingency-results"><i class="fa fa-check"></i><b>15.7.1</b> Intepretation of Contingency Results</a></li>
<li class="chapter" data-level="15.7.2" data-path="categorical.html"><a href="categorical.html#write-up-3"><i class="fa fa-check"></i><b>15.7.2</b> Write Up</a></li>
<li class="chapter" data-level="15.7.3" data-path="categorical.html"><a href="categorical.html#interpretation-of-chi-square-output"><i class="fa fa-check"></i><b>15.7.3</b> Interpretation of chi-square output</a></li>
<li class="chapter" data-level="15.7.4" data-path="categorical.html"><a href="categorical.html#write-up-4"><i class="fa fa-check"></i><b>15.7.4</b> Write Up</a></li>
<li class="chapter" data-level="15.7.5" data-path="categorical.html"><a href="categorical.html#which-contingency-test-is-best"><i class="fa fa-check"></i><b>15.7.5</b> Which contingency test is best?</a></li>
<li class="chapter" data-level="15.7.6" data-path="categorical.html"><a href="categorical.html#higher-dimension-contingency-analysis"><i class="fa fa-check"></i><b>15.7.6</b> Higher dimension contingency analysis</a></li>
<li class="chapter" data-level="15.7.7" data-path="categorical.html"><a href="categorical.html#other-experimental-designs-involving-categorical-data"><i class="fa fa-check"></i><b>15.7.7</b> Other experimental designs involving categorical data</a></li>
</ul></li>
<li class="chapter" data-level="15.8" data-path="categorical.html"><a href="categorical.html#doing-a-priori-power-analysis-for-proportion-tests"><i class="fa fa-check"></i><b>15.8</b> Doing <em>a priori</em> power analysis for proportion tests</a></li>
<li class="chapter" data-level="15.9" data-path="categorical.html"><a href="categorical.html#power-analysis-functions-for-proportion-tests"><i class="fa fa-check"></i><b>15.9</b> Power analysis functions for proportion tests</a></li>
<li class="chapter" data-level="15.10" data-path="categorical.html"><a href="categorical.html#graphing-proportions"><i class="fa fa-check"></i><b>15.10</b> Graphing Proportions</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="chisquare.html"><a href="chisquare.html"><i class="fa fa-check"></i><b>16</b> The Chi-square Distribution</a><ul>
<li class="chapter" data-level="16.1" data-path="chisquare.html"><a href="chisquare.html#background"><i class="fa fa-check"></i><b>16.1</b> Background</a></li>
<li class="chapter" data-level="16.2" data-path="chisquare.html"><a href="chisquare.html#dchisq"><i class="fa fa-check"></i><b>16.2</b> dchisq</a></li>
<li class="chapter" data-level="16.3" data-path="chisquare.html"><a href="chisquare.html#pchisq"><i class="fa fa-check"></i><b>16.3</b> pchisq</a><ul>
<li class="chapter" data-level="16.3.1" data-path="chisquare.html"><a href="chisquare.html#calculating-p-values-from-pchisq"><i class="fa fa-check"></i><b>16.3.1</b> Calculating p-values from pchisq</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="chisquare.html"><a href="chisquare.html#qchisq"><i class="fa fa-check"></i><b>16.4</b> qchisq</a></li>
<li class="chapter" data-level="16.5" data-path="chisquare.html"><a href="chisquare.html#rchisq"><i class="fa fa-check"></i><b>16.5</b> rchisq</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="nonparametrics.html"><a href="nonparametrics.html"><i class="fa fa-check"></i><b>17</b> Nonparametric Statistical Tests</a><ul>
<li class="chapter" data-level="17.1" data-path="nonparametrics.html"><a href="nonparametrics.html#experiments-involving-discrete-data"><i class="fa fa-check"></i><b>17.1</b> Experiments involving discrete data</a></li>
<li class="chapter" data-level="17.2" data-path="nonparametrics.html"><a href="nonparametrics.html#deviant-data"><i class="fa fa-check"></i><b>17.2</b> Deviant Data</a></li>
<li class="chapter" data-level="17.3" data-path="nonparametrics.html"><a href="nonparametrics.html#sign-test"><i class="fa fa-check"></i><b>17.3</b> Sign Test</a><ul>
<li class="chapter" data-level="17.3.1" data-path="nonparametrics.html"><a href="nonparametrics.html#interpretation-1"><i class="fa fa-check"></i><b>17.3.1</b> Interpretation</a></li>
<li class="chapter" data-level="17.3.2" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-5"><i class="fa fa-check"></i><b>17.3.2</b> Write Up</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="nonparametrics.html"><a href="nonparametrics.html#wilcoxon-sign-rank-test-for-one-group"><i class="fa fa-check"></i><b>17.4</b> Wilcoxon Sign Rank Test for One Group</a><ul>
<li class="chapter" data-level="17.4.1" data-path="nonparametrics.html"><a href="nonparametrics.html#wilcoxon-sign-rank-experimental-designs"><i class="fa fa-check"></i><b>17.4.1</b> Wilcoxon Sign Rank Experimental Designs</a></li>
<li class="chapter" data-level="17.4.2" data-path="nonparametrics.html"><a href="nonparametrics.html#interpretation-2"><i class="fa fa-check"></i><b>17.4.2</b> Interpretation</a></li>
<li class="chapter" data-level="17.4.3" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-6"><i class="fa fa-check"></i><b>17.4.3</b> Write Up</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="nonparametrics.html"><a href="nonparametrics.html#wilcoxon-mann-whitney-rank-sum-test-for-2-independent-groups"><i class="fa fa-check"></i><b>17.5</b> Wilcoxon Mann Whitney Rank Sum Test for 2 independent groups</a><ul>
<li class="chapter" data-level="17.5.1" data-path="nonparametrics.html"><a href="nonparametrics.html#interpretation-3"><i class="fa fa-check"></i><b>17.5.1</b> Interpretation</a></li>
<li class="chapter" data-level="17.5.2" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-7"><i class="fa fa-check"></i><b>17.5.2</b> Write Up</a></li>
</ul></li>
<li class="chapter" data-level="17.6" data-path="nonparametrics.html"><a href="nonparametrics.html#wilcoxon-sign-rank-test-for-paired-groups"><i class="fa fa-check"></i><b>17.6</b> Wilcoxon Sign Rank Test for paired groups</a><ul>
<li class="chapter" data-level="17.6.1" data-path="nonparametrics.html"><a href="nonparametrics.html#interpretation-4"><i class="fa fa-check"></i><b>17.6.1</b> Interpretation</a></li>
<li class="chapter" data-level="17.6.2" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-8"><i class="fa fa-check"></i><b>17.6.2</b> Write up</a></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="nonparametrics.html"><a href="nonparametrics.html#kruskal-wallis"><i class="fa fa-check"></i><b>17.7</b> Kruskal-Wallis</a><ul>
<li class="chapter" data-level="17.7.1" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-9"><i class="fa fa-check"></i><b>17.7.1</b> Write Up</a></li>
</ul></li>
<li class="chapter" data-level="17.8" data-path="nonparametrics.html"><a href="nonparametrics.html#friedman-test"><i class="fa fa-check"></i><b>17.8</b> Friedman test</a></li>
<li class="chapter" data-level="17.9" data-path="nonparametrics.html"><a href="nonparametrics.html#nonparametric-power-calculations"><i class="fa fa-check"></i><b>17.9</b> Nonparametric power calculations</a><ul>
<li class="chapter" data-level="17.9.1" data-path="nonparametrics.html"><a href="nonparametrics.html#how-it-works"><i class="fa fa-check"></i><b>17.9.1</b> How it works</a></li>
<li class="chapter" data-level="17.9.2" data-path="nonparametrics.html"><a href="nonparametrics.html#initialization-with-population-parameters"><i class="fa fa-check"></i><b>17.9.2</b> Initialization with population parameters</a></li>
<li class="chapter" data-level="17.9.3" data-path="nonparametrics.html"><a href="nonparametrics.html#an-example"><i class="fa fa-check"></i><b>17.9.3</b> An example</a></li>
<li class="chapter" data-level="17.9.4" data-path="nonparametrics.html"><a href="nonparametrics.html#nonpara.pwr"><i class="fa fa-check"></i><b>17.9.4</b> nonpara.pwr</a></li>
</ul></li>
<li class="chapter" data-level="17.10" data-path="nonparametrics.html"><a href="nonparametrics.html#summary"><i class="fa fa-check"></i><b>17.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="signrank.html"><a href="signrank.html"><i class="fa fa-check"></i><b>18</b> Signed Rank Distribution</a><ul>
<li class="chapter" data-level="18.1" data-path="signrank.html"><a href="signrank.html#transformation-of-data-into-sign-ranks"><i class="fa fa-check"></i><b>18.1</b> Transformation of data into sign ranks</a><ul>
<li class="chapter" data-level="18.1.1" data-path="signrank.html"><a href="signrank.html#for-a-one-group-sample"><i class="fa fa-check"></i><b>18.1.1</b> For a one group sample</a></li>
<li class="chapter" data-level="18.1.2" data-path="signrank.html"><a href="signrank.html#for-a-paired-sample"><i class="fa fa-check"></i><b>18.1.2</b> For a paired sample</a></li>
<li class="chapter" data-level="18.1.3" data-path="signrank.html"><a href="signrank.html#the-sign-rank-test-statistic-in-r"><i class="fa fa-check"></i><b>18.1.3</b> The sign rank test statistic in R</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="signrank.html"><a href="signrank.html#rs-four-sign-rank-distribution-functions"><i class="fa fa-check"></i><b>18.2</b> R’s Four Sign Rank Distribution Functions</a><ul>
<li class="chapter" data-level="18.2.1" data-path="signrank.html"><a href="signrank.html#dsignrank"><i class="fa fa-check"></i><b>18.2.1</b> dsignrank</a></li>
<li class="chapter" data-level="18.2.2" data-path="signrank.html"><a href="signrank.html#psignrank"><i class="fa fa-check"></i><b>18.2.2</b> psignrank</a></li>
<li class="chapter" data-level="18.2.3" data-path="signrank.html"><a href="signrank.html#qsignrank"><i class="fa fa-check"></i><b>18.2.3</b> qsignrank</a></li>
<li class="chapter" data-level="18.2.4" data-path="signrank.html"><a href="signrank.html#rsignrank"><i class="fa fa-check"></i><b>18.2.4</b> rsignrank</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="ranksum.html"><a href="ranksum.html"><i class="fa fa-check"></i><b>19</b> Rank Sum Distribution</a><ul>
<li class="chapter" data-level="19.0.1" data-path="ranksum.html"><a href="ranksum.html#transformation-of-data-into-rank-summs"><i class="fa fa-check"></i><b>19.0.1</b> Transformation of data into rank summs</a></li>
<li class="chapter" data-level="19.0.2" data-path="ranksum.html"><a href="ranksum.html#the-sign-rank-test-statistic-in-r-1"><i class="fa fa-check"></i><b>19.0.2</b> The sign rank test statistic in R</a></li>
<li class="chapter" data-level="19.1" data-path="ranksum.html"><a href="ranksum.html#rs-four-sign-rank-distribution-functions-1"><i class="fa fa-check"></i><b>19.1</b> R’s Four Sign Rank Distribution Functions</a><ul>
<li class="chapter" data-level="19.1.1" data-path="ranksum.html"><a href="ranksum.html#dwilcox"><i class="fa fa-check"></i><b>19.1.1</b> dwilcox</a></li>
<li class="chapter" data-level="19.1.2" data-path="ranksum.html"><a href="ranksum.html#pwilcox"><i class="fa fa-check"></i><b>19.1.2</b> pwilcox</a></li>
<li class="chapter" data-level="19.1.3" data-path="ranksum.html"><a href="ranksum.html#qwilcox"><i class="fa fa-check"></i><b>19.1.3</b> qwilcox</a></li>
<li class="chapter" data-level="19.1.4" data-path="ranksum.html"><a href="ranksum.html#rwilcox"><i class="fa fa-check"></i><b>19.1.4</b> rwilcox</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="ttests.html"><a href="ttests.html"><i class="fa fa-check"></i><b>20</b> The t-tests</a><ul>
<li class="chapter" data-level="20.1" data-path="ttests.html"><a href="ttests.html#data-assumptions-for-t-tests"><i class="fa fa-check"></i><b>20.1</b> Data assumptions for t-tests</a></li>
<li class="chapter" data-level="20.2" data-path="ttests.html"><a href="ttests.html#the-t-statistic"><i class="fa fa-check"></i><b>20.2</b> The t Statistic</a><ul>
<li class="chapter" data-level="20.2.1" data-path="ttests.html"><a href="ttests.html#one-sample-t-tests"><i class="fa fa-check"></i><b>20.2.1</b> One sample t tests</a></li>
<li class="chapter" data-level="20.2.2" data-path="ttests.html"><a href="ttests.html#unpaired-t-tests"><i class="fa fa-check"></i><b>20.2.2</b> Unpaired t tests</a></li>
<li class="chapter" data-level="20.2.3" data-path="ttests.html"><a href="ttests.html#paired-t-tests"><i class="fa fa-check"></i><b>20.2.3</b> Paired t tests</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="ttests.html"><a href="ttests.html#t-test-hypotheses"><i class="fa fa-check"></i><b>20.3</b> t Test Hypotheses</a><ul>
<li class="chapter" data-level="20.3.1" data-path="ttests.html"><a href="ttests.html#one-sample-hypotheses"><i class="fa fa-check"></i><b>20.3.1</b> One sample hypotheses</a></li>
<li class="chapter" data-level="20.3.2" data-path="ttests.html"><a href="ttests.html#unpaired-hypotheses"><i class="fa fa-check"></i><b>20.3.2</b> Unpaired hypotheses</a></li>
<li class="chapter" data-level="20.3.3" data-path="ttests.html"><a href="ttests.html#paired-hypotheses"><i class="fa fa-check"></i><b>20.3.3</b> Paired hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="ttests.html"><a href="ttests.html#confidence-intervals-of-means"><i class="fa fa-check"></i><b>20.4</b> Confidence Intervals of Means</a></li>
<li class="chapter" data-level="20.5" data-path="ttests.html"><a href="ttests.html#t-tests-running-the-analysis"><i class="fa fa-check"></i><b>20.5</b> t Tests: Running the analysis</a><ul>
<li class="chapter" data-level="20.5.1" data-path="ttests.html"><a href="ttests.html#one-sample-t-test"><i class="fa fa-check"></i><b>20.5.1</b> One sample t test</a></li>
<li class="chapter" data-level="20.5.2" data-path="ttests.html"><a href="ttests.html#unpaired-t-test"><i class="fa fa-check"></i><b>20.5.2</b> Unpaired t test</a></li>
<li class="chapter" data-level="20.5.3" data-path="ttests.html"><a href="ttests.html#paired-t-test"><i class="fa fa-check"></i><b>20.5.3</b> Paired t Test</a></li>
</ul></li>
<li class="chapter" data-level="20.6" data-path="ttests.html"><a href="ttests.html#plotting-t-tests"><i class="fa fa-check"></i><b>20.6</b> Plotting t Tests</a><ul>
<li class="chapter" data-level="20.6.1" data-path="ttests.html"><a href="ttests.html#unpaired"><i class="fa fa-check"></i><b>20.6.1</b> Unpaired</a></li>
<li class="chapter" data-level="20.6.2" data-path="ttests.html"><a href="ttests.html#paired"><i class="fa fa-check"></i><b>20.6.2</b> Paired</a></li>
</ul></li>
<li class="chapter" data-level="20.7" data-path="ttests.html"><a href="ttests.html#t-test-power"><i class="fa fa-check"></i><b>20.7</b> t Test Power</a><ul>
<li class="chapter" data-level="20.7.1" data-path="ttests.html"><a href="ttests.html#interpretation-7"><i class="fa fa-check"></i><b>20.7.1</b> Interpretation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="ttestmc.html"><a href="ttestmc.html"><i class="fa fa-check"></i><b>21</b> Statistical design of t-tests</a><ul>
<li class="chapter" data-level="21.1" data-path="ttestmc.html"><a href="ttestmc.html#about-this-chapter"><i class="fa fa-check"></i><b>21.1</b> About this chapter</a><ul>
<li class="chapter" data-level="21.1.1" data-path="ttestmc.html"><a href="ttestmc.html#scenario"><i class="fa fa-check"></i><b>21.1.1</b> Scenario</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="ttestmc.html"><a href="ttestmc.html#one-sample-t-test-monte-carlo"><i class="fa fa-check"></i><b>21.2</b> One sample t-test Monte Carlo</a></li>
<li class="chapter" data-level="21.3" data-path="ttestmc.html"><a href="ttestmc.html#unpaired-t-test-monte-carlo"><i class="fa fa-check"></i><b>21.3</b> Unpaired t-test Monte Carlo</a></li>
<li class="chapter" data-level="21.4" data-path="ttestmc.html"><a href="ttestmc.html#paired-t-test-monte-carlo"><i class="fa fa-check"></i><b>21.4</b> Paired t-test Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="tdist.html"><a href="tdist.html"><i class="fa fa-check"></i><b>22</b> t Distributions</a><ul>
<li class="chapter" data-level="22.1" data-path="tdist.html"><a href="tdist.html#dt"><i class="fa fa-check"></i><b>22.1</b> dt</a></li>
<li class="chapter" data-level="22.2" data-path="tdist.html"><a href="tdist.html#pt"><i class="fa fa-check"></i><b>22.2</b> pt</a></li>
<li class="chapter" data-level="22.3" data-path="tdist.html"><a href="tdist.html#qt"><i class="fa fa-check"></i><b>22.3</b> qt</a></li>
<li class="chapter" data-level="22.4" data-path="tdist.html"><a href="tdist.html#rt"><i class="fa fa-check"></i><b>22.4</b> rt</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="simcorrelation.html"><a href="simcorrelation.html"><i class="fa fa-check"></i><b>23</b> Simulating correlated variables</a><ul>
<li class="chapter" data-level="23.1" data-path="simcorrelation.html"><a href="simcorrelation.html#estimating-correlation-between-two-variables"><i class="fa fa-check"></i><b>23.1</b> Estimating correlation between two variables</a></li>
<li class="chapter" data-level="23.2" data-path="simcorrelation.html"><a href="simcorrelation.html#simulating-correlated-variables"><i class="fa fa-check"></i><b>23.2</b> Simulating correlated variables</a></li>
<li class="chapter" data-level="23.3" data-path="simcorrelation.html"><a href="simcorrelation.html#monte-carlo-simulation"><i class="fa fa-check"></i><b>23.3</b> Monte Carlo simulation</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="introanova.html"><a href="introanova.html"><i class="fa fa-check"></i><b>24</b> Introduction to ANOVA</a><ul>
<li class="chapter" data-level="24.1" data-path="introanova.html"><a href="introanova.html#factors-and-levels"><i class="fa fa-check"></i><b>24.1</b> Factors and levels</a></li>
<li class="chapter" data-level="24.2" data-path="introanova.html"><a href="introanova.html#anova-models-one--two--and-three-way"><i class="fa fa-check"></i><b>24.2</b> ANOVA models: One-, Two-, and Three-way</a></li>
<li class="chapter" data-level="24.3" data-path="introanova.html"><a href="introanova.html#anova-inference-protocol"><i class="fa fa-check"></i><b>24.3</b> ANOVA inference protocol</a></li>
<li class="chapter" data-level="24.4" data-path="introanova.html"><a href="introanova.html#anova-calculations"><i class="fa fa-check"></i><b>24.4</b> ANOVA calculations</a><ul>
<li class="chapter" data-level="24.4.1" data-path="introanova.html"><a href="introanova.html#sums-of-squares-partitioning"><i class="fa fa-check"></i><b>24.4.1</b> Sums of Squares partitioning</a></li>
<li class="chapter" data-level="24.4.2" data-path="introanova.html"><a href="introanova.html#degrees-of-freedom"><i class="fa fa-check"></i><b>24.4.2</b> Degrees of freedom</a></li>
<li class="chapter" data-level="24.4.3" data-path="introanova.html"><a href="introanova.html#the-mean-squares"><i class="fa fa-check"></i><b>24.4.3</b> The mean squares</a></li>
<li class="chapter" data-level="24.4.4" data-path="introanova.html"><a href="introanova.html#the-anova-table"><i class="fa fa-check"></i><b>24.4.4</b> The ANOVA table</a></li>
<li class="chapter" data-level="24.4.5" data-path="introanova.html"><a href="introanova.html#the-f-test"><i class="fa fa-check"></i><b>24.4.5</b> The F-test</a></li>
<li class="chapter" data-level="24.4.6" data-path="introanova.html"><a href="introanova.html#post-hoc-group-comparisons"><i class="fa fa-check"></i><b>24.4.6</b> Post-hoc group comparisons</a></li>
</ul></li>
<li class="chapter" data-level="24.5" data-path="introanova.html"><a href="introanova.html#completely-randomized-or-related-measures"><i class="fa fa-check"></i><b>24.5</b> Completely randomized or related measures</a><ul>
<li class="chapter" data-level="24.5.1" data-path="introanova.html"><a href="introanova.html#the-problem-of-lost-data-in-related-measures-designs"><i class="fa fa-check"></i><b>24.5.1</b> The problem of lost data in related measures designs</a></li>
</ul></li>
<li class="chapter" data-level="24.6" data-path="introanova.html"><a href="introanova.html#two-way-anova"><i class="fa fa-check"></i><b>24.6</b> Two-way ANOVA</a></li>
<li class="chapter" data-level="24.7" data-path="introanova.html"><a href="introanova.html#other-anova-models"><i class="fa fa-check"></i><b>24.7</b> Other ANOVA models</a><ul>
<li class="chapter" data-level="24.7.1" data-path="introanova.html"><a href="introanova.html#r-and-anova"><i class="fa fa-check"></i><b>24.7.1</b> R and ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="24.8" data-path="introanova.html"><a href="introanova.html#alternatives-to-anova"><i class="fa fa-check"></i><b>24.8</b> Alternatives to ANOVA</a><ul>
<li class="chapter" data-level="24.8.1" data-path="introanova.html"><a href="introanova.html#screw-anova-just-tell-me-how-to-t-test-everything"><i class="fa fa-check"></i><b>24.8.1</b> Screw ANOVA, Just Tell Me How to t-Test Everything</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="fdistr.html"><a href="fdistr.html"><i class="fa fa-check"></i><b>25</b> The F distribution</a><ul>
<li class="chapter" data-level="25.1" data-path="fdistr.html"><a href="fdistr.html#background-1"><i class="fa fa-check"></i><b>25.1</b> Background</a><ul>
<li class="chapter" data-level="25.1.1" data-path="fdistr.html"><a href="fdistr.html#sample-variance-and-fs-pdf"><i class="fa fa-check"></i><b>25.1.1</b> Sample Variance and F’s PDF</a></li>
</ul></li>
<li class="chapter" data-level="25.2" data-path="fdistr.html"><a href="fdistr.html#df"><i class="fa fa-check"></i><b>25.2</b> df</a></li>
<li class="chapter" data-level="25.3" data-path="fdistr.html"><a href="fdistr.html#pf"><i class="fa fa-check"></i><b>25.3</b> pf</a></li>
<li class="chapter" data-level="25.4" data-path="fdistr.html"><a href="fdistr.html#qf"><i class="fa fa-check"></i><b>25.4</b> qf</a></li>
<li class="chapter" data-level="25.5" data-path="fdistr.html"><a href="fdistr.html#rf"><i class="fa fa-check"></i><b>25.5</b> rf</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="onewayanova.html"><a href="onewayanova.html"><i class="fa fa-check"></i><b>26</b> One-way ANOVA Completely Randomized</a><ul>
<li class="chapter" data-level="26.1" data-path="onewayanova.html"><a href="onewayanova.html#using-ezanova"><i class="fa fa-check"></i><b>26.1</b> Using <code>ezANOVA</code></a></li>
<li class="chapter" data-level="26.2" data-path="onewayanova.html"><a href="onewayanova.html#the-chickwt-data-set"><i class="fa fa-check"></i><b>26.2</b> The chickwt data set</a><ul>
<li class="chapter" data-level="26.2.1" data-path="onewayanova.html"><a href="onewayanova.html#inspect-the-data"><i class="fa fa-check"></i><b>26.2.1</b> Inspect the data</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="onewayanova.html"><a href="onewayanova.html#run-the-anova"><i class="fa fa-check"></i><b>26.3</b> Run the ANOVA</a><ul>
<li class="chapter" data-level="26.3.1" data-path="onewayanova.html"><a href="onewayanova.html#run-the-chickwts-one-way-anova"><i class="fa fa-check"></i><b>26.3.1</b> Run the chickwts One Way ANOVA</a></li>
<li class="chapter" data-level="26.3.2" data-path="onewayanova.html"><a href="onewayanova.html#interpreting-the-one-way-cr-anova-output"><i class="fa fa-check"></i><b>26.3.2</b> Interpreting the One-Way CR ANOVA Output</a></li>
</ul></li>
<li class="chapter" data-level="26.4" data-path="onewayanova.html"><a href="onewayanova.html#posthoc"><i class="fa fa-check"></i><b>26.4</b> Post hoc pairwise comparisons</a><ul>
<li class="chapter" data-level="26.4.1" data-path="onewayanova.html"><a href="onewayanova.html#overview-of-options"><i class="fa fa-check"></i><b>26.4.1</b> Overview of options</a></li>
</ul></li>
<li class="chapter" data-level="26.5" data-path="onewayanova.html"><a href="onewayanova.html#reporting-the-result"><i class="fa fa-check"></i><b>26.5</b> Reporting the result</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="onewayRM.html"><a href="onewayRM.html"><i class="fa fa-check"></i><b>27</b> One-way ANOVA Related Measures</a><ul>
<li class="chapter" data-level="27.1" data-path="onewayRM.html"><a href="onewayRM.html#data-prep"><i class="fa fa-check"></i><b>27.1</b> Data prep</a></li>
<li class="chapter" data-level="27.2" data-path="onewayRM.html"><a href="onewayRM.html#run-the-anova-1"><i class="fa fa-check"></i><b>27.2</b> Run the ANOVA</a></li>
<li class="chapter" data-level="27.3" data-path="onewayRM.html"><a href="onewayRM.html#interpretation-8"><i class="fa fa-check"></i><b>27.3</b> Interpretation</a></li>
<li class="chapter" data-level="27.4" data-path="onewayRM.html"><a href="onewayRM.html#post-hoc-analysis"><i class="fa fa-check"></i><b>27.4</b> Post-hoc analysis</a></li>
<li class="chapter" data-level="27.5" data-path="onewayRM.html"><a href="onewayRM.html#write-up-10"><i class="fa fa-check"></i><b>27.5</b> Write up</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="twowayCR.html"><a href="twowayCR.html"><i class="fa fa-check"></i><b>28</b> Two-way ANOVA Completely Randomized</a><ul>
<li class="chapter" data-level="28.1" data-path="twowayCR.html"><a href="twowayCR.html#effect-of-strain-and-diet-on-liver"><i class="fa fa-check"></i><b>28.1</b> Effect of Strain and Diet on Liver</a></li>
<li class="chapter" data-level="28.2" data-path="twowayCR.html"><a href="twowayCR.html#the-test"><i class="fa fa-check"></i><b>28.2</b> The test</a></li>
<li class="chapter" data-level="28.3" data-path="twowayCR.html"><a href="twowayCR.html#interpretation-of-2-way-cr-anova-output"><i class="fa fa-check"></i><b>28.3</b> Interpretation of 2 Way CR ANOVA Output</a><ul>
<li class="chapter" data-level="28.3.1" data-path="twowayCR.html"><a href="twowayCR.html#levenes"><i class="fa fa-check"></i><b>28.3.1</b> Levene’s</a></li>
<li class="chapter" data-level="28.3.2" data-path="twowayCR.html"><a href="twowayCR.html#anova-table"><i class="fa fa-check"></i><b>28.3.2</b> ANOVA Table</a></li>
</ul></li>
<li class="chapter" data-level="28.4" data-path="twowayCR.html"><a href="twowayCR.html#post-hoc-multiple-comparisons"><i class="fa fa-check"></i><b>28.4</b> Post Hoc Multiple Comparisons</a><ul>
<li class="chapter" data-level="28.4.1" data-path="twowayCR.html"><a href="twowayCR.html#write-up-11"><i class="fa fa-check"></i><b>28.4.1</b> Write Up</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path="twowayRM.html"><a href="twowayRM.html"><i class="fa fa-check"></i><b>29</b> Two-way ANOVA Related Measures</a><ul>
<li class="chapter" data-level="29.1" data-path="twowayRM.html"><a href="twowayRM.html#cell-culture"><i class="fa fa-check"></i><b>29.1</b> Cell culture</a></li>
<li class="chapter" data-level="29.2" data-path="twowayRM.html"><a href="twowayRM.html#the-test-1"><i class="fa fa-check"></i><b>29.2</b> The test</a></li>
<li class="chapter" data-level="29.3" data-path="twowayRM.html"><a href="twowayRM.html#interpretation-of-the-output"><i class="fa fa-check"></i><b>29.3</b> Interpretation of the output</a><ul>
<li class="chapter" data-level="29.3.1" data-path="twowayRM.html"><a href="twowayRM.html#anova-table-1"><i class="fa fa-check"></i><b>29.3.1</b> ANOVA Table</a></li>
<li class="chapter" data-level="29.3.2" data-path="twowayRM.html"><a href="twowayRM.html#mauchlys-sphericity-test"><i class="fa fa-check"></i><b>29.3.2</b> Mauchly’s Sphericity Test</a></li>
</ul></li>
<li class="chapter" data-level="29.4" data-path="twowayRM.html"><a href="twowayRM.html#post-hoc-multiple-comparisons-1"><i class="fa fa-check"></i><b>29.4</b> Post Hoc multiple comparisons</a></li>
<li class="chapter" data-level="29.5" data-path="twowayRM.html"><a href="twowayRM.html#write-up-12"><i class="fa fa-check"></i><b>29.5</b> Write Up</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="twowaymixed.html"><a href="twowaymixed.html"><i class="fa fa-check"></i><b>30</b> Two-way ANOVA RM/CR</a><ul>
<li class="chapter" data-level="30.1" data-path="twowaymixed.html"><a href="twowaymixed.html#chickweight-dataset"><i class="fa fa-check"></i><b>30.1</b> ChickWeight Dataset</a></li>
<li class="chapter" data-level="30.2" data-path="twowaymixed.html"><a href="twowaymixed.html#munge-chickweight-data"><i class="fa fa-check"></i><b>30.2</b> Munge ChickWeight data</a></li>
<li class="chapter" data-level="30.3" data-path="twowaymixed.html"><a href="twowaymixed.html#the-test-2"><i class="fa fa-check"></i><b>30.3</b> The test</a></li>
<li class="chapter" data-level="30.4" data-path="twowaymixed.html"><a href="twowaymixed.html#interpreting-the-anova-output"><i class="fa fa-check"></i><b>30.4</b> Interpreting the ANOVA output</a><ul>
<li class="chapter" data-level="30.4.1" data-path="twowaymixed.html"><a href="twowaymixed.html#anova-the-anova-table-1"><i class="fa fa-check"></i><b>30.4.1</b> $ANOVA: The ANOVA table</a></li>
<li class="chapter" data-level="30.4.2" data-path="twowaymixed.html"><a href="twowaymixed.html#mauchlys-test-and-corrections"><i class="fa fa-check"></i><b>30.4.2</b> Mauchly’s Test and Corrections</a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path="twowaymixed.html"><a href="twowaymixed.html#post-hoc-pairwise-tests"><i class="fa fa-check"></i><b>30.5</b> Post hoc pairwise tests</a><ul>
<li class="chapter" data-level="30.5.1" data-path="twowaymixed.html"><a href="twowaymixed.html#heres-whats-been-discovered"><i class="fa fa-check"></i><b>30.5.1</b> Here’s what’s been discovered</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="31" data-path="jaxwest2.html"><a href="jaxwest2.html"><i class="fa fa-check"></i><b>31</b> Reproducible Data Munging Mostly with Tidyverse</a><ul>
<li class="chapter" data-level="31.1" data-path="jaxwest2.html"><a href="jaxwest2.html#look-at-the-original-data-carefully"><i class="fa fa-check"></i><b>31.1</b> Look at the original data carefully</a></li>
<li class="chapter" data-level="31.2" data-path="jaxwest2.html"><a href="jaxwest2.html#our-goal"><i class="fa fa-check"></i><b>31.2</b> Our goal</a></li>
<li class="chapter" data-level="31.3" data-path="jaxwest2.html"><a href="jaxwest2.html#read-the-data-into-r"><i class="fa fa-check"></i><b>31.3</b> Read the data into R</a></li>
<li class="chapter" data-level="31.4" data-path="jaxwest2.html"><a href="jaxwest2.html#select-the-variables"><i class="fa fa-check"></i><b>31.4</b> Select the variables</a></li>
<li class="chapter" data-level="31.5" data-path="jaxwest2.html"><a href="jaxwest2.html#trim-the-cases"><i class="fa fa-check"></i><b>31.5</b> Trim the cases</a></li>
<li class="chapter" data-level="31.6" data-path="jaxwest2.html"><a href="jaxwest2.html#go-long"><i class="fa fa-check"></i><b>31.6</b> Go long</a></li>
<li class="chapter" data-level="31.7" data-path="jaxwest2.html"><a href="jaxwest2.html#pull-out-the-values-for-the-day-variable"><i class="fa fa-check"></i><b>31.7</b> Pull out the values for the day variable</a></li>
<li class="chapter" data-level="31.8" data-path="jaxwest2.html"><a href="jaxwest2.html#convert-day-to-numeric"><i class="fa fa-check"></i><b>31.8</b> Convert day to numeric</a></li>
<li class="chapter" data-level="31.9" data-path="jaxwest2.html"><a href="jaxwest2.html#convert-tumor_vol-to-numeric"><i class="fa fa-check"></i><b>31.9</b> Convert tumor_vol to numeric</a></li>
<li class="chapter" data-level="31.10" data-path="jaxwest2.html"><a href="jaxwest2.html#deal-with-that-na"><i class="fa fa-check"></i><b>31.10</b> Deal with that NA</a></li>
<li class="chapter" data-level="31.11" data-path="jaxwest2.html"><a href="jaxwest2.html#convert-variables-to-factor"><i class="fa fa-check"></i><b>31.11</b> Convert variables to factor</a></li>
<li class="chapter" data-level="31.12" data-path="jaxwest2.html"><a href="jaxwest2.html#plot-the-data"><i class="fa fa-check"></i><b>31.12</b> Plot the data</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="anovamc.html"><a href="anovamc.html"><i class="fa fa-check"></i><b>32</b> ANOVA power using Monte Carlo</a><ul>
<li class="chapter" data-level="32.1" data-path="anovamc.html"><a href="anovamc.html#alternatives-to-monte-carlo"><i class="fa fa-check"></i><b>32.1</b> Alternatives to Monte Carlo</a></li>
<li class="chapter" data-level="32.2" data-path="anovamc.html"><a href="anovamc.html#what-is-monte-carlo"><i class="fa fa-check"></i><b>32.2</b> What is Monte Carlo</a></li>
<li class="chapter" data-level="32.3" data-path="anovamc.html"><a href="anovamc.html#one-way-completely-randomized-anova-monte-carlo"><i class="fa fa-check"></i><b>32.3</b> One-way completely randomized ANOVA Monte Carlo</a><ul>
<li class="chapter" data-level="32.3.1" data-path="anovamc.html"><a href="anovamc.html#directions"><i class="fa fa-check"></i><b>32.3.1</b> Directions</a></li>
<li class="chapter" data-level="32.3.2" data-path="anovamc.html"><a href="anovamc.html#step-1-create-initial-values"><i class="fa fa-check"></i><b>32.3.2</b> Step 1: Create initial values</a></li>
<li class="chapter" data-level="32.3.3" data-path="anovamc.html"><a href="anovamc.html#step-2-visualize-one-random-sample"><i class="fa fa-check"></i><b>32.3.3</b> Step 2: Visualize one random sample</a></li>
<li class="chapter" data-level="32.3.4" data-path="anovamc.html"><a href="anovamc.html#step-3-run-the-power-simulator"><i class="fa fa-check"></i><b>32.3.4</b> Step 3: Run The Power Simulator</a></li>
<li class="chapter" data-level="32.3.5" data-path="anovamc.html"><a href="anovamc.html#step-4-optimize-for-suitable-power"><i class="fa fa-check"></i><b>32.3.5</b> Step 4: Optimize for suitable power</a></li>
<li class="chapter" data-level="32.3.6" data-path="anovamc.html"><a href="anovamc.html#notes-and-considerations"><i class="fa fa-check"></i><b>32.3.6</b> Notes And Considerations</a></li>
</ul></li>
<li class="chapter" data-level="32.4" data-path="anovamc.html"><a href="anovamc.html#one-way-related-measures-anova-monte-carlo"><i class="fa fa-check"></i><b>32.4</b> One-way related measures ANOVA Monte Carlo</a></li>
<li class="chapter" data-level="32.5" data-path="anovamc.html"><a href="anovamc.html#directions-1"><i class="fa fa-check"></i><b>32.5</b> Directions</a><ul>
<li class="chapter" data-level="32.5.1" data-path="anovamc.html"><a href="anovamc.html#step-1-initial-values"><i class="fa fa-check"></i><b>32.5.1</b> Step 1: Initial values</a></li>
<li class="chapter" data-level="32.5.2" data-path="anovamc.html"><a href="anovamc.html#step-2-visualize-one-sample"><i class="fa fa-check"></i><b>32.5.2</b> Step 2: Visualize one sample</a></li>
<li class="chapter" data-level="32.5.3" data-path="anovamc.html"><a href="anovamc.html#step-3-run-the-power-simulator-1"><i class="fa fa-check"></i><b>32.5.3</b> Step 3: Run the power simulator</a></li>
<li class="chapter" data-level="32.5.4" data-path="anovamc.html"><a href="anovamc.html#step-4-should-anything-be-changed"><i class="fa fa-check"></i><b>32.5.4</b> Step 4: Should anything be changed?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="33" data-path="correl.html"><a href="correl.html"><i class="fa fa-check"></i><b>33</b> Correlation</a><ul>
<li class="chapter" data-level="33.1" data-path="correl.html"><a href="correl.html#correlation-causation"><i class="fa fa-check"></i><b>33.1</b> Correlation != Causation</a></li>
<li class="chapter" data-level="33.2" data-path="correl.html"><a href="correl.html#correlation-in-multivariate-outcomes-and-paired-designs"><i class="fa fa-check"></i><b>33.2</b> Correlation in Multivariate Outcomes and Paired Designs</a></li>
<li class="chapter" data-level="33.3" data-path="correl.html"><a href="correl.html#correlation-coefficients"><i class="fa fa-check"></i><b>33.3</b> Correlation coefficients</a><ul>
<li class="chapter" data-level="33.3.1" data-path="correl.html"><a href="correl.html#pearsons-correlation-coefficient"><i class="fa fa-check"></i><b>33.3.1</b> Pearson’s correlation coefficient</a></li>
<li class="chapter" data-level="33.3.2" data-path="correl.html"><a href="correl.html#spearmans-rank-correlation"><i class="fa fa-check"></i><b>33.3.2</b> Spearman’s rank correlation</a></li>
<li class="chapter" data-level="33.3.3" data-path="correl.html"><a href="correl.html#kendalls-tau"><i class="fa fa-check"></i><b>33.3.3</b> Kendall’s tau</a></li>
<li class="chapter" data-level="33.3.4" data-path="correl.html"><a href="correl.html#which-correlation-method-to-use"><i class="fa fa-check"></i><b>33.3.4</b> Which correlation method to use?</a></li>
<li class="chapter" data-level="33.3.5" data-path="correl.html"><a href="correl.html#r-correlation-analysis-functions"><i class="fa fa-check"></i><b>33.3.5</b> R correlation analysis functions</a></li>
<li class="chapter" data-level="33.3.6" data-path="correl.html"><a href="correl.html#plot-the-correlations"><i class="fa fa-check"></i><b>33.3.6</b> Plot the correlations</a></li>
<li class="chapter" data-level="33.3.7" data-path="correl.html"><a href="correl.html#calculate-a-correlation-coefficient-and-posthoc-test"><i class="fa fa-check"></i><b>33.3.7</b> Calculate a correlation coefficient and posthoc test</a></li>
<li class="chapter" data-level="33.3.8" data-path="correl.html"><a href="correl.html#interpretation-of-correlation-output"><i class="fa fa-check"></i><b>33.3.8</b> Interpretation of correlation output</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="34" data-path="regress.html"><a href="regress.html"><i class="fa fa-check"></i><b>34</b> Linear Regression</a><ul>
<li class="chapter" data-level="34.1" data-path="regress.html"><a href="regress.html#the-linear-regression-model"><i class="fa fa-check"></i><b>34.1</b> The linear regression model</a></li>
<li class="chapter" data-level="34.2" data-path="regress.html"><a href="regress.html#least-squares-fitting"><i class="fa fa-check"></i><b>34.2</b> Least squares fitting</a></li>
<li class="chapter" data-level="34.3" data-path="regress.html"><a href="regress.html#the-practical-importance-of-linear-model-parameters"><i class="fa fa-check"></i><b>34.3</b> The practical importance of linear model parameters</a></li>
<li class="chapter" data-level="34.4" data-path="regress.html"><a href="regress.html#linear-model-standard-errors"><i class="fa fa-check"></i><b>34.4</b> Linear model standard errors</a></li>
<li class="chapter" data-level="34.5" data-path="regress.html"><a href="regress.html#linear-regression-in-r"><i class="fa fa-check"></i><b>34.5</b> Linear regression in R</a></li>
<li class="chapter" data-level="34.6" data-path="regress.html"><a href="regress.html#intepretation-1"><i class="fa fa-check"></i><b>34.6</b> Intepretation</a><ul>
<li class="chapter" data-level="34.6.1" data-path="regress.html"><a href="regress.html#residuals"><i class="fa fa-check"></i><b>34.6.1</b> Residuals</a></li>
<li class="chapter" data-level="34.6.2" data-path="regress.html"><a href="regress.html#coefficients"><i class="fa fa-check"></i><b>34.6.2</b> Coefficients</a></li>
<li class="chapter" data-level="34.6.3" data-path="regress.html"><a href="regress.html#degrees-of-freedom-1"><i class="fa fa-check"></i><b>34.6.3</b> Degrees of freedom</a></li>
<li class="chapter" data-level="34.6.4" data-path="regress.html"><a href="regress.html#r-squared"><i class="fa fa-check"></i><b>34.6.4</b> R-squared</a></li>
<li class="chapter" data-level="34.6.5" data-path="regress.html"><a href="regress.html#f-statistic"><i class="fa fa-check"></i><b>34.6.5</b> F-statistic</a></li>
<li class="chapter" data-level="34.6.6" data-path="regress.html"><a href="regress.html#plotting-regression-results"><i class="fa fa-check"></i><b>34.6.6</b> Plotting regression results</a></li>
<li class="chapter" data-level="34.6.7" data-path="regress.html"><a href="regress.html#visualizing-residuals"><i class="fa fa-check"></i><b>34.6.7</b> Visualizing residuals</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="35" data-path="nonlinearintro.html"><a href="nonlinearintro.html"><i class="fa fa-check"></i><b>35</b> Non-linear regression introduction</a><ul>
<li class="chapter" data-level="35.1" data-path="nonlinearintro.html"><a href="nonlinearintro.html#uses-for-nonlinear-regression"><i class="fa fa-check"></i><b>35.1</b> Uses for nonlinear regression</a></li>
<li class="chapter" data-level="35.2" data-path="nonlinearintro.html"><a href="nonlinearintro.html#nonlinear-models-and-parameters"><i class="fa fa-check"></i><b>35.2</b> Nonlinear models and parameters</a><ul>
<li class="chapter" data-level="35.2.1" data-path="nonlinearintro.html"><a href="nonlinearintro.html#hyperbolic-stimulus-response-functions"><i class="fa fa-check"></i><b>35.2.1</b> Hyperbolic stimulus response functions</a></li>
<li class="chapter" data-level="35.2.2" data-path="nonlinearintro.html"><a href="nonlinearintro.html#visualizing-nonlinear-data-and-log-scaling"><i class="fa fa-check"></i><b>35.2.2</b> Visualizing nonlinear data and log scaling</a></li>
</ul></li>
<li class="chapter" data-level="35.3" data-path="nonlinearintro.html"><a href="nonlinearintro.html#how-do-regression-fits-happen"><i class="fa fa-check"></i><b>35.3</b> How do regression fits happen?</a><ul>
<li class="chapter" data-level="35.3.1" data-path="nonlinearintro.html"><a href="nonlinearintro.html#selecting-the-right-model"><i class="fa fa-check"></i><b>35.3.1</b> Selecting the right model</a></li>
<li class="chapter" data-level="35.3.2" data-path="nonlinearintro.html"><a href="nonlinearintro.html#from-models-to-formulas"><i class="fa fa-check"></i><b>35.3.2</b> From models to formulas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="36" data-path="nestedregress.html"><a href="nestedregress.html"><i class="fa fa-check"></i><b>36</b> Nested-model nonlinear regression</a><ul>
<li class="chapter" data-level="36.1" data-path="nestedregress.html"><a href="nestedregress.html#read-and-plot-the-data"><i class="fa fa-check"></i><b>36.1</b> Read and plot the data</a></li>
<li class="chapter" data-level="36.2" data-path="nestedregress.html"><a href="nestedregress.html#perform-the-nonlinear-regression"><i class="fa fa-check"></i><b>36.2</b> Perform the nonlinear regression</a><ul>
<li class="chapter" data-level="36.2.1" data-path="nestedregress.html"><a href="nestedregress.html#troubleshooting-the-regression"><i class="fa fa-check"></i><b>36.2.1</b> Troubleshooting the regression</a></li>
<li class="chapter" data-level="36.2.2" data-path="nestedregress.html"><a href="nestedregress.html#interpreting-the-parameters"><i class="fa fa-check"></i><b>36.2.2</b> Interpreting the parameters</a></li>
<li class="chapter" data-level="36.2.3" data-path="nestedregress.html"><a href="nestedregress.html#residual-plots-to-compare-fits"><i class="fa fa-check"></i><b>36.2.3</b> Residual plots to compare fits</a></li>
<li class="chapter" data-level="36.2.4" data-path="nestedregress.html"><a href="nestedregress.html#compare-aic"><i class="fa fa-check"></i><b>36.2.4</b> Compare AIC</a></li>
<li class="chapter" data-level="36.2.5" data-path="nestedregress.html"><a href="nestedregress.html#other-ways-to-compare-models"><i class="fa fa-check"></i><b>36.2.5</b> Other ways to compare models</a></li>
<li class="chapter" data-level="36.2.6" data-path="nestedregress.html"><a href="nestedregress.html#interpretation-of-this-one-replicate"><i class="fa fa-check"></i><b>36.2.6</b> Interpretation of this one replicate</a></li>
<li class="chapter" data-level="36.2.7" data-path="nestedregress.html"><a href="nestedregress.html#alternate-analysis"><i class="fa fa-check"></i><b>36.2.7</b> Alternate analysis</a></li>
</ul></li>
<li class="chapter" data-level="36.3" data-path="nestedregress.html"><a href="nestedregress.html#summary-1"><i class="fa fa-check"></i><b>36.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="37" data-path="nonlinearreplicates.html"><a href="nonlinearreplicates.html"><i class="fa fa-check"></i><b>37</b> Nonlinear regression of independent replicates</a><ul>
<li class="chapter" data-level="37.1" data-path="nonlinearreplicates.html"><a href="nonlinearreplicates.html#the-dataset"><i class="fa fa-check"></i><b>37.1</b> The dataset</a></li>
<li class="chapter" data-level="37.2" data-path="nonlinearreplicates.html"><a href="nonlinearreplicates.html#munging-for-regression-analysis"><i class="fa fa-check"></i><b>37.2</b> Munging for regression analysis</a><ul>
<li class="chapter" data-level="37.2.1" data-path="nonlinearreplicates.html"><a href="nonlinearreplicates.html#average-the-technical-replicates"><i class="fa fa-check"></i><b>37.2.1</b> Average the technical replicates</a></li>
<li class="chapter" data-level="37.2.2" data-path="nonlinearreplicates.html"><a href="nonlinearreplicates.html#create-one-table"><i class="fa fa-check"></i><b>37.2.2</b> Create one table</a></li>
<li class="chapter" data-level="37.2.3" data-path="nonlinearreplicates.html"><a href="nonlinearreplicates.html#plot-the-data-1"><i class="fa fa-check"></i><b>37.2.3</b> Plot the data</a></li>
<li class="chapter" data-level="37.2.4" data-path="nonlinearreplicates.html"><a href="nonlinearreplicates.html#clean-up-regression-results"><i class="fa fa-check"></i><b>37.2.4</b> Clean up regression results</a></li>
</ul></li>
<li class="chapter" data-level="37.3" data-path="nonlinearreplicates.html"><a href="nonlinearreplicates.html#t-test-on-half-lives"><i class="fa fa-check"></i><b>37.3</b> T-test on half-lives</a></li>
<li class="chapter" data-level="37.4" data-path="nonlinearreplicates.html"><a href="nonlinearreplicates.html#conclusion"><i class="fa fa-check"></i><b>37.4</b> Conclusion</a></li>
<li class="chapter" data-level="37.5" data-path="nonlinearreplicates.html"><a href="nonlinearreplicates.html#summary-figure"><i class="fa fa-check"></i><b>37.5</b> Summary figure</a></li>
</ul></li>
<li class="chapter" data-level="38" data-path="multregress.html"><a href="multregress.html"><i class="fa fa-check"></i><b>38</b> Multiple regression</a><ul>
<li class="chapter" data-level="38.1" data-path="multregress.html"><a href="multregress.html#the-linear-regression-model-1"><i class="fa fa-check"></i><b>38.1</b> The linear regression model</a></li>
<li class="chapter" data-level="38.2" data-path="multregress.html"><a href="multregress.html#multiple-regression-models"><i class="fa fa-check"></i><b>38.2</b> Multiple regression models</a></li>
<li class="chapter" data-level="38.3" data-path="multregress.html"><a href="multregress.html#experimental-multiple-regression"><i class="fa fa-check"></i><b>38.3</b> Experimental multiple regression</a><ul>
<li class="chapter" data-level="38.3.1" data-path="multregress.html"><a href="multregress.html#a-one-factor-experiment-with-3-groups"><i class="fa fa-check"></i><b>38.3.1</b> A one factor experiment with 3 groups</a></li>
<li class="chapter" data-level="38.3.2" data-path="multregress.html"><a href="multregress.html#a-two-factor-experiment-with-6-groups"><i class="fa fa-check"></i><b>38.3.2</b> A two factor experiment with 6 groups</a></li>
</ul></li>
<li class="chapter" data-level="38.4" data-path="multregress.html"><a href="multregress.html#multiple-linear-mixed-models"><i class="fa fa-check"></i><b>38.4</b> Multiple linear mixed models</a></li>
<li class="chapter" data-level="38.5" data-path="multregress.html"><a href="multregress.html#multiple-regression-of-observational-data"><i class="fa fa-check"></i><b>38.5</b> Multiple regression of observational data</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="logregress.html"><a href="logregress.html"><i class="fa fa-check"></i><b>39</b> Logistic regression</a><ul>
<li class="chapter" data-level="39.1" data-path="logregress.html"><a href="logregress.html#uses-of-logistic-regression"><i class="fa fa-check"></i><b>39.1</b> Uses of logistic regression</a><ul>
<li class="chapter" data-level="39.1.1" data-path="logregress.html"><a href="logregress.html#sidebar-doing-logistic-regression-is-machine-learning"><i class="fa fa-check"></i><b>39.1.1</b> Sidebar: Doing logistic regression is machine learning</a></li>
</ul></li>
<li class="chapter" data-level="39.2" data-path="logregress.html"><a href="logregress.html#derivation-of-the-logistic-regression-model"><i class="fa fa-check"></i><b>39.2</b> Derivation of the logistic regression model</a><ul>
<li class="chapter" data-level="39.2.1" data-path="logregress.html"><a href="logregress.html#relationship-of-logit-to-odds-to-the-model-coefficients-and-probability"><i class="fa fa-check"></i><b>39.2.1</b> Relationship of logit to odds to the model coefficients and probability</a></li>
<li class="chapter" data-level="39.2.2" data-path="logregress.html"><a href="logregress.html#additional-types-of-logistic-regression-models"><i class="fa fa-check"></i><b>39.2.2</b> Additional types of logistic regression models</a></li>
</ul></li>
<li class="chapter" data-level="39.3" data-path="logregress.html"><a href="logregress.html#stress-and-survival"><i class="fa fa-check"></i><b>39.3</b> Stress and survival</a><ul>
<li class="chapter" data-level="39.3.1" data-path="logregress.html"><a href="logregress.html#interpretation-of-output"><i class="fa fa-check"></i><b>39.3.1</b> Interpretation of output</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="40" data-path="mixedlogistic.html"><a href="mixedlogistic.html"><i class="fa fa-check"></i><b>40</b> Mixed model logistic regression</a><ul>
<li class="chapter" data-level="40.1" data-path="mixedlogistic.html"><a href="mixedlogistic.html#mixed-models-fixed-and-random-effects"><i class="fa fa-check"></i><b>40.1</b> Mixed models, fixed and random effects</a><ul>
<li class="chapter" data-level="40.1.1" data-path="mixedlogistic.html"><a href="mixedlogistic.html#nfat-localization-within-smooth-muscle-cells"><i class="fa fa-check"></i><b>40.1.1</b> NFAT localization within smooth muscle cells</a></li>
</ul></li>
<li class="chapter" data-level="40.2" data-path="data.html"><a href="data.html#data"><i class="fa fa-check"></i><b>40.2</b> Data</a><ul>
<li class="chapter" data-level="40.2.1" data-path="mixedlogistic.html"><a href="mixedlogistic.html#inference-1"><i class="fa fa-check"></i><b>40.2.1</b> Inference</a></li>
</ul></li>
<li class="chapter" data-level="40.3" data-path="mixedlogistic.html"><a href="mixedlogistic.html#alternative-analysis"><i class="fa fa-check"></i><b>40.3</b> Alternative analysis</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">JABSTB: Statistical Design and Analysis of Experiments with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multregress" class="section level1">
<h1><span class="header-section-number">Chapter 38</span> Multiple regression</h1>
<p>The previous chapters on linear and nonlinear regression deal with fairly specific use cases for regression. Specifically, you’ll note they involved only one predictor variable, which was continuous.</p>
<p>The goal of those procedures was to apply linear or nonlinear models to extract the regression model parameters. These parameters imply certain biological properties (e.g., <span class="math inline">\(K_D\)</span>, <span class="math inline">\(V_{max}\)</span>, kinetic rate constants, etc) that are of primary interest when using the method.</p>
<p>Linear regression is also useful to analyze continuous responses driven by discrete predictor variables. Furthermore, regression can be performed on responses associated with multiple predictor variables, some of which might be continuous and some of which might be discrete. <strong>Multiple regression</strong> or <strong>multiple linear regression</strong> is the most common jargon used to describe this extension of the linear regression to a comprehensive array of experimental designs. That’s the focus of this chapter.</p>
<p>We’ve actually been in this neighborhood previously, but called it other names. ANOVA and t-tests are regressions. Experimental biologists tend to use t-tests and ANOVA to analyze experiments that involve the use of discrete predictor variables. Why? Mostly out of habit. Those procedures are geared to alerting us to comparing effects of treatment and making decisions about whether an experiment “worked” or not.</p>
<p>But that same information lies within multiple regression analysis, which if used otherwise would generate identical answers and inference as do t-tests and ANOVA.</p>
<p>Multiple regression is used more commonly in the social and public health sciences. One reason is cultural, as for experimental biologists, that’s just the way things are done in those fields. In part it’s also because much of their data is observational. As such, they tend to deal with data sets that have many more predictor variables than what an experimental biologist can comfortably manipulate when testing hypotheses.</p>
<p>Furthermore, those fields emphasize weighing how much a predictor variable or a group of variables of interest contributes to a response while “controlling” for the effects of other variables. Arguably, there’s more of a focus on estimating variable effect sizes and less on comparing group effects to see if they differ. Multiple regression analysis lends itself better to this kind of inference than t-tests and ANOVA.</p>
<p>Throughout the semester we’ve been working through a heuristic that begins with deciding whether your response variable is continuous or discrete, and working from there to decide what to do. This is that:</p>
<p><em>For nominal response data use exact tests. For ordinal data use nonparametrics. For continuous response variables with two or fewer levels of a predictor variable, choose t-tests. For three or more levels, choose ANOVA if the predictor is factorial or regression if the predictor is equal interval. When measurements are intrinsically-linked analyze using paired/related/repeated measure versions of the tests.</em></p>
<p>Here’s an optional heuristic:</p>
<p><em>Analyze your data using a multiple regression model</em></p>
<p>Having said that, multiple linear regression takes some configuration to ensure it is cohesive with the overall experimental design. The functions, or at least their configurations, to use for non-guassian response variables (basically, those for “generalized” linear models) differs from those used for guassian variables.</p>
<p>The same goes for completely independent replicates versus replicates having paired/related/repeated measures. In regression jargon, data comprising the latter are called multiple linear “mixed” models. Conducting inference with the latter is much more difficult than for straight multiple linear models.</p>
<p>I’m going to focus below, first, on illustrating how an experimental biologist would use multiple regression when doing factorial experiments. Later, we’ll deal with more general uses for multiple regression modeling.</p>
<div id="the-linear-regression-model-1" class="section level2">
<h2><span class="header-section-number">38.1</span> The linear regression model</h2>
<p>Recall the linear model we discuses for a continuous response variable, <span class="math inline">\(Y\)</span> and its predictor variable, <span class="math inline">\(X\)</span>: <span class="math display">\[y_i=\alpha+\beta x_i +\epsilon_i \]</span></p>
<p>The <span class="math inline">\(\beta\)</span> coefficient is a multiplier such that for every 1 unit change in the level of <span class="math inline">\(x_i\)</span>, <span class="math inline">\(y_i\)</span> will change by <span class="math inline">\(\beta\)</span>. If <span class="math inline">\(\beta = 0\)</span> there is no effect for any level of <span class="math inline">\(X\)</span>. In that case, the intercept <span class="math inline">\(\alpha\)</span> estimates the value of the response variable <span class="math inline">\(Y\)</span>. Thus <span class="math inline">\(\alpha\)</span> is equivalent to the population mean <span class="math inline">\(\mu\)</span> for <span class="math inline">\(Y\)</span> in the absence of <span class="math inline">\(X\)</span>. The residual error <span class="math inline">\(\epsilon_i\)</span> is the residual difference between the values of <span class="math inline">\(y_i\)</span> predicted by the model and the values for the data. These residuals are normally distributed and have a variance of <span class="math inline">\(\sigma^2\)</span>.</p>
</div>
<div id="multiple-regression-models" class="section level2">
<h2><span class="header-section-number">38.2</span> Multiple regression models</h2>
<p>Multiple regression models have more than one predictor variables. For data containing <span class="math inline">\(i=1, 2..n\)</span> independent replicates and <span class="math inline">\(j=1, 2..p\)</span> predictor variables <span class="math display">\[y_i=\alpha+\beta_1 X_{i1}+\beta_2 X_{i2}+...\beta_p X_{ip} +\epsilon_{i}\]</span></p>
<p>These can be either continuous or discrete, or any combination thereof.</p>
<p><span class="math display">\[X=\{nominal; eg, genotype(+/+, -/+, -/-) \\~\\ ordinal; eg, education level (HS, College, PostGrad\\~\\continuous; eg, time( 0, 1, 2, 4, ..30\ min)\}\]</span></p>
</div>
<div id="experimental-multiple-regression" class="section level2">
<h2><span class="header-section-number">38.3</span> Experimental multiple regression</h2>
<p>Here’s a simulation of a simple factorial experiment, comparing responses of a stimulus and its negative control. Every measurement is independent of all other measurements. Thus, the sample has 6 independent replicates.</p>
<p>The predictor variable, FactorA, comes at two levels: control and stimulus. The response is a continuous variable. In your own mind substitute things for these. For me, the response is a transcription factor-driven luciferease activity, a negative control, and an agonist of a receptor is the stimulus.</p>
<p>We obtain the following random sample:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)
factorA &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;control&quot;</span>, <span class="st">&quot;stimulus&quot;</span>), <span class="dt">each=</span><span class="dv">3</span>)
response &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">50</span>, <span class="dv">1</span>), <span class="kw">rnorm</span>(<span class="dv">3</span>,<span class="dv">75</span>,<span class="dv">1</span>))

data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(factorA, response)
data</code></pre></div>
<pre><code>##    factorA response
## 1  control 48.79293
## 2  control 50.27743
## 3  control 51.08444
## 4 stimulus 72.65430
## 5 stimulus 75.42912
## 6 stimulus 75.50606</code></pre>
<p>The linear model for this experiment can be expressed as follows: <span class="math display">\[response=control+\beta \times stimulus + residual\]</span></p>
<p>The model formula can be configured in several optional ways.</p>
<p>Adding the term <code>+0</code> to the model formula in the <code>lm</code> function suppresses the intercept, allowing for a glance at the sample group means. These make sense with what was coded above.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>(response<span class="op">~</span>factorA<span class="op">+</span><span class="dv">0</span>, data)
model</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = response ~ factorA + 0, data = data)
## 
## Coefficients:
##  factorAcontrol  factorAstimulus  
##           50.05            74.53</code></pre>
<p>Knowing those group mean values helps to understand the meaning of the regression coefficients derived from the more conventional approach, which is not to suppress the intercept.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>(response<span class="op">~</span>factorA, data)
model</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = response ~ factorA, data = data)
## 
## Coefficients:
##     (Intercept)  factorAstimulus  
##           50.05            24.48</code></pre>
<p>The two coefficients above are estimates of the linear model’s parameters. The <code>intercept</code> and the <code>factorAstimulus</code> serve as estimates of the true population values for <span class="math inline">\(\control\)</span> and <span class="math inline">\(\beta\)</span> in our linear model, respectively.</p>
<p>We can rewrite the linear model with those estimates as <span class="math display">\[y=50.05+24.48x\]</span></p>
<p>Since <span class="math inline">\(x\)</span> represents a factorial variable, we just assign it a value of one, when a given factor level is present, or zero when it is not.</p>
<p>Thus, the response value in the presence of the stimulus is <span class="math inline">\(y=50.05+24.48=74.53\)</span>, which is the mean of the stimulus group.</p>
<p>When the stimulus is absent, than <span class="math inline">\(x=0\)</span>, and the linear model predicts a response of <span class="math inline">\(y=50.05\)</span>, which you can see is both the value of the intercept and the mean of the control group.</p>
<p>The coefficient for the stimulus term in this model formula is not the mean of the response to the stimulus, but is instead the difference between between the mean response to the stimulus and the mean response of the control.</p>
<p>Perhaps that reminds you of the numerator for the unpaired t-test, between two levels of a factor, control and stimulus? <span class="math display">\[t=\frac{mean_{stimulus}-mean_{control}}{SE}\]</span></p>
<p>Let’s see if a t-test between stimulus and control gives us the same result as the linear regression. First, let’s complete the linear model analysis.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(model)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = response ~ factorA, data = data)
## 
## Residuals:
##       1       2       3       4       5       6 
## -1.2587  0.2258  1.0328 -1.8755  0.8993  0.9762 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      50.0516     0.8155   61.37 4.22e-07 ***
## factorAstimulus  24.4782     1.1534   21.22 2.91e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.413 on 4 degrees of freedom
## Multiple R-squared:  0.9912, Adjusted R-squared:  0.989 
## F-statistic: 450.4 on 1 and 4 DF,  p-value: 2.914e-05</code></pre>
<p>Focus on the t-value for the factorAsstimulus coefficient. That t-test determines whether the coefficient value differs from zero. The coefficient value is, again, the difference between the mean responses of the control and the stimulus. We put that in the numerator and we put the SE of that difference in the denominator: <span class="math display">\[t=\frac{24.4782}{1.1534}=21.22\]</span></p>
<p>Woohoo!</p>
<p>To be clear, when the predictor variable was continuous, we previously discussed these <span class="math inline">\(\beta\)</span> coefficients as the “slope” of the linear regression line. That’s still the case here. R coerces a distance of 1 on the abscissa between the factorA values of control and stimulus. Thus, the difference between their means <span class="math inline">\(\Delta y\)</span> divided by 1 <span class="math inline">\(\Delta x\)</span> is the slope of an imaginary line between them.</p>
<p>Now let’s look at an unpaired t-test between the two factors.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(response<span class="op">~</span>factorA, data, <span class="dt">var.equal=</span>T)</code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  response by factorA
## t = -21.224, df = 4, p-value = 2.914e-05
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -27.68045 -21.27600
## sample estimates:
##  mean in group control mean in group stimulus 
##               50.05160               74.52983</code></pre>
<p>Woohoo!</p>
<p>Except for the sign, the t-statistic -21.22 is identical to what was derived in the linear regression! This t-test is calculated as follows: <span class="math display">\[t=\frac{50.05160-74.52983}{1.153353}=-21.22352\]</span> That denominator is the standard error of the difference between means, which is not part of the t-test output, but can be calculated by hand by dividing the t-statistic value by the value for the difference between the means. You can see that it equals the coefficient value within the <code>lm</code> output.</p>
<p>Thus, by comparing <code>lm</code> and <code>t.test</code> output when run on the same data set we see that the same basic calculations are performed. They’re just presented differently.</p>
<p>Put another way, a t-test is actually a linear regression using a factorial variable at two levels.</p>
<p>The <code>t.test</code> output is more explicit about group means, and it provides a confidence interval for the difference between group means, while hiding its calculation for the standard error for that difference. The <code>lm</code> is explicit about the difference between the group means, and gives you that standard error, but only shows one group mean, that for the intercept. But they’re each making the same signal-to-noise calculation (t-test)!</p>
<p>The real differences are more related to interpretation. We use the <code>t.test</code> to ask a simple threshold question: Do the two groups differ? Yes or no?</p>
<p>The linear regression question is obviously related but just different enough to matter: How much does the stimulus affect the response relative to control?</p>
<p>That distinction is important. In the context of the linear model, the result says, “the stimulus accounts for 24.48 <span class="math inline">\(Y\)</span> response units when controlled for the negative control group.</p>
<p>Thus, you can use multiple linear regression to run the equivalent of an unpaired t-test. But you can also use it to declare the effect of a factorial variable relative to a reference response. Most practitioners of multiple regression use it for the latter purposes.</p>
<div id="why-is-that-sign-negative-in-the-t-test" class="section level4">
<h4><span class="header-section-number">38.3.0.1</span> Why is that sign negative in the t-test??</h4>
<p>That’s just a quirk of R, but it’s an important quirk to understand.</p>
<p>When you give R these variables (at least in this format) it doesn’t know what factor level you want to list first. So by default it arranges groups alphanumerically.</p>
<p>The ‘c’ in control comes before the ‘s’ in stimulus, so R works with control first in both the linear regression and the t-test.</p>
<p>In the t-test, the calculation for the difference between groups is 2nd from 1st, or <span class="math inline">\(c-s\)</span>. Thus the negative value for the t-statistic.</p>
<p>The <code>lm</code> function is engineered to use the intercept as a reference. The linear regression assigns the lowest alphanumeric as the intercept, which it then subtracts from the mean response of the next variable, <span class="math inline">\(s-c\)</span>.</p>
</div>
<div id="specifying-the-intercept" class="section level4">
<h4><span class="header-section-number">38.3.0.2</span> Specifying the intercept</h4>
<p>Often you’ll name variables the way you like. But you’ll want to specify which group should be the intercept. Usually it’s your control condition. In regression jargon, it is the condition by which the other variables will be controlled for.</p>
<p>Using the <code>relevel</code> function provides you a bit more control to define the intercept value in linear regression compared to the default alphanumeric way.</p>
<p>Here’s some simulated data. The predictor variable, hart, has 4 levels: art, bart, cart, and dart. It’s on an alphanumeric scale. Smelly is the response variable. As you can see, each level of hart yields a different smelly response.</p>
<p>Even though I list the hart variable levels from <code>d</code> to <code>a</code> in the dataframe, R coerces them from <code>a</code> to <code>d</code> in the regression model, thereby forcing art to serve as the intercept</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">art &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">50</span>, <span class="dv">1</span>)
bart &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">100</span>, <span class="dv">1</span>)
cart &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">1</span>)
dart &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">200</span>, <span class="dv">1</span>)

hart &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;dart&quot;</span>, <span class="st">&quot;cart&quot;</span>, <span class="st">&quot;bart&quot;</span>, <span class="st">&quot;aart&quot;</span>), <span class="dt">each=</span><span class="dv">3</span>)
data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(hart, <span class="dt">smelly=</span><span class="kw">c</span>(dart, cart, bart, art))
data</code></pre></div>
<pre><code>##    hart       smelly
## 1  dart 199.88971451
## 2  dart 199.48899049
## 3  dart 199.08880458
## 4  cart  -0.77625389
## 5  cart   0.06445882
## 6  cart   0.95949406
## 7  bart  99.10996217
## 8  bart  99.52280730
## 9  bart  99.00161356
## 10 aart  49.42526004
## 11 aart  49.45336814
## 12 aart  49.43554800</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(smelly<span class="op">~</span>hart, data)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = smelly ~ hart, data = data)
## 
## Coefficients:
## (Intercept)     hartbart     hartcart     hartdart  
##       49.44        49.77       -49.36       150.05</code></pre>
<p>What do those coefficient values mean? Well, they are all in units of smelly, referenced to the level of smelly in the presence of art. Because it begins with the letter ‘a’, art is the lowest alphanumeric value of the four predictors. Therefore, it is assigned as the intercept factor. In smelly units, the intercept is the response to art; bart is about 50 more than art; cart is about 50 less than art; and dart is about 150 more than art.</p>
<p>But let’s say we’d instead like to reference everything to the value of cart, which has a smelly value of 0. We’d use the <code>relevel</code> function for that.</p>
<p>First we have to define the variable hart as a factorial variable explicitly. Then, we relevel the values of hart so that cart is referenced as the intercept.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">hart &lt;-<span class="st"> </span><span class="kw">factor</span>(hart) <span class="co">#don&#39;t skip this step, without it the next gives an error!!!</span>
data<span class="op">$</span>hart &lt;-<span class="st"> </span><span class="kw">relevel</span>(hart, <span class="dt">ref=</span><span class="st">&quot;cart&quot;</span>)


<span class="kw">lm</span>(smelly<span class="op">~</span>hart, data)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = smelly ~ hart, data = data)
## 
## Coefficients:
## (Intercept)     hartaart     hartbart     hartdart  
##     0.08257     49.35549     99.12889    199.40660</code></pre>
<p>The linear model for this data is <span class="math display">\[smelly = -0.658+50.5\times art+100.1\times bart+200.6 \times dart\]</span></p>
<p>When <span class="math inline">\(art=bart=0\)</span>, <span class="math inline">\(smelly=200\)</span></p>
<p>The relevel is particularly useful manipulation for experimentalists, who often have explicit negative controls in their data sets. Social and public health scientists use <code>relevel</code> when they want to control the response for one of their variables. For example, when they want to control for the age of subjects, they relevel the age variable to the intercept. In that way, all other variable coefficients are relative to the magnitude of the effect of age.</p>
</div>
<div id="a-one-factor-experiment-with-3-groups" class="section level3">
<h3><span class="header-section-number">38.3.1</span> A one factor experiment with 3 groups</h3>
<p>T-tests are for comparing 2 groups. ANOVA’s are for comparing 3 or more groups. It turns out, you can use multiple linear regression to mimic an ANOVA test, too.</p>
<p>Let’s add one more level for the predictor variable (and its responses) to the experiment. Since it now has 3 groups, and 9 independent replicates, we shouldn’t do t-tests. We could do ANOVA, but we could also do a multiple regression model, too.</p>
<p>That model is <span class="math display">\[response=control+\beta_1 stimulus1+\beta_2 stimulus2\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)
factorA &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;control&quot;</span>, <span class="st">&quot;stimulus1&quot;</span>, <span class="st">&quot;stimulus2&quot;</span>), <span class="dt">each=</span><span class="dv">3</span>)
response &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">50</span>, <span class="dv">1</span>), <span class="kw">rnorm</span>(<span class="dv">3</span>,<span class="dv">75</span>,<span class="dv">1</span>), <span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">175</span>, <span class="dv">1</span>))

data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(factorA, response)

model &lt;-<span class="st"> </span><span class="kw">lm</span>(response<span class="op">~</span>factorA, data)
<span class="kw">summary</span>(model)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = response ~ factorA, data = data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.87553 -0.01280  0.01531  0.89930  1.03284 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)       50.0516     0.6659   75.16 3.73e-10 ***
## factorAstimulus1  24.4782     0.9417   25.99 2.14e-07 ***
## factorAstimulus2 124.3865     0.9417  132.08 1.27e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.153 on 6 degrees of freedom
## Multiple R-squared:  0.9997, Adjusted R-squared:  0.9996 
## F-statistic:  9792 on 2 and 6 DF,  p-value: 2.873e-11</code></pre>
<p>Notice how the coefficient value for stimulus2 is the difference between the mean response value for stimulus2 (~175 units) and the mean response value for control (~50 units). Each coefficient t-test asks whether the value of the coefficient differs from zero.</p>
<p>In linear regression with only a single predictor variable, that coefficient was the slope of a straight line through all the <span class="math inline">\(xy\)</span> data pairs. In multiple linear regression you have to imagine separate straight lines connecting the mean intercept response value and the response values for each of the predictors.</p>
<p>We can compare the regression model output to that for an ANOVA test on the data. Here is the equivalent of a one-way completely randomized ANOVA.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">Anova</span>(model)</code></pre></div>
<pre><code>## Anova Table (Type II tests)
## 
## Response: response
##           Sum Sq Df F value    Pr(&gt;F)    
## factorA    26053  2  9792.1 2.873e-11 ***
## Residuals      8  6                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The F-test calculated in this ANOVA is the same as that calculated in the regression model. The F is a ratio of model variance to the residual variance. In the null F distribution, model and residual variance would be about equal. An extreme value of F means that the model explains a lot more of the variance than random residual differences. In this case, the model explains 9792.1 times more variance than does residual.</p>
<p>If we were making ANOVA inferences, we would conclude that factorA has an effect. There are some differences between the means of the three groups. If we were making a regression inference, we’d predict values for <span class="math inline">\(y\)</span> on the basis of this model <span class="math display">\[response = 50.05+24.48\times stimulus1+124.39\times stimulus2\]</span> and we’d say that stimulus1 and stimulus 2 cause 24.48- and 124.39-more units of response compared to control.</p>
<p>The t-test results also allow us to conclude the two groups differ from the control.</p>
</div>
<div id="a-two-factor-experiment-with-6-groups" class="section level3">
<h3><span class="header-section-number">38.3.2</span> A two factor experiment with 6 groups</h3>
<p>Now we’ll add a second factorial variable, factorB, to the design above. FactorB has two levels. The simulated design is akin to a two-way completely randomized ANOVA. We’ll also simulate in an interaction effect between the two variables.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)
factorA &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;control&quot;</span>, <span class="st">&quot;stimulus1&quot;</span>, <span class="st">&quot;stimulus2&quot;</span>), <span class="dt">each=</span><span class="dv">3</span>), <span class="dv">2</span>)
factorB &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;cofactor1&quot;</span>, <span class="st">&quot;cofactor2&quot;</span>), <span class="dt">each=</span><span class="dv">9</span>)
response &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">50</span>, <span class="dv">1</span>), 
              <span class="kw">rnorm</span>(<span class="dv">3</span>,<span class="dv">75</span>,<span class="dv">1</span>), 
              <span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">175</span>, <span class="dv">1</span>), 
              <span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">100</span>, <span class="dv">1</span>), 
              <span class="kw">rnorm</span>(<span class="dv">3</span>,<span class="dv">300</span>,<span class="dv">1</span>), 
              <span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">700</span>, <span class="dv">1</span>)
              )

data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(factorA, factorB, response)</code></pre></div>
<p>There are a handful of linear models we could run on this. They should be scientifically driven. Since we wouldn’t design an experiment like this unless we thought there would be an interaction between the two factors, we’ll focus on that. The coefficients for the interacting model would serve as effect sizes to describe the level of interaction that occurs.</p>
<p>Coefficients can be confusing. Here’s a way to clarify what’s going on. It turns out, a model’s intercept is calculated differently, depending upon how the model is defined.</p>
<p>First, a factor-less model. This output represents the grand mean of all the values in the data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(response<span class="op">~</span><span class="dv">1</span>, data)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = response ~ 1, data = data)
## 
## Coefficients:
## (Intercept)  
##         233</code></pre>
<p>Next is a linear model just for the 3 levels of factorA. The intercept is the mean for all the data in the control groups under both cofactor1 and cofactor2.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(response<span class="op">~</span>factorA, data)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = response ~ factorA, data = data)
## 
## Coefficients:
##      (Intercept)  factorAstimulus1  factorAstimulus2  
##            74.63            112.67            362.33</code></pre>
<p>Here’s a linear model for the second variable alone. The intercept represents the mean of all the groups under cofactor1</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(response<span class="op">~</span>factorB, data)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = response ~ factorB, data = data)
## 
## Coefficients:
##      (Intercept)  factorBcofactor2  
##            99.67            266.59</code></pre>
<p>Now we have the linear model for the two factors combined. This intercept is the sum of the intercepts for factorA and factorB, less the grand mean for all the data. The negative value is a hint of an interaction effect between the two factors.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(response<span class="op">~</span>factorA<span class="op">+</span>factorB, data)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = response ~ factorA + factorB, data = data)
## 
## Coefficients:
##      (Intercept)  factorAstimulus1  factorAstimulus2  factorBcofactor2  
##           -58.66            112.67            362.33            266.59</code></pre>
<p>Finally we have the full linear model for the two factors combined, including an interaction term. Here the intercept is the value of control. All coefficients values are the difference between their absolute effect sizes and the value for control (intercept).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(response<span class="op">~</span>factorA<span class="op">*</span>factorB, data)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = response ~ factorA * factorB, data = data)
## 
## Coefficients:
##                       (Intercept)                   factorAstimulus1  
##                             50.05                              24.48  
##                  factorAstimulus2                   factorBcofactor2  
##                            124.39                              49.16  
## factorAstimulus1:factorBcofactor2  factorAstimulus2:factorBcofactor2  
##                            176.39                             475.89</code></pre>
<p>Since the values each discrete predictor variable level can take on is either 1 (if present) or 0 (if not), all of these coefficient values serve as an effect size for the indicated group, relative to control (intercept).</p>
<p>The linear model is <span class="math display">\[Y=50.05+24.48\times stimulus1+124.39\times stimulus2+49.16\times cofactor2+176.39\times stimulus1/cofactor2 +475.89\times stimulus2/cofactor2\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(response<span class="op">~</span>factorA<span class="op">*</span>factorB, data))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = response ~ factorA * factorB, data = data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.87553 -0.18276 -0.00135  0.37825  1.03284 
## 
## Coefficients:
##                                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                        50.0516     0.5260   95.15  &lt; 2e-16 ***
## factorAstimulus1                   24.4782     0.7439   32.91 3.93e-13 ***
## factorAstimulus2                  124.3865     0.7439  167.21  &lt; 2e-16 ***
## factorBcofactor2                   49.1599     0.7439   66.08  &lt; 2e-16 ***
## factorAstimulus1:factorBcofactor2 176.3929     1.0520  167.67  &lt; 2e-16 ***
## factorAstimulus2:factorBcofactor2 475.8913     1.0520  452.36  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9111 on 12 degrees of freedom
## Multiple R-squared:      1,  Adjusted R-squared:      1 
## F-statistic: 2.183e+05 on 5 and 12 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The model summary recapitulates the coefficient values. Using this configuration, all are relative to the intercept. Each t-tests determines whether that coefficient differs from zero.</p>
<p>In this case, all coefficients differ from zero, meaning the factor level corresponding to each has some effect on the response over and beyond that of the control level. <strong>Note that these p-values are NOT adjusted for multiple comparisons.</strong></p>
<p>These coefficient values can be used to make declarative statements about effect sizes in response to specific levels of the variables: “In the presence of cofactor1, Stimulus1 and 2 cause a 24 and 124 unit response, respectively, over control. But in the presence of cofactor2, they cause 176- and 475-unit responses, indicating a synergy interaction.”</p>
<p>Or something like that.</p>
<p>The F test is a ratio of the variance associated with the model to the residual variance. It’s not particularly useful other than to announce that the model explains the data better than does residual variation.</p>
<p>Passing the model into an the <code>Anova</code> function from the <code>car</code> package provides F tests for the main effects of each factor and for the interaction, providing the familiar ANOVA way of interpreting the data if desired.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">Anova</span>(<span class="kw">lm</span>(response<span class="op">~</span>factorA<span class="op">*</span>factorB, data))</code></pre></div>
<pre><code>## Anova Table (Type II tests)
## 
## Response: response
##                 Sum Sq Df F value    Pr(&gt;F)    
## factorA         412618  2  248548 &lt; 2.2e-16 ***
## factorB         319811  1  385289 &lt; 2.2e-16 ***
## factorA:factorB 173643  2  104597 &lt; 2.2e-16 ***
## Residuals           10 12                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>All in all, multiple regression is an alternative way to conduct analyses on data for which every replicate is independent from all others, such as in unpaired/completely randomized designs that are otherwise performed using t-tests or ANOVA.</p>
</div>
</div>
<div id="multiple-linear-mixed-models" class="section level2">
<h2><span class="header-section-number">38.4</span> Multiple linear mixed models</h2>
<p>Multiple regression can also be useful for analyzing data within which measurements are intrinsically-linked, such as in experiments that have paired/related/repeated measures.</p>
<p>There are three key distinctions from the multiple regression above. First, we’ll need to use the <code>lmer</code> function in the <code>lme4</code> package (or the <code>lme</code> function in the <code>nlme</code> package), rather than <code>lm</code> in R’s base stats package. These use maximum likelihood estimation to calculate coefficient values, rather than least squares.</p>
<p>Second, is cutting through the jargon.</p>
<p>Third, it is dramatically more difficult to extract inference from mixed multiple regression modeling than from multiple regression modeling. The experimental researcher is probably better off sticking to ANOVA. There are exceptions to this.</p>
<p>The coefficients solved for through linear regression are called the “fixed effects” of a linear model. They correspond to the true values in the sampled population the alpha and the beta. Recall that models are perfect data are not. So they are the perfect part of the model, making them “fixed”.</p>
<p>The error term <span class="math inline">\(\epsilon\)</span> accounts for the extent by which actual data diverge from that predicted by these fixed effects. <span class="math inline">\(\eplison\)</span> exists to account for all the other unknown factors that conspire to influence a response.</p>
<p>But we can control for some of this when we take multiple measures on each replicate. In regression jargon, the replicate-to-replicate variation is called the random effect.</p>
<p>So “mixed” multiple linear regression models have a mixture of terms for the fixed and for the random effects within an experiment. Mixed models are therefore the linear regression analogs of paired/related measure designs.</p>
<p>The <code>sleepstudy</code> data set in the <code>lme4</code> package is one such mixed effect study. The study measured reaction times (in ms) under conditions of worsening sleep deprivation. Repeated reaction time measurements were taken from each of 18 subjects over a 9 day period of sleep deprivation. These 18 subjects represent a random sample of the type of person who might become sleep deprived.</p>
<p>Here’s a chart showing how it went for each subject. For some, reaction times are noticeably longer. For others, reaction lengthening is less bloody obvious. For subject 335 sleep deprivation might have slightly quickened reaction times!</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(sleepstudy, <span class="kw">aes</span>(Days, Reaction))<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>()<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&quot;lm&quot;</span>, <span class="dt">se=</span>F)<span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>Subject)</code></pre></div>
<p><img src="jabstb_files/figure-html/unnamed-chunk-392-1.png" width="672" /></p>
<p>Here’s the question everybody wants answered from this study: What effect does sleep deprivation have on reaction time?</p>
<p>Note, the question is NOT, “is the effect of sleep deprivation on reaction time”significant?“” That’s much less compelling than actually quantifying the effect size.</p>
<p>If we completely ignore the presumed correlation within the repeated measurements within each subject we would use the <code>lm</code> function in R’s base <code>stats</code> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">lm</span>(Reaction <span class="op">~</span><span class="st"> </span>Days, sleepstudy))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Reaction ~ Days, data = sleepstudy)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -110.848  -27.483    1.546   26.142  139.953 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  251.405      6.610  38.033  &lt; 2e-16 ***
## Days          10.467      1.238   8.454 9.89e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 47.71 on 178 degrees of freedom
## Multiple R-squared:  0.2865, Adjusted R-squared:  0.2825 
## F-statistic: 71.46 on 1 and 178 DF,  p-value: 9.894e-15</code></pre>
<p>This shows the average reaction time on day zero is 251.40 ms, and it lengthens by 10.47 ms each day of the sleep deprivation protocol. Both of these estimates differ from zero. The F test is for the main effect of Days and has an extreme value. Thus, the length of sleep deprivation changes reaction time. This variable accounts for about 28% of the overall variation in the data.</p>
<p>Taken together, we can conclude that a period of sleep deprivation extends reaction times by about 10 ms daily.</p>
<p><span class="math display">\[Reaction=251.4+10.4\times Days\]</span></p>
<p>But we shouldn’t ignore the repeated measures of the design. And it would also be nice to have some estimate for the standard deviation of the effect.</p>
<p>For those reasons we run a mixed model regression to account for the random effect of the 18 subjects.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mm1 &lt;-<span class="st"> </span><span class="kw">lmer</span>(Reaction <span class="op">~</span><span class="st"> </span>Days <span class="op">+</span><span class="st"> </span>(Days<span class="op">|</span>Subject), <span class="dt">REML=</span>F, sleepstudy)

<span class="kw">summary</span>(mm1)</code></pre></div>
<pre><code>## Linear mixed model fit by maximum likelihood  [&#39;lmerMod&#39;]
## Formula: Reaction ~ Days + (Days | Subject)
##    Data: sleepstudy
## 
##      AIC      BIC   logLik deviance df.resid 
##   1763.9   1783.1   -876.0   1751.9      174 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.9416 -0.4656  0.0289  0.4636  5.1793 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr
##  Subject  (Intercept) 565.52   23.781       
##           Days         32.68    5.717   0.08
##  Residual             654.94   25.592       
## Number of obs: 180, groups:  Subject, 18
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  251.405      6.632  37.906
## Days          10.467      1.502   6.968
## 
## Correlation of Fixed Effects:
##      (Intr)
## Days -0.138</code></pre>
<p>The mixed model regression generates the identical estimates for the fixed effects as previously. What we have now that we didn’t have before are standard deviation estimates for both the slope and the intercept coefficients. Those are found in the random effect output in the summary.</p>
<p>So we would conclude that the reaction time is 251.4+/-24.7 ms, which increases with sleep deprivation by 10.47+/-5.92 ms daily.</p>
<p>Unlike linear modeling, linear mixed modeling doesn’t generate F tests. That’s mostly due to the fact that underlying maximum likelihood estimation doesn’t lend itself to that. As far as inference goes, we have t values but not t-tests (the df is missing!!)</p>
</div>
<div id="multiple-regression-of-observational-data" class="section level2">
<h2><span class="header-section-number">38.5</span> Multiple regression of observational data</h2>
<p>The Western Collaborative Group Study data below is epidemiological. The data are derived from cases taken in 1960-61. <a href="http://www.epi.umn.edu/cvdepi/study-synopsis/western-collaborative-group-study/">The focus was to study the relationship between behavior and cardiovascular disease risk in middle aged men</a>. The data set below is comprised of over three thousand cases with 14 variables.</p>
<p>Since I know a little bit about blood pressure, but mostly because blood pressure is a continuous variable, I thought it would be interesting to explore how the various cofactors might influence systolic blood pressure. So I’ll use systolic blood pressure as a response variable in the regressions below. Some of the other variables will be used as predictor variables.</p>
<p>I should make an important point. In practice you don’t just crack open and explore a data set willy nilly. I’m not the PI of the study. I’m just writing another chapter on statistical methods using data to illustrate statistical concepts. The authors of the study were testing the hypothesis that the so-called type-A personality was at higher risk of coronary heart disease. They are bound by restricting their analysis to testing preset hypotheses.</p>
<p>These systolic blood pressure readings are just a variable that were vacuumed up in the study design, but were not hypothesized as the intended response variable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(wcgs)
<span class="kw">head</span>(wcgs)</code></pre></div>
<pre><code>##     id age0 height0 weight0 sbp0 dbp0 chol0 behpat0 ncigs0 dibpat0 chd69
## 1 2001   49      73     150  110   76   225       2     25       1     0
## 2 2002   42      70     160  154   84   177       2     20       1     0
## 3 2003   42      69     160  110   78   181       3      0       0     0
## 4 2004   41      68     152  124   78   132       4     20       0     0
## 5 2005   59      70     150  144   86   255       3     20       0     1
## 6 2006   44      72     204  150   90   182       4      0       0     0
##   typechd time169 arcus0
## 1       0    1664      0
## 2       0    3071      1
## 3       0    3071      0
## 4       0    3064      0
## 5       1    1885      1
## 6       0    3102      0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw">lm</span>(sbp0<span class="op">~</span>age0<span class="op">+</span>height0<span class="op">+</span>weight0<span class="op">+</span>
<span class="st">            </span>chol0<span class="op">+</span>ncigs0<span class="op">+</span>
<span class="st">            </span>dibpat0<span class="op">+</span>chd69, 
          wcgs)
<span class="kw">summary</span>(fit)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sbp0 ~ age0 + height0 + weight0 + chol0 + ncigs0 + 
##     dibpat0 + chd69, data = wcgs)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -36.215  -9.675  -1.969   7.325 101.331 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 122.06552    7.99171  15.274  &lt; 2e-16 ***
## age0          0.40531    0.04625   8.764  &lt; 2e-16 ***
## height0      -0.85157    0.11915  -7.147 1.10e-12 ***
## weight0       0.23450    0.01423  16.477  &lt; 2e-16 ***
## chol0         0.02621    0.00593   4.420 1.02e-05 ***
## ncigs0        0.04247    0.01766   2.404   0.0163 *  
## dibpat0       1.16580    0.50899   2.290   0.0221 *  
## chd69         4.24199    0.94327   4.497 7.14e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 14.06 on 3134 degrees of freedom
##   (12 observations deleted due to missingness)
## Multiple R-squared:  0.1295, Adjusted R-squared:  0.1275 
## F-statistic: 66.59 on 7 and 3134 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The model for systolic blood pressure level, in mmHg predicts <span class="math display">\[sbp=122+0.4/yr-0.85/inch+0.23/pound+0.026/mg/dl+0.04/cig/day+1.16\times typeA+4.24\times coronary event\]</span></p>
<div id="sandbox" class="section level4">
<h4><span class="header-section-number">38.5.0.1</span> Sandbox</h4>
<p>Here’s a simulated sample. The causes of the outcome are known. Only the multiple model predicts the outcome accurately. Knowing what covariates to include in the model is not straightforward.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">123</span>)
covariate &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">1</span>, <span class="dv">100</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>)
exposure  &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">100</span>,<span class="dv">0</span>,<span class="dv">1</span>)<span class="op">+</span>(<span class="fl">0.3</span><span class="op">*</span>covariate)
outcome   &lt;-<span class="st"> </span><span class="fl">2.0</span><span class="op">+</span>(<span class="fl">0.5</span><span class="op">*</span>exposure)<span class="op">+</span>(<span class="fl">0.25</span><span class="op">*</span>covariate)

<span class="kw">lm</span>(outcome<span class="op">~</span>exposure)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = outcome ~ exposure)
## 
## Coefficients:
## (Intercept)     exposure  
##      1.9888       0.6965</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(outcome<span class="op">~</span>exposure<span class="op">+</span>covariate)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = outcome ~ exposure + covariate)
## 
## Coefficients:
## (Intercept)     exposure    covariate  
##        2.00         0.50         0.25</code></pre>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="nonlinearreplicates.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="logregress.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["jabstb.pdf", "jabstb.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
