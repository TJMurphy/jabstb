<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 24 Introduction to ANOVA | JABSTB: Statistical Design and Analysis of Experiments with R</title>
  <meta name="description" content="Experimental biostatistics using R.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 24 Introduction to ANOVA | JABSTB: Statistical Design and Analysis of Experiments with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Experimental biostatistics using R." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 24 Introduction to ANOVA | JABSTB: Statistical Design and Analysis of Experiments with R" />
  
  <meta name="twitter:description" content="Experimental biostatistics using R." />
  

<meta name="author" content="TJ Murphy PhD, Department of Pharmacology and Chemical Biology, School of Medicine, Emory University, Atlanta, GA biostats538@gmail.com">


<meta name="date" content="2019-03-06">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="simcorrelation.html">
<link rel="next" href="fdistr.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">JABSTB</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="author.html"><a href="author.html"><i class="fa fa-check"></i><b>1</b> About the author</a></li>
<li class="chapter" data-level="2" data-path="history.html"><a href="history.html"><i class="fa fa-check"></i><b>2</b> A Brief History of Experimental Design</a></li>
<li class="chapter" data-level="3" data-path="software.html"><a href="software.html"><i class="fa fa-check"></i><b>3</b> Software</a><ul>
<li class="chapter" data-level="3.1" data-path="software.html"><a href="software.html#my-code-is-your-code"><i class="fa fa-check"></i><b>3.1</b> My code is your code</a></li>
<li class="chapter" data-level="3.2" data-path="software.html"><a href="software.html#install-r-and-rstudio"><i class="fa fa-check"></i><b>3.2</b> Install R and RStudio</a></li>
<li class="chapter" data-level="3.3" data-path="software.html"><a href="software.html#getting-started-with-r"><i class="fa fa-check"></i><b>3.3</b> Getting started with R</a></li>
<li class="chapter" data-level="3.4" data-path="software.html"><a href="software.html#other-resources"><i class="fa fa-check"></i><b>3.4</b> Other resources</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="bigpic.html"><a href="bigpic.html"><i class="fa fa-check"></i><b>4</b> The Big Picture</a><ul>
<li class="chapter" data-level="4.1" data-path="bigpic.html"><a href="bigpic.html#what-are-experimental-statistics"><i class="fa fa-check"></i><b>4.1</b> What are experimental statistics?</a><ul>
<li class="chapter" data-level="4.1.1" data-path="bigpic.html"><a href="bigpic.html#descriptive-modeling"><i class="fa fa-check"></i><b>4.1.1</b> Descriptive modeling</a></li>
<li class="chapter" data-level="4.1.2" data-path="bigpic.html"><a href="bigpic.html#statistical-inference"><i class="fa fa-check"></i><b>4.1.2</b> Statistical inference</a></li>
<li class="chapter" data-level="4.1.3" data-path="bigpic.html"><a href="bigpic.html#experimental-design"><i class="fa fa-check"></i><b>4.1.3</b> Experimental design</a></li>
<li class="chapter" data-level="4.1.4" data-path="bigpic.html"><a href="bigpic.html#statistics-as-an-anti-bias-framework"><i class="fa fa-check"></i><b>4.1.4</b> Statistics as an anti-bias framework</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="sampling.html"><a href="sampling.html"><i class="fa fa-check"></i><b>5</b> Statistical Sampling</a><ul>
<li class="chapter" data-level="5.1" data-path="sampling.html"><a href="sampling.html#experimental-units"><i class="fa fa-check"></i><b>5.1</b> Experimental units</a><ul>
<li class="chapter" data-level="5.1.1" data-path="sampling.html"><a href="sampling.html#a-simple-test-to-define-the-experimental-unit"><i class="fa fa-check"></i><b>5.1.1</b> A simple test to define the experimental unit</a></li>
<li class="chapter" data-level="5.1.2" data-path="sampling.html"><a href="sampling.html#blocking"><i class="fa fa-check"></i><b>5.1.2</b> Blocking</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="sampling.html"><a href="sampling.html#independent-replicates"><i class="fa fa-check"></i><b>5.2</b> Independent Replicates</a><ul>
<li class="chapter" data-level="5.2.1" data-path="sampling.html"><a href="sampling.html#a-simple-test-for-independence"><i class="fa fa-check"></i><b>5.2.1</b> A simple test for independence</a></li>
<li class="chapter" data-level="5.2.2" data-path="sampling.html"><a href="sampling.html#some-replication-examples"><i class="fa fa-check"></i><b>5.2.2</b> Some replication examples</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="sampling.html"><a href="sampling.html#random-process"><i class="fa fa-check"></i><b>5.3</b> Random process</a></li>
<li class="chapter" data-level="5.4" data-path="sampling.html"><a href="sampling.html#statistically-valid-samples"><i class="fa fa-check"></i><b>5.4</b> Statistically valid samples</a><ul>
<li class="chapter" data-level="5.4.1" data-path="sampling.html"><a href="sampling.html#select-random-subjects"><i class="fa fa-check"></i><b>5.4.1</b> Select random subjects</a></li>
<li class="chapter" data-level="5.4.2" data-path="sampling.html"><a href="sampling.html#randomize-to-sequence"><i class="fa fa-check"></i><b>5.4.2</b> Randomize to sequence</a></li>
<li class="chapter" data-level="5.4.3" data-path="sampling.html"><a href="sampling.html#randomize-to-location"><i class="fa fa-check"></i><b>5.4.3</b> Randomize to location</a></li>
<li class="chapter" data-level="5.4.4" data-path="sampling.html"><a href="sampling.html#randomize-to-block"><i class="fa fa-check"></i><b>5.4.4</b> Randomize to block</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="sampling.html"><a href="sampling.html#independence-of-replicates"><i class="fa fa-check"></i><b>5.5</b> Independence of replicates</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>6</b> Data Classification</a><ul>
<li class="chapter" data-level="6.1" data-path="data.html"><a href="data.html#dependent-and-independent-variables"><i class="fa fa-check"></i><b>6.1</b> Dependent and independent variables</a><ul>
<li class="chapter" data-level="6.1.1" data-path="data.html"><a href="data.html#when-there-is-no-independent-variable"><i class="fa fa-check"></i><b>6.1.1</b> When there is no independent variable</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="data.html"><a href="data.html#discrete-or-continuous-variables"><i class="fa fa-check"></i><b>6.2</b> Discrete or continuous variables</a><ul>
<li class="chapter" data-level="6.2.1" data-path="data.html"><a href="data.html#measured-variables"><i class="fa fa-check"></i><b>6.2.1</b> Measured variables</a></li>
<li class="chapter" data-level="6.2.2" data-path="data.html"><a href="data.html#discrete-categorical-and-ordinal-variables"><i class="fa fa-check"></i><b>6.2.2</b> Discrete categorical and ordinal variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="dispersion.html"><a href="dispersion.html"><i class="fa fa-check"></i><b>7</b> Variability, Accuracy and Precision</a><ul>
<li class="chapter" data-level="7.1" data-path="dispersion.html"><a href="dispersion.html#variance-quantifying-variation-by-least-squares"><i class="fa fa-check"></i><b>7.1</b> Variance: Quantifying variation by least squares</a></li>
<li class="chapter" data-level="7.2" data-path="dispersion.html"><a href="dispersion.html#standard-deviation"><i class="fa fa-check"></i><b>7.2</b> Standard deviation</a><ul>
<li class="chapter" data-level="7.2.1" data-path="dispersion.html"><a href="dispersion.html#what-does-the-standard-deviation-tell-us"><i class="fa fa-check"></i><b>7.2.1</b> What does the standard deviation tell us</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="dispersion.html"><a href="dispersion.html#other-ways-of-describing-variability"><i class="fa fa-check"></i><b>7.3</b> Other ways of describing variability</a></li>
<li class="chapter" data-level="7.4" data-path="dispersion.html"><a href="dispersion.html#precision-and-accuracy"><i class="fa fa-check"></i><b>7.4</b> Precision and Accuracy</a></li>
<li class="chapter" data-level="7.5" data-path="dispersion.html"><a href="dispersion.html#standard-error"><i class="fa fa-check"></i><b>7.5</b> Standard error</a><ul>
<li class="chapter" data-level="7.5.1" data-path="dispersion.html"><a href="dispersion.html#what-exactly-does-the-standard-error-represent"><i class="fa fa-check"></i><b>7.5.1</b> What exactly does the standard error represent?</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="dispersion.html"><a href="dispersion.html#confidence-intervals"><i class="fa fa-check"></i><b>7.6</b> Confidence intervals</a><ul>
<li class="chapter" data-level="7.6.1" data-path="dispersion.html"><a href="dispersion.html#simulations"><i class="fa fa-check"></i><b>7.6.1</b> Simulations</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="dispersion.html"><a href="dispersion.html#key-take-aways"><i class="fa fa-check"></i><b>7.7</b> Key take aways</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="hypotheses.html"><a href="hypotheses.html"><i class="fa fa-check"></i><b>8</b> Framing statistical hypotheses</a><ul>
<li class="chapter" data-level="8.1" data-path="hypotheses.html"><a href="hypotheses.html#the-decision-process"><i class="fa fa-check"></i><b>8.1</b> The decision process</a></li>
<li class="chapter" data-level="8.2" data-path="hypotheses.html"><a href="hypotheses.html#popper-and-falsification"><i class="fa fa-check"></i><b>8.2</b> Popper and falsification</a></li>
<li class="chapter" data-level="8.3" data-path="hypotheses.html"><a href="hypotheses.html#statistical-hypothesis-rubric"><i class="fa fa-check"></i><b>8.3</b> Statistical hypothesis rubric</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="error.html"><a href="error.html"><i class="fa fa-check"></i><b>9</b> Error</a><ul>
<li class="chapter" data-level="9.1" data-path="error.html"><a href="error.html#setting-type-1-and-type-2-error-thresholds"><i class="fa fa-check"></i><b>9.1</b> Setting type 1 and type 2 error thresholds</a><ul>
<li class="chapter" data-level="9.1.1" data-path="error.html"><a href="error.html#setting-alpha-the-type-1-error"><i class="fa fa-check"></i><b>9.1.1</b> Setting alpha-the type 1 error</a></li>
<li class="chapter" data-level="9.1.2" data-path="error.html"><a href="error.html#power-setting-beta-the-type-2-error"><i class="fa fa-check"></i><b>9.1.2</b> Power: Setting beta-the type 2 error</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="error.html"><a href="error.html#striking-the-right-balance"><i class="fa fa-check"></i><b>9.2</b> Striking the right balance</a></li>
<li class="chapter" data-level="9.3" data-path="error.html"><a href="error.html#false-discovery-rate"><i class="fa fa-check"></i><b>9.3</b> False discovery rate</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="pvalues.html"><a href="pvalues.html"><i class="fa fa-check"></i><b>10</b> P Values</a><ul>
<li class="chapter" data-level="10.1" data-path="pvalues.html"><a href="pvalues.html#how-p-values-are-calculated"><i class="fa fa-check"></i><b>10.1</b> How p-values are calculated</a></li>
<li class="chapter" data-level="10.2" data-path="pvalues.html"><a href="pvalues.html#how-p-values-should-be-interpreted"><i class="fa fa-check"></i><b>10.2</b> How p-values should be interpreted</a></li>
<li class="chapter" data-level="10.3" data-path="pvalues.html"><a href="pvalues.html#interpretation"><i class="fa fa-check"></i><b>10.3</b> Interpretation</a></li>
<li class="chapter" data-level="10.4" data-path="pvalues.html"><a href="pvalues.html#criticisms-of-p-values"><i class="fa fa-check"></i><b>10.4</b> Criticisms of p-values</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="jaxwest7.html"><a href="jaxwest7.html"><i class="fa fa-check"></i><b>11</b> Reproducible Data Munging in R</a><ul>
<li class="chapter" data-level="11.1" data-path="jaxwest7.html"><a href="jaxwest7.html#jaxwest7-glucose-data"><i class="fa fa-check"></i><b>11.1</b> Jaxwest7 glucose data</a><ul>
<li class="chapter" data-level="11.1.1" data-path="jaxwest7.html"><a href="jaxwest7.html#inspect-the-jaxwest7-data"><i class="fa fa-check"></i><b>11.1.1</b> Inspect the Jaxwest7 data</a></li>
<li class="chapter" data-level="11.1.2" data-path="jaxwest7.html"><a href="jaxwest7.html#munge-the-glucose-concentration-data-into-r"><i class="fa fa-check"></i><b>11.1.2</b> Munge the glucose concentration data into R</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="jaxwest7.html"><a href="jaxwest7.html#explore-the-jaxwest7-data"><i class="fa fa-check"></i><b>11.2</b> Explore the Jaxwest7 data</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="binomial.html"><a href="binomial.html"><i class="fa fa-check"></i><b>12</b> The Binomial Distribution</a><ul>
<li class="chapter" data-level="12.1" data-path="binomial.html"><a href="binomial.html#dbinom"><i class="fa fa-check"></i><b>12.1</b> dbinom</a></li>
<li class="chapter" data-level="12.2" data-path="binomial.html"><a href="binomial.html#pbinom"><i class="fa fa-check"></i><b>12.2</b> pbinom</a></li>
<li class="chapter" data-level="12.3" data-path="binomial.html"><a href="binomial.html#qbinom"><i class="fa fa-check"></i><b>12.3</b> qbinom</a></li>
<li class="chapter" data-level="12.4" data-path="binomial.html"><a href="binomial.html#rbinom"><i class="fa fa-check"></i><b>12.4</b> rbinom</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="poisson.html"><a href="poisson.html"><i class="fa fa-check"></i><b>13</b> The Poisson Distribution</a><ul>
<li class="chapter" data-level="13.1" data-path="poisson.html"><a href="poisson.html#poisson-events"><i class="fa fa-check"></i><b>13.1</b> Poisson Events</a></li>
<li class="chapter" data-level="13.2" data-path="poisson.html"><a href="poisson.html#dpois"><i class="fa fa-check"></i><b>13.2</b> dpois</a></li>
<li class="chapter" data-level="13.3" data-path="poisson.html"><a href="poisson.html#ppois"><i class="fa fa-check"></i><b>13.3</b> ppois</a></li>
<li class="chapter" data-level="13.4" data-path="poisson.html"><a href="poisson.html#rpois"><i class="fa fa-check"></i><b>13.4</b> rpois</a></li>
<li class="chapter" data-level="13.5" data-path="poisson.html"><a href="poisson.html#overdispersion"><i class="fa fa-check"></i><b>13.5</b> Overdispersion</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="normal.html"><a href="normal.html"><i class="fa fa-check"></i><b>14</b> The Normal Distribution</a><ul>
<li class="chapter" data-level="14.0.1" data-path="normal.html"><a href="normal.html#the-standard-normal"><i class="fa fa-check"></i><b>14.0.1</b> The Standard Normal</a></li>
<li class="chapter" data-level="14.1" data-path="normal.html"><a href="normal.html#dnorm"><i class="fa fa-check"></i><b>14.1</b> dnorm</a></li>
<li class="chapter" data-level="14.2" data-path="normal.html"><a href="normal.html#pnorm"><i class="fa fa-check"></i><b>14.2</b> pnorm</a><ul>
<li class="chapter" data-level="" data-path="normal.html"><a href="normal.html#calculating-p-values-using-pnorm"><i class="fa fa-check"></i>Calculating “p-values”&quot; using pnorm</a></li>
<li class="chapter" data-level="" data-path="normal.html"><a href="normal.html#calculating-percentiles-using-pnorm"><i class="fa fa-check"></i>Calculating percentiles using pnorm</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="normal.html"><a href="normal.html#qnorm"><i class="fa fa-check"></i><b>14.3</b> qnorm</a></li>
<li class="chapter" data-level="14.4" data-path="normal.html"><a href="normal.html#rnorm"><i class="fa fa-check"></i><b>14.4</b> rnorm</a><ul>
<li class="chapter" data-level="14.4.1" data-path="normal.html"><a href="normal.html#plotting-histograms-of-some-rnorm-samples"><i class="fa fa-check"></i><b>14.4.1</b> Plotting histograms of some rnorm samples</a></li>
<li class="chapter" data-level="14.4.2" data-path="normal.html"><a href="normal.html#bins-and-binwidth"><i class="fa fa-check"></i><b>14.4.2</b> Bins and Binwidth</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="categorical.html"><a href="categorical.html"><i class="fa fa-check"></i><b>15</b> Statistics for Categorical Data</a><ul>
<li class="chapter" data-level="15.1" data-path="categorical.html"><a href="categorical.html#types-of-categorical-data"><i class="fa fa-check"></i><b>15.1</b> Types of categorical data</a><ul>
<li class="chapter" data-level="15.1.1" data-path="categorical.html"><a href="categorical.html#proportions"><i class="fa fa-check"></i><b>15.1.1</b> Proportions</a></li>
<li class="chapter" data-level="15.1.2" data-path="categorical.html"><a href="categorical.html#frequencies"><i class="fa fa-check"></i><b>15.1.2</b> Frequencies</a></li>
<li class="chapter" data-level="15.1.3" data-path="categorical.html"><a href="categorical.html#associations"><i class="fa fa-check"></i><b>15.1.3</b> Associations</a></li>
<li class="chapter" data-level="15.1.4" data-path="categorical.html"><a href="categorical.html#statistics-covered-here"><i class="fa fa-check"></i><b>15.1.4</b> Statistics Covered Here</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="categorical.html"><a href="categorical.html#exact-v-asymptotic-calculations-of-p-values"><i class="fa fa-check"></i><b>15.2</b> Exact v Asymptotic Calculations of p-values</a><ul>
<li class="chapter" data-level="15.2.1" data-path="categorical.html"><a href="categorical.html#choosing-exact-or-asymptotic"><i class="fa fa-check"></i><b>15.2.1</b> Choosing exact or asymptotic</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="categorical.html"><a href="categorical.html#overview-of-the-types-of-hypothesis-testing"><i class="fa fa-check"></i><b>15.3</b> Overview of the types of hypothesis testing</a><ul>
<li class="chapter" data-level="15.3.1" data-path="categorical.html"><a href="categorical.html#proportion-analysis"><i class="fa fa-check"></i><b>15.3.1</b> Proportion analysis</a></li>
<li class="chapter" data-level="15.3.2" data-path="categorical.html"><a href="categorical.html#goodness-of-fit-testing"><i class="fa fa-check"></i><b>15.3.2</b> Goodness of fit testing</a></li>
<li class="chapter" data-level="15.3.3" data-path="categorical.html"><a href="categorical.html#contingency-analysis"><i class="fa fa-check"></i><b>15.3.3</b> Contingency Analysis</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="categorical.html"><a href="categorical.html#comparing-proportions"><i class="fa fa-check"></i><b>15.4</b> Comparing proportions</a><ul>
<li class="chapter" data-level="15.4.1" data-path="categorical.html"><a href="categorical.html#a-mouse-t-cell-pilot-experiment-the-cytokine-inducible-antigen-gradstudin"><i class="fa fa-check"></i><b>15.4.1</b> A Mouse T Cell Pilot Experiment: The Cytokine-inducible antigen gradstudin</a></li>
<li class="chapter" data-level="15.4.2" data-path="categorical.html"><a href="categorical.html#calculating-proportions"><i class="fa fa-check"></i><b>15.4.2</b> Calculating Proportions</a></li>
<li class="chapter" data-level="15.4.3" data-path="categorical.html"><a href="categorical.html#what-a-proportion-estimates"><i class="fa fa-check"></i><b>15.4.3</b> What A Proportion Estimates</a></li>
<li class="chapter" data-level="15.4.4" data-path="categorical.html"><a href="categorical.html#confidence-intervals-of-proportions"><i class="fa fa-check"></i><b>15.4.4</b> Confidence Intervals of Proportions</a></li>
<li class="chapter" data-level="15.4.5" data-path="categorical.html"><a href="categorical.html#a-one-sample-proportion-test"><i class="fa fa-check"></i><b>15.4.5</b> A One-Sample Proportion Test</a></li>
<li class="chapter" data-level="15.4.6" data-path="categorical.html"><a href="categorical.html#comparing-two-proportions"><i class="fa fa-check"></i><b>15.4.6</b> Comparing Two Proportions</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="categorical.html"><a href="categorical.html#exact-tests-for-two-proportions"><i class="fa fa-check"></i><b>15.5</b> Exact tests for two proportions</a></li>
<li class="chapter" data-level="15.6" data-path="categorical.html"><a href="categorical.html#goodness-of-fit-tests"><i class="fa fa-check"></i><b>15.6</b> Goodness of fit Tests</a><ul>
<li class="chapter" data-level="15.6.1" data-path="categorical.html"><a href="categorical.html#an-exact-goodness-of-fit-test"><i class="fa fa-check"></i><b>15.6.1</b> An Exact Goodness of Fit test</a></li>
<li class="chapter" data-level="15.6.2" data-path="categorical.html"><a href="categorical.html#an-approximate-goodness-of-fit-test"><i class="fa fa-check"></i><b>15.6.2</b> An Approximate Goodness of Fit test</a></li>
</ul></li>
<li class="chapter" data-level="15.7" data-path="categorical.html"><a href="categorical.html#contingency-testing"><i class="fa fa-check"></i><b>15.7</b> Contingency Testing</a><ul>
<li class="chapter" data-level="15.7.1" data-path="categorical.html"><a href="categorical.html#intepretation-of-contingency-results"><i class="fa fa-check"></i><b>15.7.1</b> Intepretation of Contingency Results</a></li>
<li class="chapter" data-level="15.7.2" data-path="categorical.html"><a href="categorical.html#write-up-3"><i class="fa fa-check"></i><b>15.7.2</b> Write Up</a></li>
<li class="chapter" data-level="15.7.3" data-path="categorical.html"><a href="categorical.html#interpretation-of-chi-square-output"><i class="fa fa-check"></i><b>15.7.3</b> Interpretation of chi-square output</a></li>
<li class="chapter" data-level="15.7.4" data-path="categorical.html"><a href="categorical.html#write-up-4"><i class="fa fa-check"></i><b>15.7.4</b> Write Up</a></li>
<li class="chapter" data-level="15.7.5" data-path="categorical.html"><a href="categorical.html#which-contingency-test-is-best"><i class="fa fa-check"></i><b>15.7.5</b> Which contingency test is best?</a></li>
<li class="chapter" data-level="15.7.6" data-path="categorical.html"><a href="categorical.html#higher-dimension-contingency-analysis"><i class="fa fa-check"></i><b>15.7.6</b> Higher dimension contingency analysis</a></li>
<li class="chapter" data-level="15.7.7" data-path="categorical.html"><a href="categorical.html#other-experimental-designs-involving-categorical-data"><i class="fa fa-check"></i><b>15.7.7</b> Other experimental designs involving categorical data</a></li>
</ul></li>
<li class="chapter" data-level="15.8" data-path="categorical.html"><a href="categorical.html#doing-a-priori-power-analysis-for-proportion-tests"><i class="fa fa-check"></i><b>15.8</b> Doing <em>a priori</em> power analysis for proportion tests</a></li>
<li class="chapter" data-level="15.9" data-path="categorical.html"><a href="categorical.html#power-analysis-functions-for-proportion-tests"><i class="fa fa-check"></i><b>15.9</b> Power analysis functions for proportion tests</a></li>
<li class="chapter" data-level="15.10" data-path="categorical.html"><a href="categorical.html#graphing-proportions"><i class="fa fa-check"></i><b>15.10</b> Graphing Proportions</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="chisquare.html"><a href="chisquare.html"><i class="fa fa-check"></i><b>16</b> The Chi-square Distribution</a><ul>
<li class="chapter" data-level="16.1" data-path="chisquare.html"><a href="chisquare.html#background"><i class="fa fa-check"></i><b>16.1</b> Background</a></li>
<li class="chapter" data-level="16.2" data-path="chisquare.html"><a href="chisquare.html#dchisq"><i class="fa fa-check"></i><b>16.2</b> dchisq</a></li>
<li class="chapter" data-level="16.3" data-path="chisquare.html"><a href="chisquare.html#pchisq"><i class="fa fa-check"></i><b>16.3</b> pchisq</a><ul>
<li class="chapter" data-level="16.3.1" data-path="chisquare.html"><a href="chisquare.html#calculating-p-values-from-pchisq"><i class="fa fa-check"></i><b>16.3.1</b> Calculating p-values from pchisq</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="chisquare.html"><a href="chisquare.html#qchisq"><i class="fa fa-check"></i><b>16.4</b> qchisq</a></li>
<li class="chapter" data-level="16.5" data-path="chisquare.html"><a href="chisquare.html#rchisq"><i class="fa fa-check"></i><b>16.5</b> rchisq</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="nonparametrics.html"><a href="nonparametrics.html"><i class="fa fa-check"></i><b>17</b> Nonparametric Statistical Tests</a><ul>
<li class="chapter" data-level="17.1" data-path="nonparametrics.html"><a href="nonparametrics.html#experiments-involving-discrete-data"><i class="fa fa-check"></i><b>17.1</b> Experiments involving discrete data</a></li>
<li class="chapter" data-level="17.2" data-path="nonparametrics.html"><a href="nonparametrics.html#deviant-data"><i class="fa fa-check"></i><b>17.2</b> Deviant Data</a></li>
<li class="chapter" data-level="17.3" data-path="nonparametrics.html"><a href="nonparametrics.html#sign-test"><i class="fa fa-check"></i><b>17.3</b> Sign Test</a><ul>
<li class="chapter" data-level="17.3.1" data-path="nonparametrics.html"><a href="nonparametrics.html#interpretation-1"><i class="fa fa-check"></i><b>17.3.1</b> Interpretation</a></li>
<li class="chapter" data-level="17.3.2" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-5"><i class="fa fa-check"></i><b>17.3.2</b> Write Up</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="nonparametrics.html"><a href="nonparametrics.html#wilcoxon-sign-rank-test-for-one-group"><i class="fa fa-check"></i><b>17.4</b> Wilcoxon Sign Rank Test for One Group</a><ul>
<li class="chapter" data-level="17.4.1" data-path="nonparametrics.html"><a href="nonparametrics.html#wilcoxon-sign-rank-experimental-designs"><i class="fa fa-check"></i><b>17.4.1</b> Wilcoxon Sign Rank Experimental Designs</a></li>
<li class="chapter" data-level="17.4.2" data-path="nonparametrics.html"><a href="nonparametrics.html#interpretation-2"><i class="fa fa-check"></i><b>17.4.2</b> Interpretation</a></li>
<li class="chapter" data-level="17.4.3" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-6"><i class="fa fa-check"></i><b>17.4.3</b> Write Up</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="nonparametrics.html"><a href="nonparametrics.html#wilcoxon-mann-whitney-rank-sum-test-for-2-independent-groups"><i class="fa fa-check"></i><b>17.5</b> Wilcoxon Mann Whitney Rank Sum Test for 2 independent groups</a><ul>
<li class="chapter" data-level="17.5.1" data-path="nonparametrics.html"><a href="nonparametrics.html#interpretation-3"><i class="fa fa-check"></i><b>17.5.1</b> Interpretation</a></li>
<li class="chapter" data-level="17.5.2" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-7"><i class="fa fa-check"></i><b>17.5.2</b> Write Up</a></li>
</ul></li>
<li class="chapter" data-level="17.6" data-path="nonparametrics.html"><a href="nonparametrics.html#wilcoxon-sign-rank-test-for-paired-groups"><i class="fa fa-check"></i><b>17.6</b> Wilcoxon Sign Rank Test for paired groups</a><ul>
<li class="chapter" data-level="17.6.1" data-path="nonparametrics.html"><a href="nonparametrics.html#interpretation-4"><i class="fa fa-check"></i><b>17.6.1</b> Interpretation</a></li>
<li class="chapter" data-level="17.6.2" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-8"><i class="fa fa-check"></i><b>17.6.2</b> Write up</a></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="nonparametrics.html"><a href="nonparametrics.html#kruskal-wallis"><i class="fa fa-check"></i><b>17.7</b> Kruskal-Wallis</a><ul>
<li class="chapter" data-level="17.7.1" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-9"><i class="fa fa-check"></i><b>17.7.1</b> Write Up</a></li>
</ul></li>
<li class="chapter" data-level="17.8" data-path="nonparametrics.html"><a href="nonparametrics.html#friedman-test"><i class="fa fa-check"></i><b>17.8</b> Friedman test</a></li>
<li class="chapter" data-level="17.9" data-path="nonparametrics.html"><a href="nonparametrics.html#nonparametric-power-calculations"><i class="fa fa-check"></i><b>17.9</b> Nonparametric power calculations</a><ul>
<li class="chapter" data-level="17.9.1" data-path="nonparametrics.html"><a href="nonparametrics.html#how-it-works"><i class="fa fa-check"></i><b>17.9.1</b> How it works</a></li>
<li class="chapter" data-level="17.9.2" data-path="nonparametrics.html"><a href="nonparametrics.html#initialization-with-population-parameters"><i class="fa fa-check"></i><b>17.9.2</b> Initialization with population parameters</a></li>
<li class="chapter" data-level="17.9.3" data-path="nonparametrics.html"><a href="nonparametrics.html#an-example"><i class="fa fa-check"></i><b>17.9.3</b> An example</a></li>
<li class="chapter" data-level="17.9.4" data-path="nonparametrics.html"><a href="nonparametrics.html#nonpara.pwr"><i class="fa fa-check"></i><b>17.9.4</b> nonpara.pwr</a></li>
</ul></li>
<li class="chapter" data-level="17.10" data-path="nonparametrics.html"><a href="nonparametrics.html#summary"><i class="fa fa-check"></i><b>17.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="signrank.html"><a href="signrank.html"><i class="fa fa-check"></i><b>18</b> Signed Rank Distribution</a><ul>
<li class="chapter" data-level="18.1" data-path="signrank.html"><a href="signrank.html#transformation-of-data-into-sign-ranks"><i class="fa fa-check"></i><b>18.1</b> Transformation of data into sign ranks</a><ul>
<li class="chapter" data-level="18.1.1" data-path="signrank.html"><a href="signrank.html#for-a-one-group-sample"><i class="fa fa-check"></i><b>18.1.1</b> For a one group sample</a></li>
<li class="chapter" data-level="18.1.2" data-path="signrank.html"><a href="signrank.html#for-a-paired-sample"><i class="fa fa-check"></i><b>18.1.2</b> For a paired sample</a></li>
<li class="chapter" data-level="18.1.3" data-path="signrank.html"><a href="signrank.html#the-sign-rank-test-statistic-in-r"><i class="fa fa-check"></i><b>18.1.3</b> The sign rank test statistic in R</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="signrank.html"><a href="signrank.html#rs-four-sign-rank-distribution-functions"><i class="fa fa-check"></i><b>18.2</b> R’s Four Sign Rank Distribution Functions</a><ul>
<li class="chapter" data-level="18.2.1" data-path="signrank.html"><a href="signrank.html#dsignrank"><i class="fa fa-check"></i><b>18.2.1</b> dsignrank</a></li>
<li class="chapter" data-level="18.2.2" data-path="signrank.html"><a href="signrank.html#psignrank"><i class="fa fa-check"></i><b>18.2.2</b> psignrank</a></li>
<li class="chapter" data-level="18.2.3" data-path="signrank.html"><a href="signrank.html#qsignrank"><i class="fa fa-check"></i><b>18.2.3</b> qsignrank</a></li>
<li class="chapter" data-level="18.2.4" data-path="signrank.html"><a href="signrank.html#rsignrank"><i class="fa fa-check"></i><b>18.2.4</b> rsignrank</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="ranksum.html"><a href="ranksum.html"><i class="fa fa-check"></i><b>19</b> Rank Sum Distribution</a><ul>
<li class="chapter" data-level="19.0.1" data-path="ranksum.html"><a href="ranksum.html#transformation-of-data-into-rank-summs"><i class="fa fa-check"></i><b>19.0.1</b> Transformation of data into rank summs</a></li>
<li class="chapter" data-level="19.0.2" data-path="ranksum.html"><a href="ranksum.html#the-sign-rank-test-statistic-in-r-1"><i class="fa fa-check"></i><b>19.0.2</b> The sign rank test statistic in R</a></li>
<li class="chapter" data-level="19.1" data-path="ranksum.html"><a href="ranksum.html#rs-four-sign-rank-distribution-functions-1"><i class="fa fa-check"></i><b>19.1</b> R’s Four Sign Rank Distribution Functions</a><ul>
<li class="chapter" data-level="19.1.1" data-path="ranksum.html"><a href="ranksum.html#dwilcox"><i class="fa fa-check"></i><b>19.1.1</b> dwilcox</a></li>
<li class="chapter" data-level="19.1.2" data-path="ranksum.html"><a href="ranksum.html#pwilcox"><i class="fa fa-check"></i><b>19.1.2</b> pwilcox</a></li>
<li class="chapter" data-level="19.1.3" data-path="ranksum.html"><a href="ranksum.html#qwilcox"><i class="fa fa-check"></i><b>19.1.3</b> qwilcox</a></li>
<li class="chapter" data-level="19.1.4" data-path="ranksum.html"><a href="ranksum.html#rwilcox"><i class="fa fa-check"></i><b>19.1.4</b> rwilcox</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="ttests.html"><a href="ttests.html"><i class="fa fa-check"></i><b>20</b> The t-tests</a><ul>
<li class="chapter" data-level="20.1" data-path="ttests.html"><a href="ttests.html#data-assumptions-for-t-tests"><i class="fa fa-check"></i><b>20.1</b> Data assumptions for t-tests</a></li>
<li class="chapter" data-level="20.2" data-path="ttests.html"><a href="ttests.html#the-t-statistic"><i class="fa fa-check"></i><b>20.2</b> The t Statistic</a><ul>
<li class="chapter" data-level="20.2.1" data-path="ttests.html"><a href="ttests.html#one-sample-t-tests"><i class="fa fa-check"></i><b>20.2.1</b> One sample t tests</a></li>
<li class="chapter" data-level="20.2.2" data-path="ttests.html"><a href="ttests.html#unpaired-t-tests"><i class="fa fa-check"></i><b>20.2.2</b> Unpaired t tests</a></li>
<li class="chapter" data-level="20.2.3" data-path="ttests.html"><a href="ttests.html#paired-t-tests"><i class="fa fa-check"></i><b>20.2.3</b> Paired t tests</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="ttests.html"><a href="ttests.html#t-test-hypotheses"><i class="fa fa-check"></i><b>20.3</b> t Test Hypotheses</a><ul>
<li class="chapter" data-level="20.3.1" data-path="ttests.html"><a href="ttests.html#one-sample-hypotheses"><i class="fa fa-check"></i><b>20.3.1</b> One sample hypotheses</a></li>
<li class="chapter" data-level="20.3.2" data-path="ttests.html"><a href="ttests.html#unpaired-hypotheses"><i class="fa fa-check"></i><b>20.3.2</b> Unpaired hypotheses</a></li>
<li class="chapter" data-level="20.3.3" data-path="ttests.html"><a href="ttests.html#paired-hypotheses"><i class="fa fa-check"></i><b>20.3.3</b> Paired hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="ttests.html"><a href="ttests.html#confidence-intervals-of-means"><i class="fa fa-check"></i><b>20.4</b> Confidence Intervals of Means</a></li>
<li class="chapter" data-level="20.5" data-path="ttests.html"><a href="ttests.html#t-tests-running-the-analysis"><i class="fa fa-check"></i><b>20.5</b> t Tests: Running the analysis</a><ul>
<li class="chapter" data-level="20.5.1" data-path="ttests.html"><a href="ttests.html#one-sample-t-test"><i class="fa fa-check"></i><b>20.5.1</b> One sample t test</a></li>
<li class="chapter" data-level="20.5.2" data-path="ttests.html"><a href="ttests.html#unpaired-t-test"><i class="fa fa-check"></i><b>20.5.2</b> Unpaired t test</a></li>
<li class="chapter" data-level="20.5.3" data-path="ttests.html"><a href="ttests.html#paired-t-test"><i class="fa fa-check"></i><b>20.5.3</b> Paired t Test</a></li>
</ul></li>
<li class="chapter" data-level="20.6" data-path="ttests.html"><a href="ttests.html#plotting-t-tests"><i class="fa fa-check"></i><b>20.6</b> Plotting t Tests</a><ul>
<li class="chapter" data-level="20.6.1" data-path="ttests.html"><a href="ttests.html#unpaired"><i class="fa fa-check"></i><b>20.6.1</b> Unpaired</a></li>
<li class="chapter" data-level="20.6.2" data-path="ttests.html"><a href="ttests.html#paired"><i class="fa fa-check"></i><b>20.6.2</b> Paired</a></li>
</ul></li>
<li class="chapter" data-level="20.7" data-path="ttests.html"><a href="ttests.html#t-test-power"><i class="fa fa-check"></i><b>20.7</b> t Test Power</a><ul>
<li class="chapter" data-level="20.7.1" data-path="ttests.html"><a href="ttests.html#interpretation-7"><i class="fa fa-check"></i><b>20.7.1</b> Interpretation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="ttestmc.html"><a href="ttestmc.html"><i class="fa fa-check"></i><b>21</b> Statistical design of t-tests</a><ul>
<li class="chapter" data-level="21.1" data-path="ttestmc.html"><a href="ttestmc.html#about-this-chapter"><i class="fa fa-check"></i><b>21.1</b> About this chapter</a><ul>
<li class="chapter" data-level="21.1.1" data-path="ttestmc.html"><a href="ttestmc.html#scenario"><i class="fa fa-check"></i><b>21.1.1</b> Scenario</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="ttestmc.html"><a href="ttestmc.html#one-sample-t-test-monte-carlo"><i class="fa fa-check"></i><b>21.2</b> One sample t-test Monte Carlo</a></li>
<li class="chapter" data-level="21.3" data-path="ttestmc.html"><a href="ttestmc.html#unpaired-t-test-monte-carlo"><i class="fa fa-check"></i><b>21.3</b> Unpaired t-test Monte Carlo</a></li>
<li class="chapter" data-level="21.4" data-path="ttestmc.html"><a href="ttestmc.html#paired-t-test-monte-carlo"><i class="fa fa-check"></i><b>21.4</b> Paired t-test Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="tdist.html"><a href="tdist.html"><i class="fa fa-check"></i><b>22</b> t Distributions</a><ul>
<li class="chapter" data-level="22.1" data-path="tdist.html"><a href="tdist.html#dt"><i class="fa fa-check"></i><b>22.1</b> dt</a></li>
<li class="chapter" data-level="22.2" data-path="tdist.html"><a href="tdist.html#pt"><i class="fa fa-check"></i><b>22.2</b> pt</a></li>
<li class="chapter" data-level="22.3" data-path="tdist.html"><a href="tdist.html#qt"><i class="fa fa-check"></i><b>22.3</b> qt</a></li>
<li class="chapter" data-level="22.4" data-path="tdist.html"><a href="tdist.html#rt"><i class="fa fa-check"></i><b>22.4</b> rt</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="simcorrelation.html"><a href="simcorrelation.html"><i class="fa fa-check"></i><b>23</b> Simulating correlated variables</a><ul>
<li class="chapter" data-level="23.1" data-path="simcorrelation.html"><a href="simcorrelation.html#estimating-correlation-between-two-variables"><i class="fa fa-check"></i><b>23.1</b> Estimating correlation between two variables</a></li>
<li class="chapter" data-level="23.2" data-path="simcorrelation.html"><a href="simcorrelation.html#simulating-correlated-variables"><i class="fa fa-check"></i><b>23.2</b> Simulating correlated variables</a></li>
<li class="chapter" data-level="23.3" data-path="simcorrelation.html"><a href="simcorrelation.html#monte-carlo-simulation"><i class="fa fa-check"></i><b>23.3</b> Monte Carlo simulation</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="introanova.html"><a href="introanova.html"><i class="fa fa-check"></i><b>24</b> Introduction to ANOVA</a><ul>
<li class="chapter" data-level="24.1" data-path="introanova.html"><a href="introanova.html#factors-and-levels"><i class="fa fa-check"></i><b>24.1</b> Factors and levels</a></li>
<li class="chapter" data-level="24.2" data-path="introanova.html"><a href="introanova.html#anova-models-one--two--and-three-way"><i class="fa fa-check"></i><b>24.2</b> ANOVA models: One-, Two-, and Three-way</a></li>
<li class="chapter" data-level="24.3" data-path="introanova.html"><a href="introanova.html#anova-inference-protocol"><i class="fa fa-check"></i><b>24.3</b> ANOVA inference protocol</a></li>
<li class="chapter" data-level="24.4" data-path="introanova.html"><a href="introanova.html#anova-calculations"><i class="fa fa-check"></i><b>24.4</b> ANOVA calculations</a><ul>
<li class="chapter" data-level="24.4.1" data-path="introanova.html"><a href="introanova.html#sums-of-squares-partitioning"><i class="fa fa-check"></i><b>24.4.1</b> Sums of Squares partitioning</a></li>
<li class="chapter" data-level="24.4.2" data-path="introanova.html"><a href="introanova.html#degrees-of-freedom"><i class="fa fa-check"></i><b>24.4.2</b> Degrees of freedom</a></li>
<li class="chapter" data-level="24.4.3" data-path="introanova.html"><a href="introanova.html#the-mean-squares"><i class="fa fa-check"></i><b>24.4.3</b> The mean squares</a></li>
<li class="chapter" data-level="24.4.4" data-path="introanova.html"><a href="introanova.html#the-anova-table"><i class="fa fa-check"></i><b>24.4.4</b> The ANOVA table</a></li>
<li class="chapter" data-level="24.4.5" data-path="introanova.html"><a href="introanova.html#the-f-test"><i class="fa fa-check"></i><b>24.4.5</b> The F-test</a></li>
<li class="chapter" data-level="24.4.6" data-path="introanova.html"><a href="introanova.html#post-hoc-group-comparisons"><i class="fa fa-check"></i><b>24.4.6</b> Post-hoc group comparisons</a></li>
</ul></li>
<li class="chapter" data-level="24.5" data-path="introanova.html"><a href="introanova.html#completely-randomized-or-related-measures"><i class="fa fa-check"></i><b>24.5</b> Completely randomized or related measures</a><ul>
<li class="chapter" data-level="24.5.1" data-path="introanova.html"><a href="introanova.html#the-problem-of-lost-data-in-related-measures-designs"><i class="fa fa-check"></i><b>24.5.1</b> The problem of lost data in related measures designs</a></li>
</ul></li>
<li class="chapter" data-level="24.6" data-path="introanova.html"><a href="introanova.html#two-way-anova"><i class="fa fa-check"></i><b>24.6</b> Two-way ANOVA</a></li>
<li class="chapter" data-level="24.7" data-path="introanova.html"><a href="introanova.html#other-anova-models"><i class="fa fa-check"></i><b>24.7</b> Other ANOVA models</a><ul>
<li class="chapter" data-level="24.7.1" data-path="introanova.html"><a href="introanova.html#r-and-anova"><i class="fa fa-check"></i><b>24.7.1</b> R and ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="24.8" data-path="introanova.html"><a href="introanova.html#alternatives-to-anova"><i class="fa fa-check"></i><b>24.8</b> Alternatives to ANOVA</a><ul>
<li class="chapter" data-level="24.8.1" data-path="introanova.html"><a href="introanova.html#screw-anova-just-tell-me-how-to-t-test-everything"><i class="fa fa-check"></i><b>24.8.1</b> Screw ANOVA, Just Tell Me How to t-Test Everything</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="fdistr.html"><a href="fdistr.html"><i class="fa fa-check"></i><b>25</b> The F distribution</a><ul>
<li class="chapter" data-level="25.1" data-path="fdistr.html"><a href="fdistr.html#background-1"><i class="fa fa-check"></i><b>25.1</b> Background</a><ul>
<li class="chapter" data-level="25.1.1" data-path="fdistr.html"><a href="fdistr.html#sample-variance-and-fs-pdf"><i class="fa fa-check"></i><b>25.1.1</b> Sample Variance and F’s PDF</a></li>
</ul></li>
<li class="chapter" data-level="25.2" data-path="fdistr.html"><a href="fdistr.html#df"><i class="fa fa-check"></i><b>25.2</b> df</a></li>
<li class="chapter" data-level="25.3" data-path="fdistr.html"><a href="fdistr.html#pf"><i class="fa fa-check"></i><b>25.3</b> pf</a></li>
<li class="chapter" data-level="25.4" data-path="fdistr.html"><a href="fdistr.html#qf"><i class="fa fa-check"></i><b>25.4</b> qf</a></li>
<li class="chapter" data-level="25.5" data-path="fdistr.html"><a href="fdistr.html#rf"><i class="fa fa-check"></i><b>25.5</b> rf</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="onewayanova.html"><a href="onewayanova.html"><i class="fa fa-check"></i><b>26</b> One-way ANOVA Completely Randomized</a><ul>
<li class="chapter" data-level="26.1" data-path="onewayanova.html"><a href="onewayanova.html#using-ezanova"><i class="fa fa-check"></i><b>26.1</b> Using <code>ezANOVA</code></a></li>
<li class="chapter" data-level="26.2" data-path="onewayanova.html"><a href="onewayanova.html#the-chickwt-data-set"><i class="fa fa-check"></i><b>26.2</b> The chickwt data set</a><ul>
<li class="chapter" data-level="26.2.1" data-path="onewayanova.html"><a href="onewayanova.html#inspect-the-data"><i class="fa fa-check"></i><b>26.2.1</b> Inspect the data</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="onewayanova.html"><a href="onewayanova.html#run-the-anova"><i class="fa fa-check"></i><b>26.3</b> Run the ANOVA</a><ul>
<li class="chapter" data-level="26.3.1" data-path="onewayanova.html"><a href="onewayanova.html#run-the-chickwts-one-way-anova"><i class="fa fa-check"></i><b>26.3.1</b> Run the chickwts One Way ANOVA</a></li>
<li class="chapter" data-level="26.3.2" data-path="onewayanova.html"><a href="onewayanova.html#interpreting-the-one-way-cr-anova-output"><i class="fa fa-check"></i><b>26.3.2</b> Interpreting the One-Way CR ANOVA Output</a></li>
</ul></li>
<li class="chapter" data-level="26.4" data-path="onewayanova.html"><a href="onewayanova.html#posthoc"><i class="fa fa-check"></i><b>26.4</b> Post hoc pairwise comparisons</a><ul>
<li class="chapter" data-level="26.4.1" data-path="onewayanova.html"><a href="onewayanova.html#overview-of-options"><i class="fa fa-check"></i><b>26.4.1</b> Overview of options</a></li>
</ul></li>
<li class="chapter" data-level="26.5" data-path="onewayanova.html"><a href="onewayanova.html#reporting-the-result"><i class="fa fa-check"></i><b>26.5</b> Reporting the result</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="onewayRM.html"><a href="onewayRM.html"><i class="fa fa-check"></i><b>27</b> One-way ANOVA Related Measures</a><ul>
<li class="chapter" data-level="27.1" data-path="onewayRM.html"><a href="onewayRM.html#data-prep"><i class="fa fa-check"></i><b>27.1</b> Data prep</a></li>
<li class="chapter" data-level="27.2" data-path="onewayRM.html"><a href="onewayRM.html#run-the-anova-1"><i class="fa fa-check"></i><b>27.2</b> Run the ANOVA</a></li>
<li class="chapter" data-level="27.3" data-path="onewayRM.html"><a href="onewayRM.html#interpretation-8"><i class="fa fa-check"></i><b>27.3</b> Interpretation</a></li>
<li class="chapter" data-level="27.4" data-path="onewayRM.html"><a href="onewayRM.html#post-hoc-analysis"><i class="fa fa-check"></i><b>27.4</b> Post-hoc analysis</a></li>
<li class="chapter" data-level="27.5" data-path="onewayRM.html"><a href="onewayRM.html#write-up-10"><i class="fa fa-check"></i><b>27.5</b> Write up</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="twowayCR.html"><a href="twowayCR.html"><i class="fa fa-check"></i><b>28</b> Two-way ANOVA Completely Randomized</a><ul>
<li class="chapter" data-level="28.1" data-path="twowayCR.html"><a href="twowayCR.html#effect-of-strain-and-diet-on-liver"><i class="fa fa-check"></i><b>28.1</b> Effect of Strain and Diet on Liver</a></li>
<li class="chapter" data-level="28.2" data-path="twowayCR.html"><a href="twowayCR.html#the-test"><i class="fa fa-check"></i><b>28.2</b> The test</a></li>
<li class="chapter" data-level="28.3" data-path="twowayCR.html"><a href="twowayCR.html#interpretation-of-2-way-cr-anova-output"><i class="fa fa-check"></i><b>28.3</b> Interpretation of 2 Way CR ANOVA Output</a><ul>
<li class="chapter" data-level="28.3.1" data-path="twowayCR.html"><a href="twowayCR.html#levenes"><i class="fa fa-check"></i><b>28.3.1</b> Levene’s</a></li>
<li class="chapter" data-level="28.3.2" data-path="twowayCR.html"><a href="twowayCR.html#anova-table"><i class="fa fa-check"></i><b>28.3.2</b> ANOVA Table</a></li>
</ul></li>
<li class="chapter" data-level="28.4" data-path="twowayCR.html"><a href="twowayCR.html#post-hoc-multiple-comparisons"><i class="fa fa-check"></i><b>28.4</b> Post Hoc Multiple Comparisons</a><ul>
<li class="chapter" data-level="28.4.1" data-path="twowayCR.html"><a href="twowayCR.html#write-up-11"><i class="fa fa-check"></i><b>28.4.1</b> Write Up</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path="twowayRM.html"><a href="twowayRM.html"><i class="fa fa-check"></i><b>29</b> Two-way ANOVA Related Measures</a><ul>
<li class="chapter" data-level="29.1" data-path="twowayRM.html"><a href="twowayRM.html#cell-culture"><i class="fa fa-check"></i><b>29.1</b> Cell culture</a></li>
<li class="chapter" data-level="29.2" data-path="twowayRM.html"><a href="twowayRM.html#the-test-1"><i class="fa fa-check"></i><b>29.2</b> The test</a></li>
<li class="chapter" data-level="29.3" data-path="twowayRM.html"><a href="twowayRM.html#interpretation-of-the-output"><i class="fa fa-check"></i><b>29.3</b> Interpretation of the output</a><ul>
<li class="chapter" data-level="29.3.1" data-path="twowayRM.html"><a href="twowayRM.html#anova-table-1"><i class="fa fa-check"></i><b>29.3.1</b> ANOVA Table</a></li>
<li class="chapter" data-level="29.3.2" data-path="twowayRM.html"><a href="twowayRM.html#mauchlys-sphericity-test"><i class="fa fa-check"></i><b>29.3.2</b> Mauchly’s Sphericity Test</a></li>
</ul></li>
<li class="chapter" data-level="29.4" data-path="twowayRM.html"><a href="twowayRM.html#post-hoc-multiple-comparisons-1"><i class="fa fa-check"></i><b>29.4</b> Post Hoc multiple comparisons</a></li>
<li class="chapter" data-level="29.5" data-path="twowayRM.html"><a href="twowayRM.html#write-up-12"><i class="fa fa-check"></i><b>29.5</b> Write Up</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="twowaymixed.html"><a href="twowaymixed.html"><i class="fa fa-check"></i><b>30</b> Two-way ANOVA RM/CR</a><ul>
<li class="chapter" data-level="30.1" data-path="twowaymixed.html"><a href="twowaymixed.html#chickweight-dataset"><i class="fa fa-check"></i><b>30.1</b> ChickWeight Dataset</a></li>
<li class="chapter" data-level="30.2" data-path="twowaymixed.html"><a href="twowaymixed.html#munge-chickweight-data"><i class="fa fa-check"></i><b>30.2</b> Munge ChickWeight data</a></li>
<li class="chapter" data-level="30.3" data-path="twowaymixed.html"><a href="twowaymixed.html#the-test-2"><i class="fa fa-check"></i><b>30.3</b> The test</a></li>
<li class="chapter" data-level="30.4" data-path="twowaymixed.html"><a href="twowaymixed.html#interpreting-the-anova-output"><i class="fa fa-check"></i><b>30.4</b> Interpreting the ANOVA output</a><ul>
<li class="chapter" data-level="30.4.1" data-path="twowaymixed.html"><a href="twowaymixed.html#anova-the-anova-table-1"><i class="fa fa-check"></i><b>30.4.1</b> $ANOVA: The ANOVA table</a></li>
<li class="chapter" data-level="30.4.2" data-path="twowaymixed.html"><a href="twowaymixed.html#mauchlys-test-and-corrections"><i class="fa fa-check"></i><b>30.4.2</b> Mauchly’s Test and Corrections</a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path="twowaymixed.html"><a href="twowaymixed.html#post-hoc-pairwise-tests"><i class="fa fa-check"></i><b>30.5</b> Post hoc pairwise tests</a><ul>
<li class="chapter" data-level="30.5.1" data-path="twowaymixed.html"><a href="twowaymixed.html#heres-whats-been-discovered"><i class="fa fa-check"></i><b>30.5.1</b> Here’s what’s been discovered</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="31" data-path="jaxwest2.html"><a href="jaxwest2.html"><i class="fa fa-check"></i><b>31</b> Reproducible Data Munging Mostly with Tidyverse</a><ul>
<li class="chapter" data-level="31.1" data-path="jaxwest2.html"><a href="jaxwest2.html#look-at-the-original-data-carefully"><i class="fa fa-check"></i><b>31.1</b> Look at the original data carefully</a></li>
<li class="chapter" data-level="31.2" data-path="jaxwest2.html"><a href="jaxwest2.html#our-goal"><i class="fa fa-check"></i><b>31.2</b> Our goal</a></li>
<li class="chapter" data-level="31.3" data-path="jaxwest2.html"><a href="jaxwest2.html#read-the-data-into-r"><i class="fa fa-check"></i><b>31.3</b> Read the data into R</a></li>
<li class="chapter" data-level="31.4" data-path="jaxwest2.html"><a href="jaxwest2.html#select-the-variables"><i class="fa fa-check"></i><b>31.4</b> Select the variables</a></li>
<li class="chapter" data-level="31.5" data-path="jaxwest2.html"><a href="jaxwest2.html#trim-the-cases"><i class="fa fa-check"></i><b>31.5</b> Trim the cases</a></li>
<li class="chapter" data-level="31.6" data-path="jaxwest2.html"><a href="jaxwest2.html#go-long"><i class="fa fa-check"></i><b>31.6</b> Go long</a></li>
<li class="chapter" data-level="31.7" data-path="jaxwest2.html"><a href="jaxwest2.html#pull-out-the-values-for-the-day-variable"><i class="fa fa-check"></i><b>31.7</b> Pull out the values for the day variable</a></li>
<li class="chapter" data-level="31.8" data-path="jaxwest2.html"><a href="jaxwest2.html#convert-day-to-numeric"><i class="fa fa-check"></i><b>31.8</b> Convert day to numeric</a></li>
<li class="chapter" data-level="31.9" data-path="jaxwest2.html"><a href="jaxwest2.html#convert-tumor_vol-to-numeric"><i class="fa fa-check"></i><b>31.9</b> Convert tumor_vol to numeric</a></li>
<li class="chapter" data-level="31.10" data-path="jaxwest2.html"><a href="jaxwest2.html#deal-with-that-na"><i class="fa fa-check"></i><b>31.10</b> Deal with that NA</a></li>
<li class="chapter" data-level="31.11" data-path="jaxwest2.html"><a href="jaxwest2.html#convert-variables-to-factor"><i class="fa fa-check"></i><b>31.11</b> Convert variables to factor</a></li>
<li class="chapter" data-level="31.12" data-path="jaxwest2.html"><a href="jaxwest2.html#plot-the-data"><i class="fa fa-check"></i><b>31.12</b> Plot the data</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="anovamc.html"><a href="anovamc.html"><i class="fa fa-check"></i><b>32</b> ANOVA power using Monte Carlo</a><ul>
<li class="chapter" data-level="32.1" data-path="anovamc.html"><a href="anovamc.html#what-is-monte-carlo"><i class="fa fa-check"></i><b>32.1</b> What is Monte Carlo</a></li>
<li class="chapter" data-level="32.2" data-path="anovamc.html"><a href="anovamc.html#one-way-completely-randomized-anova-monte-carlo"><i class="fa fa-check"></i><b>32.2</b> One-way completely randomized ANOVA Monte Carlo</a><ul>
<li class="chapter" data-level="32.2.1" data-path="anovamc.html"><a href="anovamc.html#directions"><i class="fa fa-check"></i><b>32.2.1</b> Directions</a></li>
<li class="chapter" data-level="32.2.2" data-path="anovamc.html"><a href="anovamc.html#step-1-create-initial-values"><i class="fa fa-check"></i><b>32.2.2</b> Step 1: Create initial values</a></li>
<li class="chapter" data-level="32.2.3" data-path="anovamc.html"><a href="anovamc.html#step-2-visualize-one-random-sample"><i class="fa fa-check"></i><b>32.2.3</b> Step 2: Visualize one random sample</a></li>
<li class="chapter" data-level="32.2.4" data-path="anovamc.html"><a href="anovamc.html#step-3-run-the-power-simulator"><i class="fa fa-check"></i><b>32.2.4</b> Step 3: Run The Power Simulator</a></li>
<li class="chapter" data-level="32.2.5" data-path="anovamc.html"><a href="anovamc.html#step-4-optimize-for-suitable-power"><i class="fa fa-check"></i><b>32.2.5</b> Step 4: Optimize for suitable power</a></li>
<li class="chapter" data-level="32.2.6" data-path="anovamc.html"><a href="anovamc.html#notes-and-considerations"><i class="fa fa-check"></i><b>32.2.6</b> Notes And Considerations</a></li>
</ul></li>
<li class="chapter" data-level="32.3" data-path="anovamc.html"><a href="anovamc.html#one-way-related-measures-anova-monte-carlo"><i class="fa fa-check"></i><b>32.3</b> One-way related measures ANOVA Monte Carlo</a></li>
<li class="chapter" data-level="32.4" data-path="anovamc.html"><a href="anovamc.html#directions-1"><i class="fa fa-check"></i><b>32.4</b> Directions</a><ul>
<li class="chapter" data-level="32.4.1" data-path="anovamc.html"><a href="anovamc.html#step-1-initial-values"><i class="fa fa-check"></i><b>32.4.1</b> Step 1: Initial values</a></li>
<li class="chapter" data-level="32.4.2" data-path="anovamc.html"><a href="anovamc.html#step-2-visualize-one-sample"><i class="fa fa-check"></i><b>32.4.2</b> Step 2: Visualize one sample</a></li>
<li class="chapter" data-level="32.4.3" data-path="anovamc.html"><a href="anovamc.html#step-3-run-the-power-simulator-1"><i class="fa fa-check"></i><b>32.4.3</b> Step 3: Run the power simulator</a></li>
<li class="chapter" data-level="32.4.4" data-path="anovamc.html"><a href="anovamc.html#step-4-should-anything-be-changed"><i class="fa fa-check"></i><b>32.4.4</b> Step 4: Should anything be changed?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="33" data-path="correl.html"><a href="correl.html"><i class="fa fa-check"></i><b>33</b> Correlation</a><ul>
<li class="chapter" data-level="33.1" data-path="correl.html"><a href="correl.html#correlation-causation"><i class="fa fa-check"></i><b>33.1</b> Correlation != Causation</a></li>
<li class="chapter" data-level="33.2" data-path="correl.html"><a href="correl.html#correlation-in-multivariate-outcomes-and-paired-designs"><i class="fa fa-check"></i><b>33.2</b> Correlation in Multivariate Outcomes and Paired Designs</a></li>
<li class="chapter" data-level="33.3" data-path="correl.html"><a href="correl.html#correlation-coefficients"><i class="fa fa-check"></i><b>33.3</b> Correlation coefficients</a><ul>
<li class="chapter" data-level="33.3.1" data-path="correl.html"><a href="correl.html#pearsons-correlation-coefficient"><i class="fa fa-check"></i><b>33.3.1</b> Pearson’s correlation coefficient</a></li>
<li class="chapter" data-level="33.3.2" data-path="correl.html"><a href="correl.html#spearmans-rank-correlation"><i class="fa fa-check"></i><b>33.3.2</b> Spearman’s rank correlation</a></li>
<li class="chapter" data-level="33.3.3" data-path="correl.html"><a href="correl.html#kendalls-tau"><i class="fa fa-check"></i><b>33.3.3</b> Kendall’s tau</a></li>
<li class="chapter" data-level="33.3.4" data-path="correl.html"><a href="correl.html#which-correlation-method-to-use"><i class="fa fa-check"></i><b>33.3.4</b> Which correlation method to use?</a></li>
<li class="chapter" data-level="33.3.5" data-path="correl.html"><a href="correl.html#r-correlation-analysis-functions"><i class="fa fa-check"></i><b>33.3.5</b> R correlation analysis functions</a></li>
<li class="chapter" data-level="33.3.6" data-path="correl.html"><a href="correl.html#plot-the-correlations"><i class="fa fa-check"></i><b>33.3.6</b> Plot the correlations</a></li>
<li class="chapter" data-level="33.3.7" data-path="correl.html"><a href="correl.html#calculate-a-correlation-coefficient-and-posthoc-test"><i class="fa fa-check"></i><b>33.3.7</b> Calculate a correlation coefficient and posthoc test</a></li>
<li class="chapter" data-level="33.3.8" data-path="correl.html"><a href="correl.html#interpretation-of-correlation-output"><i class="fa fa-check"></i><b>33.3.8</b> Interpretation of correlation output</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="34" data-path="regress.html"><a href="regress.html"><i class="fa fa-check"></i><b>34</b> Linear Regression</a><ul>
<li class="chapter" data-level="34.1" data-path="regress.html"><a href="regress.html#the-linear-regression-model"><i class="fa fa-check"></i><b>34.1</b> The linear regression model</a></li>
<li class="chapter" data-level="34.2" data-path="regress.html"><a href="regress.html#least-squares-fitting"><i class="fa fa-check"></i><b>34.2</b> Least squares fitting</a></li>
<li class="chapter" data-level="34.3" data-path="regress.html"><a href="regress.html#the-practical-importance-of-linear-model-parameters"><i class="fa fa-check"></i><b>34.3</b> The practical importance of linear model parameters</a></li>
<li class="chapter" data-level="34.4" data-path="regress.html"><a href="regress.html#linear-model-standard-errors"><i class="fa fa-check"></i><b>34.4</b> Linear model standard errors</a></li>
<li class="chapter" data-level="34.5" data-path="regress.html"><a href="regress.html#linear-regression-in-r"><i class="fa fa-check"></i><b>34.5</b> Linear regression in R</a></li>
<li class="chapter" data-level="34.6" data-path="regress.html"><a href="regress.html#intepretation-1"><i class="fa fa-check"></i><b>34.6</b> Intepretation</a><ul>
<li class="chapter" data-level="34.6.1" data-path="regress.html"><a href="regress.html#residuals"><i class="fa fa-check"></i><b>34.6.1</b> Residuals</a></li>
<li class="chapter" data-level="34.6.2" data-path="regress.html"><a href="regress.html#coefficients"><i class="fa fa-check"></i><b>34.6.2</b> Coefficients</a></li>
<li class="chapter" data-level="34.6.3" data-path="regress.html"><a href="regress.html#degrees-of-freedom-1"><i class="fa fa-check"></i><b>34.6.3</b> Degrees of freedom</a></li>
<li class="chapter" data-level="34.6.4" data-path="regress.html"><a href="regress.html#r-squared"><i class="fa fa-check"></i><b>34.6.4</b> R-squared</a></li>
<li class="chapter" data-level="34.6.5" data-path="regress.html"><a href="regress.html#f-statistic"><i class="fa fa-check"></i><b>34.6.5</b> F-statistic</a></li>
<li class="chapter" data-level="34.6.6" data-path="regress.html"><a href="regress.html#plotting-regression-results"><i class="fa fa-check"></i><b>34.6.6</b> Plotting regression results</a></li>
<li class="chapter" data-level="34.6.7" data-path="regress.html"><a href="regress.html#visualizing-residuals"><i class="fa fa-check"></i><b>34.6.7</b> Visualizing residuals</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">JABSTB: Statistical Design and Analysis of Experiments with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introanova" class="section level1">
<h1><span class="header-section-number">Chapter 24</span> Introduction to ANOVA</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(RColorBrewer)</code></pre></div>
<p>The choice of any statistical design and analysis is always driven by the type of outcome and predictor variables involved. Recall that all variables are either continuous or discrete. Furthermore, it’s helpful to think of outcome variables further classified as either <a href="data.html#data">measured, ordered or sorted</a>, where measured variables are continuous, and ordered and sorted are discrete.</p>
<p>Once the dependent variable is deemed to be continuous measured, the experimental design model is determined by the number of explanatory groups involved. If the grouping factor is discrete, use t-tests with two or fewer.</p>
<div class="figure"><span id="fig:unnamed-chunk-233"></span>
<img src="images/anova_heuristic.jpg" alt="ANOVA heuristic"  />
<p class="caption">
Figure 24.1: ANOVA heuristic
</p>
</div>
<p>The analysis of variance (ANOVA) is a method to design and evaluate experiments in which the predictor variable(s) are discrete factors for three or more groups and when the outcome variable is on some continuous measured scale. ANOVA is also univariate, in so far as the analysis involves only a single outcome variable.</p>
<p>The validity of an ANOVA depends upon fulfilling the following assumptions: * Every replicate is independent of all others. * Some random process is used when generating measurements, * The distribution from which the outcome variable is derived is continuous random normal. * The variances of the groups are approximately equal.</p>
<p>When the first two of these assumptions cannot be met, it’s a scientific experience, not an experiment designed for unbiased hypotheses testing. There is no need pretend otherwise by performing statistical testing. In that case, just report descriptive statistics while omitting inference (ie, don’t do p-values).</p>
<p>On the basis of small samples it usually difficult to conclude that the 3rd and 4th assumptions are met. Both affirmative and negative results of tests of normality, tests for homogeneity of variance and outlier tests should be taken with a grain of salt. The smaller the sample size, the larger the grain of salt. Use your judgment. Do you have any reason to believe the variable is not normally distributed? Are you confident the variable being measured in a linear range? If a truly normally distributed variable is measured in the linear range, you can be reasonably confident that you are satisfying these assumptions.</p>
<p>Data that appears skewed can be transformed using log or reciprocal functions, followed by ANOVA testing on those transformed values.</p>
<p>There are alternative analytic options as will be detailed below. In particular, there is no need to use ANOVA for discrete types of outcome data. ANOVA is not designed to analyze such data. Additionally, regression, either linear or nonlinear, is often a preferred method of analysis when the predictor variable is continuous rather than discrete.</p>
<p>ANOVA represents a family of about a dozen or so statistical tests. These differ by how many predictor factors are involved and whether or not the measurements are intrinsically-related such that replicates are completely randomized or repeated/related.</p>
<p>ANOVA experiments tend to design themselves since they are fairly intuitive way of asking questions. In fact, ANOVA is probably the most widely used experimental design in the biomedical sciences. If you go to any article in your favorite journal randomly, chances are it will have a figure or table depicting an ANOVA design, which would look something like these.</p>
<div class="figure"><span id="fig:unnamed-chunk-234"></span>
<img src="jabstb_files/figure-html/unnamed-chunk-234-1.png" alt="Typical graphs depicting some of the different ANOVA designs." width="480" /><img src="jabstb_files/figure-html/unnamed-chunk-234-2.png" alt="Typical graphs depicting some of the different ANOVA designs." width="480" /><img src="jabstb_files/figure-html/unnamed-chunk-234-3.png" alt="Typical graphs depicting some of the different ANOVA designs." width="480" />
<p class="caption">
Figure 24.2: Typical graphs depicting some of the different ANOVA designs.
</p>
</div>
<p>The reasons why ANOVA is so popular are very simple.</p>
<p>First, ANOVA is versatile. ANOVA allows for testing many groups simultaneously, for one or more factors, each at several levels. You can test for the main effect of each factor, or for interactions between factors. You can also test for differences between specific individual groups, using post hoc analysis. Repeated/related designs are readily accommodated, including mixed designs where one factor is completely randomized and another is related measure within a single multi-factor experiments.</p>
<p>Second, ANOVA is efficient. Fewer experimental units are needed to make the same number of pairwise group comparisons than would otherwise be necessary using a t-test-based experimental design. That efficiency can improve modestly as the number of groups increases.</p>
<p>As you know, each individual hypothesis test carries a risk of type1 error. In one sense, ANOVA serves as a protocol to detect differences between many groups while ensuring that the overall type1 error, the so-called experimentwise error, remains fixed at the same tolerable threshold we’d set for a single t-test between two groups.</p>
<div id="factors-and-levels" class="section level2">
<h2><span class="header-section-number">24.1</span> Factors and levels</h2>
<p>In ANOVA jargon, predictor variables are classified as “factors”. ANOVA designs are said to be factorial. They are multifactorial if more than a single factor is involved. In other corners, ANOVA is referred to as factorial analysis (which should not be confused with factor analysis). Where some people describe an ANOVA experiment as a “one-way ANOVA” others might describe it as “one-factor ANOVA”. It’s all the same.</p>
<p>The factors of ANOVA represent categorical, discrete variables that are each applied at two or more levels. For example, a factor at three levels is a predictor variable that has three discrete values and those three groups in the experiment.</p>
<p>Imagine an experiment to explore how a particular gene influences blood glucose levels. Blood glucose levels, a continuous response variable, are measured in experimental units comprising a total of three different genotypes: wild-type, heterozygous knockouts of that gene, and homozygous knockouts of the gene. Here, genotype is a discrete predictor variable, a factor, which has three levels.</p>
<p>To run functions related to ANOVA, R requires that your predictor variables are classified as factors in data sets.</p>
<p>The following script creates a vector object called <code>genotype</code>. The object is a representation of the genotype variable. The data class for that vector is <code>character</code> because it is comprised of character strings. But look what happens when it is packaged into a data frame called <code>my.factors</code>. R coerces <code>genotype</code> into a factor variable with 3 levels. Which is nice.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">genotype &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;wild-type&quot;</span>, <span class="st">&quot;heterozygote&quot;</span>, <span class="st">&quot;homozygote&quot;</span>)
<span class="kw">class</span>(genotype)</code></pre></div>
<pre><code>## [1] &quot;character&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">my.factors &lt;-<span class="st"> </span><span class="kw">data.frame</span>(genotype)
<span class="kw">str</span>(my.factors)</code></pre></div>
<pre><code>## &#39;data.frame&#39;:    3 obs. of  1 variable:
##  $ genotype: Factor w/ 3 levels &quot;heterozygote&quot;,..: 3 1 2</code></pre>
<p>In contrast, this coercion won’t occur if a factor in an experiment represents a variable with continuous scale values. To illustrate what I mean by this, imagine adding a factor to the genotype experiment. We would test for the effect of an antidiabetic drug on blood glucose at 0, 10 and 30 microgram/kg. These effects would be measured at each level of the genotype factor.</p>
<p>We would create the vector <code>drug</code> as an object representing the drug variable and its three levels as follows. Note however that here, R does not coerce numeric values as factors:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">drug &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">30</span>)
my.factors &lt;-<span class="st"> </span><span class="kw">data.frame</span>(genotype, drug)
<span class="kw">str</span>(my.factors)</code></pre></div>
<pre><code>## &#39;data.frame&#39;:    3 obs. of  2 variables:
##  $ genotype: Factor w/ 3 levels &quot;heterozygote&quot;,..: 3 1 2
##  $ drug    : num  0 10 30</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">class</span>(drug)</code></pre></div>
<pre><code>## [1] &quot;numeric&quot;</code></pre>
<p>That’s easily fixed using the <code>as.factor</code> function</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">drug &lt;-<span class="st"> </span><span class="kw">as.factor</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">30</span>))
my.factors &lt;-<span class="st"> </span><span class="kw">data.frame</span>(genotype, drug)
<span class="kw">str</span>(my.factors)</code></pre></div>
<pre><code>## &#39;data.frame&#39;:    3 obs. of  2 variables:
##  $ genotype: Factor w/ 3 levels &quot;heterozygote&quot;,..: 3 1 2
##  $ drug    : Factor w/ 3 levels &quot;0&quot;,&quot;10&quot;,&quot;30&quot;: 1 2 3</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">class</span>(drug)</code></pre></div>
<pre><code>## [1] &quot;factor&quot;</code></pre>
<p>Alternately, we would enter the drug levels as character strings, which would be coerced into a factor at two levels when added to a data frame, like for the first example above:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">drug &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;zero&quot;</span>, <span class="st">&quot;ten&quot;</span>, <span class="st">&quot;thirty&quot;</span>)</code></pre></div>
<p>I bring this up to point out that you can do ANOVA with continuous predictor variables. You just have to treat them as factors.</p>
<p>When a continuous predictor variable is used at many levels (eg, a time series, a dose series, etc), regression <em>per se</em> may can be a better alternative to ANOVA. Regression allows for capturing that additional information encoded within continuous variables.</p>
<p>But that decision is more scientific than it is statistical. For example, you would use regression rather than ANOVA if the goal is to derive regression parameter estimates, such as slopes for rates or affinity constants. Only use ANOVA when the goal is to determine whether the factor has any effect at all, or if it interacts with some other factor.</p>
<p>Be aware that R will bark out error messages at you ff you use continuous variables as factors without actually converting them to factor class objects.</p>
</div>
<div id="anova-models-one--two--and-three-way" class="section level2">
<h2><span class="header-section-number">24.2</span> ANOVA models: One-, Two-, and Three-way</h2>
<p>If an experiment has only one factor, it a one-way ANOVA design (alternately, “one-factor ANOVA”). If an experiment has two factors, it is a two-way ANOVA or two factor design. Three factors? Three-way ANOVA. These models can also be either completely randomized, repeated/related measures, or mixed.</p>
<p>In a completely randomized structure, every level of the factor(s) is randomly assigned to replicates. Every replicate measurement is independent from all others.</p>
<p>In a related measures structure, measurements within an experimental unit are intrinsically-linked. Every replicate receives <em>all</em> levels of a factor (eg, before-after, stepped dosing, or when subjects are highly homogeneous, such as cultured cells or inbred animals).</p>
<p>Thus, the possible ANOVA models are quite diverse:</p>
<ul>
<li>One-way ANOVA -completely randomized</li>
<li>One-way ANOVA -related measures</li>
<li>Two-way ANOVA -completely randomized on both factors</li>
<li>Two-way ANOVA -related measures on both factors</li>
<li>Two-way ANOVA -mixed, one factor completely randomized, the other factor related measures</li>
<li>Three-way ANOVA -can be CR, RM or mixed,</li>
</ul>
<p>I should mention that ANOVA for even more than three factors is conceptually possible. However, you are strongly cautioned such large, complex designs have considerable downside.</p>
<p>Three-way ANOVA, for example, allows for such a large number of hypotheses to be tested (three different main effects and four possible interaction effects, not to mention the large number of post hoc group comparisons) that it can be difficult to conclude what is responsible for any observed effects. These larger designs also tend to break the efficiency rule, it’s fair to say that three way ANOVA designs tend to be over-ambitious experiments…over-designed and usually under powered for the large number of hypotheses they can test.</p>
<p>Designing an experiment as completely randomized or related measures is largely a scientific, not a statistical, decision. What that means is this: measurements are either intrinsically-linked or they are not. Making that determination is a scientific call, based upon the nature of the biological material that you are working with. When you’ve concluded measurements are intrinsically-linked, then the choice must be a related measures design and analysis.</p>
<p>Similarly, choosing to run experiments as one-way or two-way ANOVA designs is also scientific. In fact, you would choose the latter mostly to test whether two factors interact. If you are uninterested in whether two factors interact, don’t combine them in an experiment. You might wish to ask your questions using separate one-way ANOVAs, instead.</p>
<p>We’ll discuss interaction hypotheses and effects in more detail later.</p>
</div>
<div id="anova-inference-protocol" class="section level2">
<h2><span class="header-section-number">24.3</span> ANOVA inference protocol</h2>
<p>ANOVA can be used inferentially as stand alone test, or as an omnibus test. The test statistic for ANOVA is the F-test, which will be described below.</p>
<p>A positive F-test result can be used to infer whether a factor, or an interaction between factors, is effective.</p>
<p>Given the example above, I can use positive F-test to conclude that genotype at a given locus influences blood glucose. And just leave it at that, without demonstrating which conditions differ from each other.</p>
<p>Alternately, a positive F-test result can be used as an omnibus. Here, a positive F-test implies that at least two group means differ from each other. The positive F-test grants access to explore which group means differ from each other. This is done by making pairwise group comparisons.</p>
<p>The decision to use the F-test as a stand alone or as an omnibus is driven by your scientific objectives.</p>
<div class="figure"><span id="fig:unnamed-chunk-239"></span>
<img src="images/anova_process.jpg" alt="ANOVA work flow"  />
<p class="caption">
Figure 24.3: ANOVA work flow
</p>
</div>
<p>These “post hoc” pairwise comparisons are, essentially, any of several variations on the t-test designed to adjust p-values on the basis of the multiple comparisons.</p>
<p>The choices of groups to compare after the F-test are driven by scientific, rather than statistical, reasoning. You can compare all groups to each other, or you can compare a much more limited subset of groups.</p>
<p>What is important, statistically, is to make adjustments to the p-value threshold given all the comparisons made, so that the experimentwise type1 error does not exceed your declared threshold (usually 5%).</p>
<p>In an experiment whose number of groups equals <span class="math inline">\(k\)</span>, there are a total of <span class="math inline">\(\frac{k(k-1)}{2}\)</span> possible comparisons to make.</p>
<p>Let’s use the simplest case of a <span class="math inline">\(k=3\)</span> groups ANOVA as an example. There are <span class="math inline">\(C=\frac{3(3-1)}{2}=3\)</span> comparisons that can be made. Using the Bonferroni correction (<span class="math inline">\(p_{adjust}=\frac{0.05}{C}=0.01667\)</span>), only comparisons between 2 groups whose p &lt; 0.0167 would test as different from each other.</p>
</div>
<div id="anova-calculations" class="section level2">
<h2><span class="header-section-number">24.4</span> ANOVA calculations</h2>
<p>The simplest way to think about ANOVA is that it operates like a variance budgeting tool. In the final analysis, the higher the ratio of the variance associated with the grouping factor(s) compared to the residual variance, the more likely that some group means will differ.</p>
<p>ANOVA uses the least squares method to derive and account for sources of variation within a data set.</p>
<p>Recall that the variance of a random variable <span class="math inline">\(Y\)</span> is estimated through sampling, and calculated by dividing the sum of its squared deviates, <span class="math inline">\(SS\)</span>, by the sample degrees of freedom (df).</p>
<p><span class="math display">\[var(Y)=\frac{\sum_{i=1}^n(y_i-\bar y)^2}{n-1}=\frac{SS}{df}=MS\]</span></p>
<p>In ANOVA jargon the variance is also commonly referred to as the mean square <span class="math inline">\(MS\)</span>, illustrating that variance can be thought of as an averaged deviate.</p>
<p>Now, that formula only illustrates how variance is calculated for a single sample group. What about multiple groups? As you might imagine, we have to incorporate information from all of the groups.</p>
<p>To begin to understand that, recognize that all ANOVAs, irrespective of the specific design have two fundamental sources of variation:</p>
<ol style="list-style-type: decimal">
<li>Variation due to the experimental model, which is specified by the nature of the predictor variables.</li>
<li>Residual variation, which is variation that cannot be explained by predictor variables.</li>
</ol>
<p>A useful property of sums of squared deviates is that the total variation within an experiment, whether due to known or known sources, can be accounted for.</p>
<p>That total variation within an experiment can be expressed as the sum of the squared deviates, and it is the sum of the squared deviates for the model and residual components: <span class="math display">\[SS_{total}=SS_{model}+SS_{residual} \]</span></p>
<p>Perhaps it helps if you first think about this visually.</p>
<p>Let’s imagine a simple one-way completely randomized ANOVA data set that looks like the graph below. There is only one factor, at three levels. Each group has five independent replicates, for a total of 15 replicates within the entire experiment.</p>
<p>We would express the model for this experiment as <span class="math display">\[SS_{model}=SS_{genotype} \]</span></p>
<p>and thus <span class="math display">\[SS_{total}=SS_{genotype}+SS_{residual} \]</span></p>
<p>The graph illustrates each data point, the means for each group (black bars) and the grand mean of the sample (gold bars). You can readily imagine the distances from the data points to the group means and to the grand means. You can also appreciate and the distances from the group means to the grand mean. You probably have a harder time visualizing the squares of those distances. My mind sees it Euclidean (geometrically). Larger distances, squared, lead to bigger boxes! The bigger the boxes, the greater that replicate contributes to the variance.</p>
<p>With that picture in mind, think of the variances within the experiment as follows:</p>
<ul>
<li>Total variance: average squared distances of the all the points to the grand mean</li>
<li>Model variance: weighted average squared distances of group means to the grand mean</li>
<li>Residual variance: average squared distances of the points to the group means</li>
</ul>
<div class="figure"><span id="fig:unnamed-chunk-240"></span>
<img src="jabstb_files/figure-html/unnamed-chunk-240-1.png" alt="A completely randomized one way ANOVA, the genotype factor has three levels. Gold bar = grand mean, black bar = group means" width="672" />
<p class="caption">
Figure 24.4: A completely randomized one way ANOVA, the genotype factor has three levels. Gold bar = grand mean, black bar = group means
</p>
</div>
<div id="sums-of-squares-partitioning" class="section level3">
<h3><span class="header-section-number">24.4.1</span> Sums of Squares partitioning</h3>
<p>The first step in an ANOVA involves partitioning the variation in a data set using sums of squares.</p>
<p>In this experiment, there are <span class="math inline">\(i=1, 2..n\)</span> independent replicates. There are also <span class="math inline">\(j=1, 2..k\)</span> groups.</p>
<p>The total sum of squares is the sum of the squared deviation from all data points to <span class="math inline">\(\hat y\)</span>, which is the grand mean of the sample.</p>
<p><span class="math display">\[SS_{total}=\sum_{j=1}^k\sum_{i=1}^n(y_i-\hat y)^2\]</span></p>
<p>The sum of squares for the genotype effect is sum of the weighted squared deviation between the group means, <span class="math inline">\(\bar y_j\)</span> and the grand mean. Here, <span class="math inline">\(n_j\)</span> is the sample size within the <span class="math inline">\(j^{th}\)</span> group.</p>
<p><span class="math display">\[SS_{genotype}=\sum_{j=1}^kn_j(\bar y_j-\hat y)^2\]</span></p>
<p>Some software refers to this variation as the “treatment” sum of squares.</p>
<p>Parenthetically, let’s pause to reflect for a moment to consider one consequence of how that equation shows the weighting of group deviation by sample size. The level of model variation can skew to one group when its sample size differs markedly from the others. This explains why you want to keep group sizes reasonably balanced, or roughly equivalent, when designing experiments.</p>
<p>Finally, the residual sum of squares is calculated as the sum of the squared deviation between replicate values and group means,</p>
<p><span class="math display">\[SS_{residual}=\sum_{j=1}^k\sum_{i=1}^n(y_i-\bar y_j)^2\]</span></p>
<p>which, because the total variation amount of is fixed, can also be calculated as follows:</p>
<p><span class="math display">\[SS_{residual}=SS_{total}-SS_{genotype}\]</span></p>
<p>In some software residual variation is referred to as “error”. The term “error” arises from ANOVA theory, which holds that the true population means represented by these sample groups are “fixed” in the population. Thus, any variation associated with our estimate must be in error. Residuals are the measurements of that “error”.</p>
<p>Perhaps you can intuit a few things. First, the residual variation is the variation unaccounted for by the model. Meaning that whatever its causes, they are not under experimental control.</p>
<p>Second, if the variation around each group mean remains similar, but as the group means differ from each other more, the greater the fraction of the overall variation that will be associated with the model, and the less that will be associated with the residual.</p>
<p>Third, when the noise around those group means increases, less of the total variation will be associated with the model of group means, and the more with the residual.</p>
<p>In other words, noisy experiments tend to hide detectable differences between means, while clean experiments favor detecting these differences. Similarly, predictors that lead to large effects on means</p>
<p>If that seems bloody obvious to you, and it is simple, then you should not have any problem processing how ANOVA works.</p>
<p>The following two graphs emphasize these observations. In the null graph, the group means are roughly equivalent and very nearly the same as the grand mean. There’s very little model variation. Most of the variation is in the residuals.</p>
<p>In the effective treatment graph, where the means truly differ because I coded them to differ, the residual variation is about the same as the null. But you can see there is a lot more model variation, at least compared to the null graph.</p>
<p><img src="jabstb_files/figure-html/unnamed-chunk-241-1.png" width="288" /><img src="jabstb_files/figure-html/unnamed-chunk-241-2.png" width="288" /></p>
</div>
<div id="degrees-of-freedom" class="section level3">
<h3><span class="header-section-number">24.4.2</span> Degrees of freedom</h3>
<p>Again, variance is an averaged deviation. To calculate a variance we’ll need to divide the sum of squares for a component by its degrees of freedom. Just as sum of squares are calculated differently depending on whether it is total, or model or residual, so too are degrees of freedom.</p>
<p>The theory behind <span class="math inline">\(df\)</span> is a bit more complicated than this, as a general rule, we lose a degree of freedom every time the calculation of a mean is involved in determination of a given <span class="math inline">\(SS\)</span>. The basic idea is this: For that mean value to be true, one of the replicates must remain fixed, while all the others are free to vary.</p>
<p>The degrees of freedom for total variance are <span class="math inline">\(df_{total}=N-1\)</span>. We use all 15 replicates, <span class="math inline">\(N\)</span>, to calculate <span class="math inline">\(\hat y\)</span>, the grand mean. We lose a degree of freedom because for that grand mean to be true, one of those replicate values must be fixed while the others are free to vary.</p>
<p>We have <span class="math inline">\(k\)</span> groups. The degrees of freedom for the genotype model variance are <span class="math inline">\(df_{genotype}=k-1\)</span>, because the calculation is based upon the group means, two of which can be free to vary.</p>
<p>The residual degrees of freedom are <span class="math inline">\(df_{residual}=N-k\)</span>.</p>
</div>
<div id="the-mean-squares" class="section level3">
<h3><span class="header-section-number">24.4.3</span> The mean squares</h3>
<p>The mean squares are ANOVA jargon to represent variances, and variance can be thought of as averaged variation.</p>
<p>Total variance is <span class="math display">\[MS_{total}=\frac{SS_{total}}{df_{total}} \]</span></p>
<p>The variance associated with the model is <span class="math display">\[MS_{model}=\frac{SS_{model}}{df_{model}} \]</span></p>
<p>And the residual variance is <span class="math display">\[MS_{residual}=\frac{SS_{residual}}{df_{residual}} \]</span></p>
</div>
<div id="the-anova-table" class="section level3">
<h3><span class="header-section-number">24.4.4</span> The ANOVA table</h3>
<p>The typical ANOVA table lists the following:</p>
<p><em>source of variation, </em> its <span class="math inline">\(df\)</span>, * its <span class="math inline">\(SS\)</span>, * its <span class="math inline">\(MS\)</span> * an F-test, where appropriate * a p-value from the F-test</p>
<p>ANOVA functions in R vary in their output. But here’s the ANOVA table output for the data in the last previous figure:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(<span class="kw">lm</span>(blood_glucose <span class="op">~</span><span class="st"> </span>genotype, data))</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: blood_glucose
##           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## genotype   2 21176.9 10588.4  22.979 7.877e-05 ***
## Residuals 12  5529.4   460.8                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="the-f-test" class="section level3">
<h3><span class="header-section-number">24.4.5</span> The F-test</h3>
<p>F-tests are the first step in drawing inference in ANOVA. The value of F is the ratio of two variances. For the result in the ANOVA table above <span class="math inline">\(F=\frac{10588.4}{460.8}=22.979\)</span>. The variance associated with the genotype model is 22.979x greater than the residual variance.</p>
<p>The p-value is derived from an F probability distribution with 2 and 12 degrees of freedom. The result in the table can be mimicked using R’s <a href="@\fdistr"><code>pf</code> function</a>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pf</span>(<span class="fl">22.979</span>, <span class="dv">2</span>, <span class="dv">12</span>, <span class="dt">lower.tail=</span>F)</code></pre></div>
<pre><code>## [1] 7.87784e-05</code></pre>
<p>The example above is a simple one factor completely randomized model for which there is only one F test, because it has only one component. A two-way ANOVA would have three F tests if completely randomized. An F test will pop into the ANOVA table when a factor is treated as related/repeated measures. Three-way ANOVA can have about a dozen F tests!</p>
</div>
<div id="post-hoc-group-comparisons" class="section level3">
<h3><span class="header-section-number">24.4.6</span> Post-hoc group comparisons</h3>
<p>An final stage of ANOVA, which is optional but done very commmonly, is to run what are essentially t-test comparisons between groups. The goal is to see which specific groups actually differ from each other. The comparisons to make should be driven by scientific judgement.</p>
<p>For example, an experiment with <span class="math inline">\(k\)</span> groups may be designed to test which of several groups differ from a negative control. The total number of comparisons that could be made are <span class="math inline">\(\frac{k(k-1)}{2}\)</span>. Yet, only a specific <span class="math inline">\(k-1\)</span> subset are of any interest.</p>
<p>There are several ways to run these post-hoc group comparisons. What is most important, however, is these be done in a way that keeps the FWER below the pre-set type1 error threshold. What this means</p>
</div>
</div>
<div id="completely-randomized-or-related-measures" class="section level2">
<h2><span class="header-section-number">24.5</span> Completely randomized or related measures</h2>
<p>Up until now we’ve discussed ANOVA in its simplest use case, the one-way completely randomized (CR) ANOVA.</p>
<p>Related measures (RM) ANOVA is done when the measurements are not completely independent, but instead are intrinsically-linked.</p>
<p>Examples of intrinsically-linked subjects include</p>
<ul>
<li>identical human twins,</li>
<li>before and after on a single subject,</li>
<li>all plates and wells from a single batch or passage of a cell culture,</li>
<li>a protein preparation from a single batch,</li>
<li>a single cell in culture,</li>
<li>split tissues from one animal subject, and</li>
<li>litter mates of isogenic animal strains.</li>
</ul>
<p>There are certainly others.</p>
<p>Since an RM design involves taking multiple measurements from each of the same replicates, each replicate may vary randomly. That random variation can be accounted for, too. That source of variation is no longer in the residual error term, but can be taken right into the model.</p>
<div id="the-problem-of-lost-data-in-related-measures-designs" class="section level3">
<h3><span class="header-section-number">24.5.1</span> The problem of lost data in related measures designs</h3>
<p>The CR vs RM design decision has a few important consequences.</p>
<p>First, when within-subject correlation is high, RM are much more efficient and less costly to produce. How much more? You can run Monte Carlo simulations to establish this for virtually any set of conditions.</p>
<p>Second, over the course of any experiment it is possible to lose specific response values here and there. For example, a data value may be lost due to a bad lane in a replicate western blot, you accidently throw away a tube from a series, or any of a number of such primitive errors.</p>
<p>CR ANOVA is tolerant of such losses. That leads to a missing replicate, and an unbalanced data sets, but it’s only one or a few values out of many.</p>
<p>That is not the case with related measures designs. All of the values for every level of every factor for every replicate must be included. If any values are missing for a given replicate, all of the remaining values for that replicate either have to be censored, or the missing values should be imputed.</p>
<p>The missing data problem becomes amplified in two way and three way related measures ANOVA! Those experiments tend to have more groups, meaning more data is at risk of being censored.</p>
<p>Researchers often ask if it is reasonable to ‘flip’ to a completely randomized analysis when they notice too many values are missing from their data set.</p>
<p>No, it is not reasonable. The type of experimental design is scientifically-driven. Intrinsically-linked measurements are not independent, and should not be analyzed as if they are independent. To do so violates one of the two primary assumptions of the statistical analysis.</p>
<p>There are a few options to deal with this, and both happen in planning.</p>
<p>First, where possible, include an extra replicate or two as a hedge over what the power analysis suggests is necessary.</p>
<p>Second, don’t make a RM design too over-ambitious. Limit the number of levels to that which is scientifically important.</p>
<p>Third, be aware of the risk of lost values. Is the experimental protocol difficult? Are any protocol steps at high risk of failure? Are there any intrinsic barriers to efficiently collecting the data?</p>
</div>
</div>
<div id="two-way-anova" class="section level2">
<h2><span class="header-section-number">24.6</span> Two-way ANOVA</h2>
<p>This is a method to investigate the effects of two factors simultaneously. Thus, the variation associated with each factor can be partitioned. This also allows for assessing the variation associated with an interaction between the two factors.</p>
<p>What is an interaction? Simply, it is a response that is greater (or lesser) than the sum of the two factors combined.</p>
<p>Let’s go back to the genotype blood_glucose problem. We’ll add a factor, and simplify the study a bit. We’re interested in a gene that, when absent, raises blood glucose. We’re also interested in a drug that, when present, lowers blood glucose.</p>
<p>We have reason to hypothesize that a genotype:drug interaction might exist. For example, the gene might encode a protein that metabolizes our drug, thus impairing the drug’s ability to lower blood glucose.</p>
<p>We’ll simulate a <span class="math inline">\(2\times 2\)</span> experiment that has only the presence or absence of each of these factors.</p>
<p>Here’s the data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12345</span>)
blood_glucose &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">c</span>(<span class="kw">rnorm</span>(<span class="dv">5</span>, <span class="dv">100</span>, <span class="dv">20</span>), <span class="kw">rnorm</span>(<span class="dv">5</span>, <span class="dv">75</span>, <span class="dv">20</span>), <span class="kw">rnorm</span>(<span class="dv">5</span>, <span class="dv">200</span>, <span class="dv">20</span>), <span class="kw">rnorm</span>(<span class="dv">5</span>, <span class="dv">100</span>, <span class="dv">20</span>)), <span class="dv">1</span>)
drug &lt;-<span class="st"> </span><span class="kw">as.factor</span>(<span class="kw">rep</span>(<span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">30</span>),<span class="dt">each=</span><span class="dv">5</span>),<span class="dv">2</span>))
genotype &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;WT&quot;</span>, <span class="st">&quot;KO&quot;</span>), <span class="dt">each=</span><span class="dv">10</span>)

test &lt;-<span class="st"> </span><span class="kw">data.frame</span>(genotype, drug, blood_glucose)

y0 &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">subset</span>(test, genotype<span class="op">==</span><span class="st">&quot;WT&quot;</span> <span class="op">&amp;</span><span class="st"> </span>drug<span class="op">==</span><span class="dv">0</span>)<span class="op">$</span>blood_glucose)
y30 &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">subset</span>(test, genotype<span class="op">==</span><span class="st">&quot;WT&quot;</span> <span class="op">&amp;</span><span class="st"> </span>drug<span class="op">==</span><span class="dv">30</span>)<span class="op">$</span>blood_glucose)
yend0 &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">subset</span>(test, genotype<span class="op">==</span><span class="st">&quot;KO&quot;</span> <span class="op">&amp;</span><span class="st"> </span>drug<span class="op">==</span><span class="dv">0</span>)<span class="op">$</span>blood_glucose)
yend30 &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">subset</span>(test, genotype<span class="op">==</span><span class="st">&quot;KO&quot;</span> <span class="op">&amp;</span><span class="st"> </span>drug<span class="op">==</span><span class="dv">30</span>)<span class="op">$</span>blood_glucose)
  
<span class="kw">ggplot</span>(test, <span class="kw">aes</span>(genotype, blood_glucose, <span class="dt">color=</span>drug))<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">size=</span><span class="dv">6</span>, <span class="dt">width =</span><span class="fl">0.3</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_brewer</span>(<span class="dt">palette=</span><span class="st">&quot;Dark2&quot;</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.y=</span>mean, <span class="dt">geom=</span><span class="st">&quot;point&quot;</span>, <span class="dt">shape =</span> <span class="dv">95</span>, <span class="dt">size=</span> <span class="dv">15</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_discrete</span>(<span class="dt">limits=</span><span class="kw">c</span>(<span class="st">&quot;WT&quot;</span>, <span class="st">&quot;KO&quot;</span>))<span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y=</span><span class="st">&quot;blood glucose&quot;</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x=</span><span class="st">&quot;WT&quot;</span>, <span class="dt">y=</span>y30, <span class="dt">xend=</span><span class="st">&quot;KO&quot;</span>, <span class="dt">yend=</span>yend30))<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x=</span><span class="st">&quot;WT&quot;</span>, <span class="dt">y=</span>y0, <span class="dt">xend=</span><span class="st">&quot;KO&quot;</span>, <span class="dt">yend=</span>yend0))</code></pre></div>
<pre><code>## Warning: Computation failed in `stat_summary()`:
## &#39;what&#39; must be a function or character string</code></pre>
<p><img src="jabstb_files/figure-html/unnamed-chunk-244-1.png" width="672" /></p>
<p>An interaction effect can be represented by the differing slopes of those two lines. If the lines are not parallel, it means that the effect of the drug is not the same at both levels of genotype. Or you could say the effect of the genotype is not the same at both levels of the drug. Whatever.</p>
<p>The statistical term used to describe such phenomena is that the two factors interacted.</p>
<p>Thus, a statistical interaction occurs when the effects of two factors are not the same across all of their levels.</p>
<p>Here’s a quick ANOVA table for those data. It has an F test for each of the factors genotype and drug, and an F test for the genotype:drug interaction. All three F-tests are extreme.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(<span class="kw">lm</span>(blood_glucose <span class="op">~</span><span class="st"> </span>genotype <span class="op">+</span><span class="st"> </span>drug <span class="op">+</span>genotype<span class="op">*</span>drug, test))</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: blood_glucose
##               Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## genotype       1 25127.0 25127.0  94.333 4.116e-08 ***
## drug           1 26028.1 26028.1  97.716 3.225e-08 ***
## genotype:drug  1  4845.4  4845.4  18.191 0.0005923 ***
## Residuals     16  4261.8   266.4                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Since the F-test for the genotype:drug interaction is extreme, we can reject the null that there is no interaction between them. Furthermore, the existence of the interaction effect complicates the interpretation of the effects of the genotype and drug factors. Generally, an interaction effect supercedes an effect of either factor, alone.</p>
<p>Although genotype seems to have a strong effect on glucose levels, that’s really blunted in the presence of drug. And although the drug seems to reduce glucose, that effect becomes remarkably prominent when the genotype changes. When interactions occur, the effect of one factor cannot be interpreted without condition on the other factor!</p>
<p>It might be useful to see the data for the discussion that follows.</p>
<table>
<thead>
<tr class="header">
<th align="left">genotype</th>
<th align="left">drug</th>
<th align="right">blood_glucose</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">WT</td>
<td align="left">0</td>
<td align="right">111.7</td>
</tr>
<tr class="even">
<td align="left">WT</td>
<td align="left">0</td>
<td align="right">114.2</td>
</tr>
<tr class="odd">
<td align="left">WT</td>
<td align="left">0</td>
<td align="right">97.8</td>
</tr>
<tr class="even">
<td align="left">WT</td>
<td align="left">0</td>
<td align="right">90.9</td>
</tr>
<tr class="odd">
<td align="left">WT</td>
<td align="left">0</td>
<td align="right">112.1</td>
</tr>
<tr class="even">
<td align="left">WT</td>
<td align="left">30</td>
<td align="right">38.6</td>
</tr>
<tr class="odd">
<td align="left">WT</td>
<td align="left">30</td>
<td align="right">87.6</td>
</tr>
<tr class="even">
<td align="left">WT</td>
<td align="left">30</td>
<td align="right">69.5</td>
</tr>
<tr class="odd">
<td align="left">WT</td>
<td align="left">30</td>
<td align="right">69.3</td>
</tr>
<tr class="even">
<td align="left">WT</td>
<td align="left">30</td>
<td align="right">56.6</td>
</tr>
<tr class="odd">
<td align="left">KO</td>
<td align="left">0</td>
<td align="right">197.7</td>
</tr>
<tr class="even">
<td align="left">KO</td>
<td align="left">0</td>
<td align="right">236.3</td>
</tr>
<tr class="odd">
<td align="left">KO</td>
<td align="left">0</td>
<td align="right">207.4</td>
</tr>
<tr class="even">
<td align="left">KO</td>
<td align="left">0</td>
<td align="right">210.4</td>
</tr>
<tr class="odd">
<td align="left">KO</td>
<td align="left">0</td>
<td align="right">185.0</td>
</tr>
<tr class="even">
<td align="left">KO</td>
<td align="left">30</td>
<td align="right">116.3</td>
</tr>
<tr class="odd">
<td align="left">KO</td>
<td align="left">30</td>
<td align="right">82.3</td>
</tr>
<tr class="even">
<td align="left">KO</td>
<td align="left">30</td>
<td align="right">93.4</td>
</tr>
<tr class="odd">
<td align="left">KO</td>
<td align="left">30</td>
<td align="right">122.4</td>
</tr>
<tr class="even">
<td align="left">KO</td>
<td align="left">30</td>
<td align="right">106.0</td>
</tr>
</tbody>
</table>
<p>Four sources of variation are accounted for: the main effect of genotype, the main effect of drug, the interaction between drug and genotype, and the residual error.</p>
<p>Three F tests were performed. Each of these used <span class="math inline">\(MS_{residual}\)</span> in the denominator and the <span class="math inline">\(MS\)</span> for the respective source in the numerator.</p>
<p>How has this variation been determined?</p>
<p>The experimental model is as follows: <span class="math display">\[SS_{model}=SS_{genotype}+SS_{drug}+SS_{genotype\times drug} \]</span></p>
<p>The grand mean of all the data is computed as before: <span class="math display">\[\hat y=\frac{1}{n}\sum_{i=1}^ny_i \]</span></p>
<p>There are two factors, each at two levels. Thus, there are a total of <span class="math inline">\(j=4\)</span> experimental groups. Each group has a sample size of <span class="math inline">\(n_j=5\)</span> replicates and represent a combination of predictor variables: WT/0, WT/30, KO/0, KO/30. The mean of each group is <span class="math inline">\(\bar_j\)</span>.</p>
<p>Therefore, <span class="math display">\[SS_{model}= \sum_{j=1}^kn_j(\bar y_j-\hat y)^2 \]</span> represents the total model variation.</p>
<p>We can also artificially group these factors and levels further. Two groups correspond to the levels of the genotype factors and two correspond to the levels of the drug factor. Their means are <span class="math inline">\(\bar y_{wt}, \bar y_{ko}\)</span> and <span class="math inline">\(\bar y_0, \bar y_{30}\)</span>, respectively. Each of these groups has a sample size of <span class="math inline">\(2n_j\)</span>.</p>
<p>These contrived means are used to isolate for the variation of each of the two factors:</p>
<p><span class="math display">\[SS_{genotype}= \sum n_{wt}(\bar y_{wt}-\hat y)^2+n_{ko}(\bar y_{ko}-\hat y)^2 \]</span></p>
<p><span class="math display">\[SS_{drug}= \sum n_{0}(\bar y_{0}-\hat y)^2+n_{30}(\bar y_{30}-\hat y)^2 \]</span></p>
<p>All that remains is to account for the variation associated with the interaction effect. That can be solved for algebraically: <span class="math display">\[SS_{genotype\times drug}=SS_{model}-SS_{genotype}-SS_{drug} \]</span></p>
<p>Because two way ANOVA’s have two factors, one of the factors can be applied completely randomized, and the other can be applied as related measures. Or both factors can be completely randomized, or both can be related measures.</p>
</div>
<div id="other-anova-models" class="section level2">
<h2><span class="header-section-number">24.7</span> Other ANOVA models</h2>
<p>For all ANOVA experiments, irrespective of the design, the total amount of deviation in the data can be partitioned into model and residual terms:</p>
<p><span class="math display">\[SS_{total}=SS_{model}+ SS_{residual}\]</span></p>
<p>What’s interesting is that different ANOVA experimental designs have different models. We’re interested in two factors, factorA and factorB, and have the ability to study each at multiple levels. The interaction between factorA and factorB is <span class="math inline">\(A\times B\)</span></p>
<p>One way CR: <span class="math inline">\(SS_{model}=SS_{factorA}\)</span></p>
<p>One way RM: <span class="math inline">\(SS_model=SS_{factorA}+SS_{subj}\)</span></p>
<p>Two way CR: <span class="math inline">\(SS_{model}=SS_{factorA}+SS_{factorB}+SS_{A\times B}\)</span></p>
<p>Two way RM on A factor: <span class="math inline">\(SS_{model}=SS_A+SS_B+SS_{A\times B}+SS_{subj\times A}\)</span></p>
<p>Two way RM on both factors: <span class="math inline">\(SS_{model}=SS_A+SS_B+SS_{A\times B}+SS_{subj\times A}+SS_{subjXB}+SS_{subj\times A\times B}\)</span></p>
<p>The big difference between completely randomized and related measure designs is that in the latter, we’re now accounting for the deviation associated with each replicate in the model! Otherwise, that replicate deviation would have been blended into the residuals.</p>
<p>This turns out to be a pretty big deal. When that deviation due to the subjects is pulled out of the residual, it lowers the value of the denominator of the F statistic. Thus making the F statistic larger!</p>
<div id="r-and-anova" class="section level3">
<h3><span class="header-section-number">24.7.1</span> R and ANOVA</h3>
<p>There are a handful of ways to conduct ANOVA analysis on R. These are not necessarily more right or wrong than the others. What is important to know, however, is that they do perform calculations differently under certain circumstances (eg, Type 1 v Type 2 v Type 3 SS calculations). Therefore, they produce distinct results which can be confusing, particularly when comparing R’s results to other software you might be familiar with.</p>
<p>This again emphasizes the need to share specific details of the analysis in our publications. In this case, specify using R, specify the R function used, and even specify the <code>type</code> argument used in ezANOVA.</p>
<p>Given data and a group of arguments we’ll call foo, R’s ANOVA function options are as follows:</p>
<p><code>anova</code> - A function in R’s base. eg, <code>anova(lm(foo))</code></p>
<p><code>aov</code> - A function in R’s base. eg, `aov(foo)</p>
<p><code>Anova</code> - A function in R’s car package. eg, <code>Anova(lm(foo))</code></p>
<p><code>ezAnova</code> - A function in R’s ezAnova package, <code>ezAnova(foo)</code></p>
<p>There are others. For example, since ANOVA analyses are also general linear models the same basic problem can also be solved using <code>lm(foo)</code>without ANOVA. Passing an `lm(foo) into an ANOVA function is generally designed to provide you an ANOVA table.</p>
<p>For the ANOVA part of this course, we’ll use <code>ezANOVA</code> from the <code>ez</code> package. In particular, it is a bit more straightforward to use than the other options when dealing with related measures and with two-way ANOVA, which are very common in biomedical research.</p>
<p><strong>Key Jargon to understand to do ezANOVA in R</strong></p>
<p>Don’t confuse ezANOVA’s use of between and within the way it is used elsewhere in ANOVA jargon.</p>
<p>Specify a completely random design by defining the <strong>‘between’</strong> variable as your factor name. The between here is meant to imply comparisons between groups.</p>
<p>Specify a related measures design by defining the <strong><code>within</code></strong> variable as your factor name. The within here is meant to imply comparisons within replicates.</p>
<div id="type-of-calculation" class="section level4">
<h4><span class="header-section-number">24.7.1.1</span> Type of calculation</h4>
<p>There are three ways ANOVA can be calculated, which are referred to as type I, type II and type III.</p>
<p>When an experiment is balanced, which is to say it has equal sample sizes per group, the type of calculation is immaterial. In that case,type I, II and III yield the same output.</p>
<p>Unbalanced experiments are those in which the sample sizes of groups are not the same. As long as the differences are not too large, the presence of unbalance is usually not a problem. But it can impact the precise output of different ANOVA functions, depending upon whether they perform type I, II or III calculations.</p>
<p>This causes some confusion, particularly when comparing the output of different ANOVA functions in R (eg, <code>Anova</code> vs <code>aov</code> vs <code>anova</code> vs <code>ezAnova</code>) and/or commercial software (eg, SAS, SPSS, Prism). The researcher scratchers her head, wonders which is “correct”.</p>
<p>In one sense, they are all correct.</p>
<p>Type I, II and II sum of squares calculations are explained <a href="https://www.r-bloggers.com/anova-%E2%80%93-type-iiiiii-ss-explained/">here</a> and also <a href="https://mcfromnz.wordpress.com/2011/03/02/anova-type-iiiiii-ss-explained/">here</a>.</p>
<p>Suffice to say this is important to not overlook. This serves to illustrate how providing good detail about the software used to analyze data is important for reproducibility.</p>
<p>The most significant point to understand is that some commercial software uses type 3 calculations by default. As a consequence, given the same data set, the results from those packages may not coincide perfectly with those of ezANOVA unless using a <code>type = 3</code> argument in the function.</p>
<p>My recommendation is to use <code>type = 2</code> when interested in testing hypotheses about the main effects of factors, and there is no interest in an interaction if working on a two- or three-way ANOVA data set. That’s because <code>type = 2</code> is purported to yield consistently higher power for main effects.</p>
<p>Use <code>type = 3</code> when, instead, the experiment is designed to test whether an interaction occurs between factors. When an interaction occurs, the main effects are not interpretable.</p>
<p>Type I sum of squares are calculated when using the <code>anova</code> and <code>aov</code> functions of base R. This is otherwise known as “sequential” sum of squares calculation. On multifactor data with those functions, the results can differ given the order by which the factors are argued. Thus, <code>aov(lm(outcome~factorA + factorB))</code> might yield slightly different results compared to <code>aov(lm(outcome~factorB + factorA))</code>. The idea is to calculate the effect on a factor that is most interesting to you scientifically, while “controlling” for the effect of the other factor.</p>
</div>
</div>
</div>
<div id="alternatives-to-anova" class="section level2">
<h2><span class="header-section-number">24.8</span> Alternatives to ANOVA</h2>
<p>When the outcome variable is measured and the design is completely randomized, the data can be analyzed using the general linear model with R’s <code>lm</code> function, rather than by ANOVA. This allows for analyzing interaction effects between factors. The results will be the same as ANOVA. If the design has a related measures component, then a linear mixed effects model should be run instead. In that case, use <code>lmer</code> in the <code>lme4</code> package.</p>
<p>Alternately a nonparametric analysis can be performed using either the Kruskal-Wallis (completely randomized) for the Friedman (related measures) test. Bear in mind that there is no nonparametric analog for the two-way ANOVA. Thus, hypotheses related to interaction effects are not testable using nonparametric statistics.</p>
<p>Finally there is the generalized linear model (<code>glm</code>) for completely randomized designs or the generalized linear mixed model (<code>glmer</code>) for designs that incorporate related measures, respectively. Each of these allow for testing interactions between factors. These allow for a flexible array of outcome variables. These should be used, rather than ANOVA, when the outcome variable is non-normal or is discrete. For example, these are the tools of choice when the outcome variable is binomial or frequency data and there are 3 or more groups to compare. Additional families are possible.</p>
<div id="screw-anova-just-tell-me-how-to-t-test-everything" class="section level3">
<h3><span class="header-section-number">24.8.1</span> Screw ANOVA, Just Tell Me How to t-Test Everything</h3>
<p>OK, fine.</p>
<p>This is far from ideal because of the bias it introduces. You don’t <em>have</em> to do ANOVA for an experiment with 3 or more groups (or anything else for that matter–you just have to be able to defend your choices). A major purpose of ANOVA is to maintain an experiment-wise type1 error of 5%. But there are other ways to accomplish this objective.</p>
<p>For example, you might skip the ANOVA step and simply run serial t-tests comparing all of the groups in an experiment. Or run t-tests to compare a <strong>pre-planned</strong> sublist of all possible comparisons. The emphasis here on pre-planning is important. Make decisions ahead of time about what is to be compared, then make only those comparisons. No more and no less. Otherwise, you’re snooping. Once you’re in snooping mode, you’re deeply biased towards opportunistic outcomes.</p>
<p>For example, you may run multiple control groups within your experiment to signal that some important aspect of the protocol is working properly, but these controls are otherwise not scientifically interesting (with respect to testing new hypotheses). You may not wish to expend any of your type1 error budget doing comparisons on these controls.</p>
<p>With those reservations noted, what follows are two ways to go about this.</p>
<p>To begin, if we have <span class="math inline">\(k\)</span> predictor variables and <span class="math inline">\(k\)</span> groups in our experiment it has a <strong>total</strong> of <span class="math inline">\(C=k(k-1)/2\)</span> possible comparisons that could be made.</p>
<p>The <code>pairwise.t.test</code> is the function to use for this purpose. Use it to make the group comparisons that interest you. choosing the <code>p.adjust.method</code> that strikes your fancy. Two of the latter are listed below.</p>
<div id="bonferroni-correction" class="section level5">
<h5><span class="header-section-number">24.8.1.0.1</span> Bonferroni Correction</h5>
<p>If <span class="math inline">\(C\)</span> is the number of comparisons to be tested, whether or not it is equal to <span class="math inline">\(k(k-1)/2\)</span>, and if <span class="math inline">\(\alpha\)</span> is the type1 error threshold you’ve set for the entire experiment, then the corrected type1 error threshold for each comparison is <span class="math inline">\(\alpha_c=\frac{alpha}{C}\)</span>.</p>
<p>Thus, you would reject the null hypothesis for any comparison for which a t-test yields a p-value that is less than <span class="math inline">\(\alpha_c\)</span>.</p>
</div>
<div id="holm-sidak-correction" class="section level5">
<h5><span class="header-section-number">24.8.1.0.2</span> Holm-Sidak Correction</h5>
<p>This is a modestly more liberal alternative to the Bonferroni correction. Here, for <span class="math inline">\(C\)</span> comparisons and an experimentwise type1 error threshold <span class="math inline">\(\alpha\)</span>, the corrected per comparison threshold would be <span class="math inline">\(\alpha_c=1-(1-\alpha)^C\)</span>.</p>
<p>Again, for a given comparison reject, the null if its p-value is less than <span class="math inline">\(\alpha_c\)</span>.</p>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="simcorrelation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="fdistr.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["jabstb.pdf", "jabstb.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
