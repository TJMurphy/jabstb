<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 19 Nonparametric Statistical Tests | JABSTB: Statistical Design and Analysis of Experiments with R</title>
  <meta name="description" content="Experimental biostatistics using R." />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 19 Nonparametric Statistical Tests | JABSTB: Statistical Design and Analysis of Experiments with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Experimental biostatistics using R." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 19 Nonparametric Statistical Tests | JABSTB: Statistical Design and Analysis of Experiments with R" />
  
  <meta name="twitter:description" content="Experimental biostatistics using R." />
  

<meta name="author" content="TJ Murphy PhD, Department of Pharmacology and Chemical Biology, School of Medicine, Emory University, Atlanta, GA biostats538@gmail.com" />


<meta name="date" content="2020-03-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chisquare.html"/>
<link rel="next" href="signrank.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">JABSTB</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="author.html"><a href="author.html"><i class="fa fa-check"></i><b>1</b> About the author and book</a></li>
<li class="chapter" data-level="2" data-path="history.html"><a href="history.html"><i class="fa fa-check"></i><b>2</b> A Brief History of Experimental Design</a></li>
<li class="chapter" data-level="3" data-path="software.html"><a href="software.html"><i class="fa fa-check"></i><b>3</b> Installing and Understanding the software</a><ul>
<li class="chapter" data-level="3.1" data-path="software.html"><a href="software.html#spring-2020-term-versions"><i class="fa fa-check"></i><b>3.1</b> Spring 2020 term versions</a><ul>
<li class="chapter" data-level="3.1.1" data-path="software.html"><a href="software.html#what-are-these"><i class="fa fa-check"></i><b>3.1.1</b> What are these?</a></li>
<li class="chapter" data-level="3.1.2" data-path="software.html"><a href="software.html#rule-1-install-r-first-install-rstudio-second"><i class="fa fa-check"></i><b>3.1.2</b> Rule 1: Install R first, install RStudio second</a></li>
<li class="chapter" data-level="3.1.3" data-path="software.html"><a href="software.html#rule-2-dont-pay"><i class="fa fa-check"></i><b>3.1.3</b> Rule 2: Don’t pay!</a></li>
<li class="chapter" data-level="3.1.4" data-path="software.html"><a href="software.html#rule-3-dont-compile"><i class="fa fa-check"></i><b>3.1.4</b> Rule 3: Don’t compile!</a></li>
<li class="chapter" data-level="3.1.5" data-path="software.html"><a href="software.html#rule-4-install-the-right-software-for-your-machine"><i class="fa fa-check"></i><b>3.1.5</b> Rule 4: Install the right software for your machine</a></li>
<li class="chapter" data-level="3.1.6" data-path="software.html"><a href="software.html#rule-5-use-this-installation-guide"><i class="fa fa-check"></i><b>3.1.6</b> Rule 5: Use this installation guide</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="software.html"><a href="software.html#after-installation"><i class="fa fa-check"></i><b>3.2</b> After installation</a><ul>
<li class="chapter" data-level="3.2.1" data-path="software.html"><a href="software.html#what-is-r"><i class="fa fa-check"></i><b>3.2.1</b> What is R?</a></li>
<li class="chapter" data-level="3.2.2" data-path="software.html"><a href="software.html#r-packages"><i class="fa fa-check"></i><b>3.2.2</b> R packages</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="software.html"><a href="software.html#important-avoid-compiling"><i class="fa fa-check"></i><b>3.3</b> Important: Avoid compiling</a><ul>
<li class="chapter" data-level="3.3.1" data-path="software.html"><a href="software.html#reasons-not-to-compile"><i class="fa fa-check"></i><b>3.3.1</b> Reasons not to compile</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i><b>4</b> Start Learning R</a><ul>
<li class="chapter" data-level="4.1" data-path="getting-started.html"><a href="getting-started.html#digging-in-with-rrstudio"><i class="fa fa-check"></i><b>4.1</b> Digging in with R/RStudio</a></li>
<li class="chapter" data-level="4.2" data-path="getting-started.html"><a href="getting-started.html#the-tidyverse-package"><i class="fa fa-check"></i><b>4.2</b> The tidyverse package</a><ul>
<li class="chapter" data-level="4.2.1" data-path="getting-started.html"><a href="getting-started.html#do-swirlstats"><i class="fa fa-check"></i><b>4.2.1</b> Do swirlstats</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="getting-started.html"><a href="getting-started.html#other-resources"><i class="fa fa-check"></i><b>4.3</b> Other resources</a><ul>
<li class="chapter" data-level="4.3.1" data-path="getting-started.html"><a href="getting-started.html#internet-search"><i class="fa fa-check"></i><b>4.3.1</b> Internet search</a></li>
<li class="chapter" data-level="4.3.2" data-path="getting-started.html"><a href="getting-started.html#help-documents"><i class="fa fa-check"></i><b>4.3.2</b> Help Documents</a></li>
<li class="chapter" data-level="4.3.3" data-path="getting-started.html"><a href="getting-started.html#package-vignettes"><i class="fa fa-check"></i><b>4.3.3</b> Package Vignettes</a></li>
<li class="chapter" data-level="4.3.4" data-path="getting-started.html"><a href="getting-started.html#people"><i class="fa fa-check"></i><b>4.3.4</b> People</a></li>
<li class="chapter" data-level="4.3.5" data-path="getting-started.html"><a href="getting-started.html#typos"><i class="fa fa-check"></i><b>4.3.5</b> typos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="philos.html"><a href="philos.html"><i class="fa fa-check"></i><b>5</b> What is your philosophy?</a><ul>
<li class="chapter" data-level="5.1" data-path="philos.html"><a href="philos.html#exploration-and-uncertainty"><i class="fa fa-check"></i><b>5.1</b> Exploration and uncertainty</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="bigpic.html"><a href="bigpic.html"><i class="fa fa-check"></i><b>6</b> Stats: The Big Picture</a><ul>
<li class="chapter" data-level="6.1" data-path="bigpic.html"><a href="bigpic.html#what-are-experimental-statistics"><i class="fa fa-check"></i><b>6.1</b> What are experimental statistics?</a><ul>
<li class="chapter" data-level="6.1.1" data-path="bigpic.html"><a href="bigpic.html#descriptive-modeling"><i class="fa fa-check"></i><b>6.1.1</b> Descriptive modeling</a></li>
<li class="chapter" data-level="6.1.2" data-path="bigpic.html"><a href="bigpic.html#statistical-inference"><i class="fa fa-check"></i><b>6.1.2</b> Statistical inference</a></li>
<li class="chapter" data-level="6.1.3" data-path="bigpic.html"><a href="bigpic.html#experimental-design"><i class="fa fa-check"></i><b>6.1.3</b> Experimental design</a></li>
<li class="chapter" data-level="6.1.4" data-path="bigpic.html"><a href="bigpic.html#statistics-as-an-anti-bias-framework"><i class="fa fa-check"></i><b>6.1.4</b> Statistics as an anti-bias framework</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="sampling.html"><a href="sampling.html"><i class="fa fa-check"></i><b>7</b> Statistical Sampling</a><ul>
<li class="chapter" data-level="7.1" data-path="sampling.html"><a href="sampling.html#experimental-units"><i class="fa fa-check"></i><b>7.1</b> Experimental units</a><ul>
<li class="chapter" data-level="7.1.1" data-path="sampling.html"><a href="sampling.html#a-simple-test-to-define-the-experimental-unit"><i class="fa fa-check"></i><b>7.1.1</b> A simple test to define the experimental unit</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="sampling.html"><a href="sampling.html#independent-replicates"><i class="fa fa-check"></i><b>7.2</b> Independent Replicates</a><ul>
<li class="chapter" data-level="7.2.1" data-path="sampling.html"><a href="sampling.html#a-simple-test-for-independence"><i class="fa fa-check"></i><b>7.2.1</b> A simple test for independence</a></li>
<li class="chapter" data-level="7.2.2" data-path="sampling.html"><a href="sampling.html#some-replication-examples"><i class="fa fa-check"></i><b>7.2.2</b> Some replication examples</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="sampling.html"><a href="sampling.html#random-process"><i class="fa fa-check"></i><b>7.3</b> Random process</a></li>
<li class="chapter" data-level="7.4" data-path="sampling.html"><a href="sampling.html#statistically-valid-samples"><i class="fa fa-check"></i><b>7.4</b> Statistically valid samples</a><ul>
<li class="chapter" data-level="7.4.1" data-path="sampling.html"><a href="sampling.html#select-random-subjects"><i class="fa fa-check"></i><b>7.4.1</b> Select random subjects</a></li>
<li class="chapter" data-level="7.4.2" data-path="sampling.html"><a href="sampling.html#randomize-to-sequence"><i class="fa fa-check"></i><b>7.4.2</b> Randomize to sequence</a></li>
<li class="chapter" data-level="7.4.3" data-path="sampling.html"><a href="sampling.html#randomize-to-location"><i class="fa fa-check"></i><b>7.4.3</b> Randomize to location</a></li>
<li class="chapter" data-level="7.4.4" data-path="sampling.html"><a href="sampling.html#randomize-to-block"><i class="fa fa-check"></i><b>7.4.4</b> Randomize to block</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="sampling.html"><a href="sampling.html#independence-of-replicates"><i class="fa fa-check"></i><b>7.5</b> Independence of replicates</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>8</b> Data Classification</a><ul>
<li class="chapter" data-level="8.1" data-path="data.html"><a href="data.html#dependent-and-independent-variables"><i class="fa fa-check"></i><b>8.1</b> Dependent and independent variables</a><ul>
<li class="chapter" data-level="8.1.1" data-path="data.html"><a href="data.html#statistical-notation"><i class="fa fa-check"></i><b>8.1.1</b> Statistical notation</a></li>
<li class="chapter" data-level="8.1.2" data-path="data.html"><a href="data.html#when-there-is-no-independent-variable"><i class="fa fa-check"></i><b>8.1.2</b> When there is no independent variable</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="data.html"><a href="data.html#discrete-or-continuous-variables"><i class="fa fa-check"></i><b>8.2</b> Discrete or continuous variables</a><ul>
<li class="chapter" data-level="8.2.1" data-path="data.html"><a href="data.html#measured-variables"><i class="fa fa-check"></i><b>8.2.1</b> Measured variables</a></li>
<li class="chapter" data-level="8.2.2" data-path="data.html"><a href="data.html#discrete-categorical-and-ordinal-variables"><i class="fa fa-check"></i><b>8.2.2</b> Discrete categorical and ordinal variables</a></li>
<li class="chapter" data-level="8.2.3" data-path="data.html"><a href="data.html#rescaling-variables"><i class="fa fa-check"></i><b>8.2.3</b> Rescaling variables</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="data.html"><a href="data.html#working-with-data"><i class="fa fa-check"></i><b>8.3</b> Working with data</a><ul>
<li class="chapter" data-level="8.3.1" data-path="data.html"><a href="data.html#entering-data"><i class="fa fa-check"></i><b>8.3.1</b> Entering data</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="data.html"><a href="data.html#summary"><i class="fa fa-check"></i><b>8.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="dispersion.html"><a href="dispersion.html"><i class="fa fa-check"></i><b>9</b> Variability, Accuracy and Precision</a><ul>
<li class="chapter" data-level="9.0.1" data-path="dispersion.html"><a href="dispersion.html#data-are-messy"><i class="fa fa-check"></i><b>9.0.1</b> Data are messy</a></li>
<li class="chapter" data-level="9.1" data-path="dispersion.html"><a href="dispersion.html#illustration-of-a-model-with-error"><i class="fa fa-check"></i><b>9.1</b> Illustration of a model with error</a></li>
<li class="chapter" data-level="9.2" data-path="dispersion.html"><a href="dispersion.html#variance-quantifying-variation-by-least-squares"><i class="fa fa-check"></i><b>9.2</b> Variance: Quantifying variation by least squares</a><ul>
<li class="chapter" data-level="9.2.1" data-path="dispersion.html"><a href="dispersion.html#definition-of-variance"><i class="fa fa-check"></i><b>9.2.1</b> Definition of variance</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="dispersion.html"><a href="dispersion.html#standard-deviation"><i class="fa fa-check"></i><b>9.3</b> Standard deviation</a><ul>
<li class="chapter" data-level="9.3.1" data-path="dispersion.html"><a href="dispersion.html#what-does-the-standard-deviation-tell-us"><i class="fa fa-check"></i><b>9.3.1</b> What does the standard deviation tell us</a></li>
<li class="chapter" data-level="9.3.2" data-path="dispersion.html"><a href="dispersion.html#ways-of-describing-sample-variability"><i class="fa fa-check"></i><b>9.3.2</b> Ways of describing sample variability</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="dispersion.html"><a href="dispersion.html#precision-and-accuracy"><i class="fa fa-check"></i><b>9.4</b> Precision and Accuracy</a></li>
<li class="chapter" data-level="9.5" data-path="dispersion.html"><a href="dispersion.html#standard-error"><i class="fa fa-check"></i><b>9.5</b> Standard error</a><ul>
<li class="chapter" data-level="9.5.1" data-path="dispersion.html"><a href="dispersion.html#what-exactly-does-the-standard-error-represent"><i class="fa fa-check"></i><b>9.5.1</b> What exactly does the standard error represent?</a></li>
<li class="chapter" data-level="9.5.2" data-path="dispersion.html"><a href="dispersion.html#should-i-use-sd-or-sem"><i class="fa fa-check"></i><b>9.5.2</b> “Should I use SD or SEM?”</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="dispersion.html"><a href="dispersion.html#confidence-intervals"><i class="fa fa-check"></i><b>9.6</b> Confidence intervals</a><ul>
<li class="chapter" data-level="9.6.1" data-path="dispersion.html"><a href="dispersion.html#ci-definition"><i class="fa fa-check"></i><b>9.6.1</b> CI Definition</a></li>
<li class="chapter" data-level="9.6.2" data-path="dispersion.html"><a href="dispersion.html#evaluating-confidence-intervals"><i class="fa fa-check"></i><b>9.6.2</b> Evaluating confidence intervals</a></li>
<li class="chapter" data-level="9.6.3" data-path="dispersion.html"><a href="dispersion.html#ci-simulation-tools"><i class="fa fa-check"></i><b>9.6.3</b> CI Simulation tools</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="dispersion.html"><a href="dispersion.html#key-take-aways"><i class="fa fa-check"></i><b>9.7</b> Key take aways</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="hypotheses.html"><a href="hypotheses.html"><i class="fa fa-check"></i><b>10</b> Framing statistical hypotheses</a><ul>
<li class="chapter" data-level="10.1" data-path="hypotheses.html"><a href="hypotheses.html#the-decision-process"><i class="fa fa-check"></i><b>10.1</b> The decision process</a></li>
<li class="chapter" data-level="10.2" data-path="hypotheses.html"><a href="hypotheses.html#popper-and-falsification"><i class="fa fa-check"></i><b>10.2</b> Popper and falsification</a></li>
<li class="chapter" data-level="10.3" data-path="hypotheses.html"><a href="hypotheses.html#statistical-hypothesis-rubric"><i class="fa fa-check"></i><b>10.3</b> Statistical hypothesis rubric</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="error.html"><a href="error.html"><i class="fa fa-check"></i><b>11</b> Error</a><ul>
<li class="chapter" data-level="11.1" data-path="error.html"><a href="error.html#setting-type-1-and-type-2-error-thresholds"><i class="fa fa-check"></i><b>11.1</b> Setting type 1 and type 2 error thresholds</a><ul>
<li class="chapter" data-level="11.1.1" data-path="error.html"><a href="error.html#setting-alpha-the-type-1-error"><i class="fa fa-check"></i><b>11.1.1</b> Setting alpha-the type 1 error</a></li>
<li class="chapter" data-level="11.1.2" data-path="error.html"><a href="error.html#power-setting-beta-the-type-2-error"><i class="fa fa-check"></i><b>11.1.2</b> Power: Setting beta-the type 2 error</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="error.html"><a href="error.html#striking-the-right-balance"><i class="fa fa-check"></i><b>11.2</b> Striking the right balance</a></li>
<li class="chapter" data-level="11.3" data-path="error.html"><a href="error.html#false-discovery-rate"><i class="fa fa-check"></i><b>11.3</b> False discovery rate</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="pvalues.html"><a href="pvalues.html"><i class="fa fa-check"></i><b>12</b> P Values</a><ul>
<li class="chapter" data-level="12.1" data-path="pvalues.html"><a href="pvalues.html#definition"><i class="fa fa-check"></i><b>12.1</b> Definition</a></li>
<li class="chapter" data-level="12.2" data-path="pvalues.html"><a href="pvalues.html#test-statistics-come-from-null-distributions"><i class="fa fa-check"></i><b>12.2</b> Test statistics come from null distributions</a><ul>
<li class="chapter" data-level="12.2.1" data-path="pvalues.html"><a href="pvalues.html#p-value-behavior"><i class="fa fa-check"></i><b>12.2.1</b> P-value behavior</a></li>
<li class="chapter" data-level="12.2.2" data-path="pvalues.html"><a href="pvalues.html#p-values-and-the-decision-process"><i class="fa fa-check"></i><b>12.2.2</b> P-values and the decision process</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="pvalues.html"><a href="pvalues.html#a-blood-glucose-p-value"><i class="fa fa-check"></i><b>12.3</b> A blood glucose p-value</a></li>
<li class="chapter" data-level="12.4" data-path="pvalues.html"><a href="pvalues.html#how-p-values-should-be-interpreted"><i class="fa fa-check"></i><b>12.4</b> How p-values should be interpreted</a></li>
<li class="chapter" data-level="12.5" data-path="pvalues.html"><a href="pvalues.html#interpretation"><i class="fa fa-check"></i><b>12.5</b> Interpretation</a></li>
<li class="chapter" data-level="12.6" data-path="pvalues.html"><a href="pvalues.html#criticisms-of-p-values"><i class="fa fa-check"></i><b>12.6</b> Criticisms of p-values</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="jaxwest7.html"><a href="jaxwest7.html"><i class="fa fa-check"></i><b>13</b> Reproducible Data Munging in R</a><ul>
<li class="chapter" data-level="13.1" data-path="jaxwest7.html"><a href="jaxwest7.html#jaxwest7-glucose-data"><i class="fa fa-check"></i><b>13.1</b> Jaxwest7 glucose data</a><ul>
<li class="chapter" data-level="13.1.1" data-path="jaxwest7.html"><a href="jaxwest7.html#inspect-the-jaxwest7-data"><i class="fa fa-check"></i><b>13.1.1</b> Inspect the Jaxwest7 data</a></li>
<li class="chapter" data-level="13.1.2" data-path="jaxwest7.html"><a href="jaxwest7.html#munge-the-glucose-concentration-data-into-r"><i class="fa fa-check"></i><b>13.1.2</b> Munge the glucose concentration data into R</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="jaxwest7.html"><a href="jaxwest7.html#explore-the-jaxwest7-data"><i class="fa fa-check"></i><b>13.2</b> Explore the Jaxwest7 data</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="binomial.html"><a href="binomial.html"><i class="fa fa-check"></i><b>14</b> The Binomial Distribution</a><ul>
<li class="chapter" data-level="14.1" data-path="binomial.html"><a href="binomial.html#dbinom"><i class="fa fa-check"></i><b>14.1</b> dbinom</a></li>
<li class="chapter" data-level="14.2" data-path="binomial.html"><a href="binomial.html#pbinom"><i class="fa fa-check"></i><b>14.2</b> pbinom</a></li>
<li class="chapter" data-level="14.3" data-path="binomial.html"><a href="binomial.html#qbinom"><i class="fa fa-check"></i><b>14.3</b> qbinom</a></li>
<li class="chapter" data-level="14.4" data-path="binomial.html"><a href="binomial.html#rbinom"><i class="fa fa-check"></i><b>14.4</b> rbinom</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="poisson.html"><a href="poisson.html"><i class="fa fa-check"></i><b>15</b> The Poisson Distribution</a><ul>
<li class="chapter" data-level="15.1" data-path="poisson.html"><a href="poisson.html#poisson-events"><i class="fa fa-check"></i><b>15.1</b> Poisson Events</a></li>
<li class="chapter" data-level="15.2" data-path="poisson.html"><a href="poisson.html#dpois"><i class="fa fa-check"></i><b>15.2</b> dpois</a></li>
<li class="chapter" data-level="15.3" data-path="poisson.html"><a href="poisson.html#ppois"><i class="fa fa-check"></i><b>15.3</b> ppois</a></li>
<li class="chapter" data-level="15.4" data-path="poisson.html"><a href="poisson.html#rpois"><i class="fa fa-check"></i><b>15.4</b> rpois</a></li>
<li class="chapter" data-level="15.5" data-path="poisson.html"><a href="poisson.html#overdispersion"><i class="fa fa-check"></i><b>15.5</b> Overdispersion</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="normal.html"><a href="normal.html"><i class="fa fa-check"></i><b>16</b> The Normal Distribution</a><ul>
<li class="chapter" data-level="16.0.1" data-path="normal.html"><a href="normal.html#the-standard-normal"><i class="fa fa-check"></i><b>16.0.1</b> The Standard Normal</a></li>
<li class="chapter" data-level="16.1" data-path="normal.html"><a href="normal.html#dnorm"><i class="fa fa-check"></i><b>16.1</b> dnorm</a></li>
<li class="chapter" data-level="16.2" data-path="normal.html"><a href="normal.html#pnorm"><i class="fa fa-check"></i><b>16.2</b> pnorm</a><ul>
<li class="chapter" data-level="" data-path="normal.html"><a href="normal.html#calculating-p-values-using-pnorm"><i class="fa fa-check"></i>Calculating “p-values”" using pnorm</a></li>
<li class="chapter" data-level="" data-path="normal.html"><a href="normal.html#calculating-percentiles-using-pnorm"><i class="fa fa-check"></i>Calculating percentiles using pnorm</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="normal.html"><a href="normal.html#qnorm"><i class="fa fa-check"></i><b>16.3</b> qnorm</a></li>
<li class="chapter" data-level="16.4" data-path="normal.html"><a href="normal.html#rnorm"><i class="fa fa-check"></i><b>16.4</b> rnorm</a><ul>
<li class="chapter" data-level="16.4.1" data-path="normal.html"><a href="normal.html#plotting-histograms-of-some-rnorm-samples"><i class="fa fa-check"></i><b>16.4.1</b> Plotting histograms of some rnorm samples</a></li>
<li class="chapter" data-level="16.4.2" data-path="normal.html"><a href="normal.html#bins-and-binwidth"><i class="fa fa-check"></i><b>16.4.2</b> Bins and Binwidth</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="categorical.html"><a href="categorical.html"><i class="fa fa-check"></i><b>17</b> Statistics for Categorical Data</a><ul>
<li class="chapter" data-level="17.1" data-path="categorical.html"><a href="categorical.html#types-of-categorical-data"><i class="fa fa-check"></i><b>17.1</b> Types of categorical data</a><ul>
<li class="chapter" data-level="17.1.1" data-path="categorical.html"><a href="categorical.html#proportions"><i class="fa fa-check"></i><b>17.1.1</b> Proportions</a></li>
<li class="chapter" data-level="17.1.2" data-path="categorical.html"><a href="categorical.html#frequencies"><i class="fa fa-check"></i><b>17.1.2</b> Frequencies</a></li>
<li class="chapter" data-level="17.1.3" data-path="categorical.html"><a href="categorical.html#associations"><i class="fa fa-check"></i><b>17.1.3</b> Associations</a></li>
<li class="chapter" data-level="17.1.4" data-path="categorical.html"><a href="categorical.html#statistics-covered-here"><i class="fa fa-check"></i><b>17.1.4</b> Statistics Covered Here</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="categorical.html"><a href="categorical.html#exact-v-asymptotic-calculations-of-p-values"><i class="fa fa-check"></i><b>17.2</b> Exact v Asymptotic Calculations of p-values</a><ul>
<li class="chapter" data-level="17.2.1" data-path="categorical.html"><a href="categorical.html#choosing-exact-or-asymptotic"><i class="fa fa-check"></i><b>17.2.1</b> Choosing exact or asymptotic</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="categorical.html"><a href="categorical.html#overview-of-the-types-of-hypothesis-testing"><i class="fa fa-check"></i><b>17.3</b> Overview of the types of hypothesis testing</a><ul>
<li class="chapter" data-level="17.3.1" data-path="categorical.html"><a href="categorical.html#proportion-analysis"><i class="fa fa-check"></i><b>17.3.1</b> Proportion analysis</a></li>
<li class="chapter" data-level="17.3.2" data-path="categorical.html"><a href="categorical.html#goodness-of-fit-testing"><i class="fa fa-check"></i><b>17.3.2</b> Goodness of fit testing</a></li>
<li class="chapter" data-level="17.3.3" data-path="categorical.html"><a href="categorical.html#contingency-analysis"><i class="fa fa-check"></i><b>17.3.3</b> Contingency Analysis</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="categorical.html"><a href="categorical.html#comparing-proportions"><i class="fa fa-check"></i><b>17.4</b> Comparing proportions</a><ul>
<li class="chapter" data-level="17.4.1" data-path="categorical.html"><a href="categorical.html#a-mouse-t-cell-pilot-experiment-the-cytokine-inducible-antigen-gradstudin"><i class="fa fa-check"></i><b>17.4.1</b> A Mouse T Cell Pilot Experiment: The Cytokine-inducible antigen gradstudin</a></li>
<li class="chapter" data-level="17.4.2" data-path="categorical.html"><a href="categorical.html#calculating-proportions"><i class="fa fa-check"></i><b>17.4.2</b> Calculating Proportions</a></li>
<li class="chapter" data-level="17.4.3" data-path="categorical.html"><a href="categorical.html#what-a-proportion-estimates"><i class="fa fa-check"></i><b>17.4.3</b> What A Proportion Estimates</a></li>
<li class="chapter" data-level="17.4.4" data-path="categorical.html"><a href="categorical.html#confidence-intervals-of-proportions"><i class="fa fa-check"></i><b>17.4.4</b> Confidence Intervals of Proportions</a></li>
<li class="chapter" data-level="17.4.5" data-path="categorical.html"><a href="categorical.html#a-one-sample-proportion-test"><i class="fa fa-check"></i><b>17.4.5</b> A One-Sample Proportion Test</a></li>
<li class="chapter" data-level="17.4.6" data-path="categorical.html"><a href="categorical.html#an-exact-test-for-one-proportion"><i class="fa fa-check"></i><b>17.4.6</b> An exact test for one proportion</a></li>
<li class="chapter" data-level="17.4.7" data-path="categorical.html"><a href="categorical.html#comparing-two-proportions"><i class="fa fa-check"></i><b>17.4.7</b> Comparing Two Proportions</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="categorical.html"><a href="categorical.html#exact-tests-for-two-proportions"><i class="fa fa-check"></i><b>17.5</b> Exact tests for two proportions</a></li>
<li class="chapter" data-level="17.6" data-path="categorical.html"><a href="categorical.html#goodness-of-fit-tests"><i class="fa fa-check"></i><b>17.6</b> Goodness of fit Tests</a><ul>
<li class="chapter" data-level="17.6.1" data-path="categorical.html"><a href="categorical.html#an-exact-goodness-of-fit-test"><i class="fa fa-check"></i><b>17.6.1</b> An Exact Goodness of Fit test</a></li>
<li class="chapter" data-level="17.6.2" data-path="categorical.html"><a href="categorical.html#an-approximate-goodness-of-fit-test"><i class="fa fa-check"></i><b>17.6.2</b> An Approximate Goodness of Fit test</a></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="categorical.html"><a href="categorical.html#contingency-testing"><i class="fa fa-check"></i><b>17.7</b> Contingency Testing</a><ul>
<li class="chapter" data-level="17.7.1" data-path="categorical.html"><a href="categorical.html#interpretation-of-contingency-results"><i class="fa fa-check"></i><b>17.7.1</b> Interpretation of Contingency Results</a></li>
<li class="chapter" data-level="17.7.2" data-path="categorical.html"><a href="categorical.html#write-up-4"><i class="fa fa-check"></i><b>17.7.2</b> Write Up</a></li>
<li class="chapter" data-level="17.7.3" data-path="categorical.html"><a href="categorical.html#interpretation-of-chi-square-output"><i class="fa fa-check"></i><b>17.7.3</b> Interpretation of chi-square output</a></li>
<li class="chapter" data-level="17.7.4" data-path="categorical.html"><a href="categorical.html#write-up-5"><i class="fa fa-check"></i><b>17.7.4</b> Write Up</a></li>
<li class="chapter" data-level="17.7.5" data-path="categorical.html"><a href="categorical.html#which-contingency-test-is-best"><i class="fa fa-check"></i><b>17.7.5</b> Which contingency test is best?</a></li>
<li class="chapter" data-level="17.7.6" data-path="categorical.html"><a href="categorical.html#higher-dimension-contingency-analysis"><i class="fa fa-check"></i><b>17.7.6</b> Higher dimension contingency analysis</a></li>
<li class="chapter" data-level="17.7.7" data-path="categorical.html"><a href="categorical.html#other-experimental-designs-involving-categorical-data"><i class="fa fa-check"></i><b>17.7.7</b> Other experimental designs involving categorical data</a></li>
</ul></li>
<li class="chapter" data-level="17.8" data-path="categorical.html"><a href="categorical.html#power-analysis-for-proportion-tests"><i class="fa fa-check"></i><b>17.8</b> Power analysis for proportion tests</a></li>
<li class="chapter" data-level="17.9" data-path="categorical.html"><a href="categorical.html#power-analysis-functions-for-proportion-tests"><i class="fa fa-check"></i><b>17.9</b> Power analysis functions for proportion tests</a></li>
<li class="chapter" data-level="17.10" data-path="categorical.html"><a href="categorical.html#graphing-proportions"><i class="fa fa-check"></i><b>17.10</b> Graphing Proportions</a></li>
<li class="chapter" data-level="17.11" data-path="categorical.html"><a href="categorical.html#key-takeaways"><i class="fa fa-check"></i><b>17.11</b> Key Takeaways</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="chisquare.html"><a href="chisquare.html"><i class="fa fa-check"></i><b>18</b> The Chi-square Distribution</a><ul>
<li class="chapter" data-level="18.1" data-path="chisquare.html"><a href="chisquare.html#background"><i class="fa fa-check"></i><b>18.1</b> Background</a></li>
<li class="chapter" data-level="18.2" data-path="chisquare.html"><a href="chisquare.html#dchisq"><i class="fa fa-check"></i><b>18.2</b> dchisq</a></li>
<li class="chapter" data-level="18.3" data-path="chisquare.html"><a href="chisquare.html#pchisq"><i class="fa fa-check"></i><b>18.3</b> pchisq</a><ul>
<li class="chapter" data-level="18.3.1" data-path="chisquare.html"><a href="chisquare.html#calculating-p-values-from-pchisq"><i class="fa fa-check"></i><b>18.3.1</b> Calculating p-values from pchisq</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="chisquare.html"><a href="chisquare.html#qchisq"><i class="fa fa-check"></i><b>18.4</b> qchisq</a></li>
<li class="chapter" data-level="18.5" data-path="chisquare.html"><a href="chisquare.html#rchisq"><i class="fa fa-check"></i><b>18.5</b> rchisq</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="nonparametrics.html"><a href="nonparametrics.html"><i class="fa fa-check"></i><b>19</b> Nonparametric Statistical Tests</a><ul>
<li class="chapter" data-level="19.1" data-path="nonparametrics.html"><a href="nonparametrics.html#nonparametric-sampling-distributions"><i class="fa fa-check"></i><b>19.1</b> Nonparametric sampling distributions</a></li>
<li class="chapter" data-level="19.2" data-path="nonparametrics.html"><a href="nonparametrics.html#experiments-involving-discrete-data"><i class="fa fa-check"></i><b>19.2</b> Experiments involving discrete data</a><ul>
<li class="chapter" data-level="19.2.1" data-path="nonparametrics.html"><a href="nonparametrics.html#ordered-data-1"><i class="fa fa-check"></i><b>19.2.1</b> Ordered data</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="nonparametrics.html"><a href="nonparametrics.html#experiments-involving-deviant-data"><i class="fa fa-check"></i><b>19.3</b> Experiments involving deviant Data</a></li>
<li class="chapter" data-level="19.4" data-path="nonparametrics.html"><a href="nonparametrics.html#sign-test"><i class="fa fa-check"></i><b>19.4</b> Sign Test</a><ul>
<li class="chapter" data-level="19.4.1" data-path="nonparametrics.html"><a href="nonparametrics.html#interpretation-1"><i class="fa fa-check"></i><b>19.4.1</b> Interpretation</a></li>
<li class="chapter" data-level="19.4.2" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-6"><i class="fa fa-check"></i><b>19.4.2</b> Write Up</a></li>
</ul></li>
<li class="chapter" data-level="19.5" data-path="nonparametrics.html"><a href="nonparametrics.html#wilcoxon-sign-rank-test-for-one-group"><i class="fa fa-check"></i><b>19.5</b> Wilcoxon Sign Rank Test for One Group</a><ul>
<li class="chapter" data-level="19.5.1" data-path="nonparametrics.html"><a href="nonparametrics.html#wilcoxon-sign-rank-experimental-designs"><i class="fa fa-check"></i><b>19.5.1</b> Wilcoxon Sign Rank Experimental Designs</a></li>
<li class="chapter" data-level="19.5.2" data-path="nonparametrics.html"><a href="nonparametrics.html#interpretation-2"><i class="fa fa-check"></i><b>19.5.2</b> Interpretation</a></li>
<li class="chapter" data-level="19.5.3" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-7"><i class="fa fa-check"></i><b>19.5.3</b> Write Up</a></li>
</ul></li>
<li class="chapter" data-level="19.6" data-path="nonparametrics.html"><a href="nonparametrics.html#wilcoxon-mann-whitney-rank-sum-test-for-2-independent-groups"><i class="fa fa-check"></i><b>19.6</b> Wilcoxon Mann Whitney Rank Sum Test for 2 independent groups</a><ul>
<li class="chapter" data-level="19.6.1" data-path="nonparametrics.html"><a href="nonparametrics.html#interpretation-3"><i class="fa fa-check"></i><b>19.6.1</b> Interpretation</a></li>
<li class="chapter" data-level="19.6.2" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-8"><i class="fa fa-check"></i><b>19.6.2</b> Write Up</a></li>
<li class="chapter" data-level="19.6.3" data-path="nonparametrics.html"><a href="nonparametrics.html#plot"><i class="fa fa-check"></i><b>19.6.3</b> Plot</a></li>
</ul></li>
<li class="chapter" data-level="19.7" data-path="nonparametrics.html"><a href="nonparametrics.html#wilcoxon-sign-rank-test-for-paired-groups"><i class="fa fa-check"></i><b>19.7</b> Wilcoxon Sign Rank Test for paired groups</a><ul>
<li class="chapter" data-level="19.7.1" data-path="nonparametrics.html"><a href="nonparametrics.html#interpretation-4"><i class="fa fa-check"></i><b>19.7.1</b> Interpretation</a></li>
<li class="chapter" data-level="19.7.2" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-9"><i class="fa fa-check"></i><b>19.7.2</b> Write up</a></li>
<li class="chapter" data-level="19.7.3" data-path="nonparametrics.html"><a href="nonparametrics.html#plot-1"><i class="fa fa-check"></i><b>19.7.3</b> Plot</a></li>
</ul></li>
<li class="chapter" data-level="19.8" data-path="nonparametrics.html"><a href="nonparametrics.html#kruskal-wallis"><i class="fa fa-check"></i><b>19.8</b> Kruskal-Wallis</a><ul>
<li class="chapter" data-level="19.8.1" data-path="nonparametrics.html"><a href="nonparametrics.html#the-experimental-design"><i class="fa fa-check"></i><b>19.8.1</b> The experimental design</a></li>
<li class="chapter" data-level="19.8.2" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-10"><i class="fa fa-check"></i><b>19.8.2</b> Write Up</a></li>
</ul></li>
<li class="chapter" data-level="19.9" data-path="nonparametrics.html"><a href="nonparametrics.html#friedman-test"><i class="fa fa-check"></i><b>19.9</b> Friedman test</a><ul>
<li class="chapter" data-level="19.9.1" data-path="nonparametrics.html"><a href="nonparametrics.html#blocked-experimental-design"><i class="fa fa-check"></i><b>19.9.1</b> Blocked experimental design</a></li>
<li class="chapter" data-level="19.9.2" data-path="nonparametrics.html"><a href="nonparametrics.html#interpretation-5"><i class="fa fa-check"></i><b>19.9.2</b> Interpretation</a></li>
<li class="chapter" data-level="19.9.3" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-11"><i class="fa fa-check"></i><b>19.9.3</b> Write up</a></li>
</ul></li>
<li class="chapter" data-level="19.10" data-path="nonparametrics.html"><a href="nonparametrics.html#nonparametric-power-calculations"><i class="fa fa-check"></i><b>19.10</b> Nonparametric power calculations</a><ul>
<li class="chapter" data-level="19.10.1" data-path="nonparametrics.html"><a href="nonparametrics.html#how-it-works"><i class="fa fa-check"></i><b>19.10.1</b> How it works</a></li>
<li class="chapter" data-level="19.10.2" data-path="nonparametrics.html"><a href="nonparametrics.html#simulating-response-data"><i class="fa fa-check"></i><b>19.10.2</b> Simulating response data</a></li>
<li class="chapter" data-level="19.10.3" data-path="nonparametrics.html"><a href="nonparametrics.html#an-example"><i class="fa fa-check"></i><b>19.10.3</b> An example</a></li>
<li class="chapter" data-level="19.10.4" data-path="nonparametrics.html"><a href="nonparametrics.html#nonpara.pwr"><i class="fa fa-check"></i><b>19.10.4</b> nonpara.pwr</a></li>
</ul></li>
<li class="chapter" data-level="19.11" data-path="nonparametrics.html"><a href="nonparametrics.html#summary-1"><i class="fa fa-check"></i><b>19.11</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="signrank.html"><a href="signrank.html"><i class="fa fa-check"></i><b>20</b> Signed Rank Distribution</a><ul>
<li class="chapter" data-level="20.1" data-path="signrank.html"><a href="signrank.html#transformation-of-data-into-sign-ranks"><i class="fa fa-check"></i><b>20.1</b> Transformation of data into sign ranks</a><ul>
<li class="chapter" data-level="20.1.1" data-path="signrank.html"><a href="signrank.html#for-a-one-group-sample"><i class="fa fa-check"></i><b>20.1.1</b> For a one group sample</a></li>
<li class="chapter" data-level="20.1.2" data-path="signrank.html"><a href="signrank.html#for-a-paired-sample"><i class="fa fa-check"></i><b>20.1.2</b> For a paired sample</a></li>
<li class="chapter" data-level="20.1.3" data-path="signrank.html"><a href="signrank.html#the-sign-rank-test-statistic-in-r"><i class="fa fa-check"></i><b>20.1.3</b> The sign rank test statistic in R</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="signrank.html"><a href="signrank.html#rs-four-sign-rank-distribution-functions"><i class="fa fa-check"></i><b>20.2</b> R’s Four Sign Rank Distribution Functions</a><ul>
<li class="chapter" data-level="20.2.1" data-path="signrank.html"><a href="signrank.html#dsignrank"><i class="fa fa-check"></i><b>20.2.1</b> dsignrank</a></li>
<li class="chapter" data-level="20.2.2" data-path="signrank.html"><a href="signrank.html#psignrank"><i class="fa fa-check"></i><b>20.2.2</b> psignrank</a></li>
<li class="chapter" data-level="20.2.3" data-path="signrank.html"><a href="signrank.html#qsignrank"><i class="fa fa-check"></i><b>20.2.3</b> qsignrank</a></li>
<li class="chapter" data-level="20.2.4" data-path="signrank.html"><a href="signrank.html#rsignrank"><i class="fa fa-check"></i><b>20.2.4</b> rsignrank</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="ranksum.html"><a href="ranksum.html"><i class="fa fa-check"></i><b>21</b> Rank Sum Distribution</a><ul>
<li class="chapter" data-level="21.0.1" data-path="ranksum.html"><a href="ranksum.html#transformation-of-data-into-rank-summs"><i class="fa fa-check"></i><b>21.0.1</b> Transformation of data into rank summs</a></li>
<li class="chapter" data-level="21.0.2" data-path="ranksum.html"><a href="ranksum.html#the-sign-rank-test-statistic-in-r-1"><i class="fa fa-check"></i><b>21.0.2</b> The sign rank test statistic in R</a></li>
<li class="chapter" data-level="21.1" data-path="ranksum.html"><a href="ranksum.html#rs-four-sign-rank-distribution-functions-1"><i class="fa fa-check"></i><b>21.1</b> R’s Four Sign Rank Distribution Functions</a><ul>
<li class="chapter" data-level="21.1.1" data-path="ranksum.html"><a href="ranksum.html#dwilcox"><i class="fa fa-check"></i><b>21.1.1</b> dwilcox</a></li>
<li class="chapter" data-level="21.1.2" data-path="ranksum.html"><a href="ranksum.html#pwilcox"><i class="fa fa-check"></i><b>21.1.2</b> pwilcox</a></li>
<li class="chapter" data-level="21.1.3" data-path="ranksum.html"><a href="ranksum.html#qwilcox"><i class="fa fa-check"></i><b>21.1.3</b> qwilcox</a></li>
<li class="chapter" data-level="21.1.4" data-path="ranksum.html"><a href="ranksum.html#rwilcox"><i class="fa fa-check"></i><b>21.1.4</b> rwilcox</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="ttests.html"><a href="ttests.html"><i class="fa fa-check"></i><b>22</b> The t-tests</a><ul>
<li class="chapter" data-level="22.1" data-path="ttests.html"><a href="ttests.html#data-assumptions-for-t-tests"><i class="fa fa-check"></i><b>22.1</b> Data assumptions for t-tests</a></li>
<li class="chapter" data-level="22.2" data-path="ttests.html"><a href="ttests.html#the-t-statistic"><i class="fa fa-check"></i><b>22.2</b> The t Statistic</a><ul>
<li class="chapter" data-level="22.2.1" data-path="ttests.html"><a href="ttests.html#one-sample-t-tests"><i class="fa fa-check"></i><b>22.2.1</b> One sample t tests</a></li>
<li class="chapter" data-level="22.2.2" data-path="ttests.html"><a href="ttests.html#unpaired-t-tests"><i class="fa fa-check"></i><b>22.2.2</b> Unpaired t tests</a></li>
<li class="chapter" data-level="22.2.3" data-path="ttests.html"><a href="ttests.html#paired-t-tests"><i class="fa fa-check"></i><b>22.2.3</b> Paired t tests</a></li>
</ul></li>
<li class="chapter" data-level="22.3" data-path="ttests.html"><a href="ttests.html#t-test-hypotheses"><i class="fa fa-check"></i><b>22.3</b> t Test Hypotheses</a><ul>
<li class="chapter" data-level="22.3.1" data-path="ttests.html"><a href="ttests.html#one-sided-or-two-sided"><i class="fa fa-check"></i><b>22.3.1</b> One-sided or two-sided??</a></li>
<li class="chapter" data-level="22.3.2" data-path="ttests.html"><a href="ttests.html#one-sample-hypotheses"><i class="fa fa-check"></i><b>22.3.2</b> One sample hypotheses</a></li>
<li class="chapter" data-level="22.3.3" data-path="ttests.html"><a href="ttests.html#unpaired-hypotheses"><i class="fa fa-check"></i><b>22.3.3</b> Unpaired hypotheses</a></li>
<li class="chapter" data-level="22.3.4" data-path="ttests.html"><a href="ttests.html#paired-hypotheses"><i class="fa fa-check"></i><b>22.3.4</b> Paired hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="22.4" data-path="ttests.html"><a href="ttests.html#confidence-intervals-of-means"><i class="fa fa-check"></i><b>22.4</b> Confidence Intervals of Means</a></li>
<li class="chapter" data-level="22.5" data-path="ttests.html"><a href="ttests.html#parameters-small-samples-and-reliability"><i class="fa fa-check"></i><b>22.5</b> Parameters, small samples, and reliability</a><ul>
<li class="chapter" data-level="22.5.1" data-path="ttests.html"><a href="ttests.html#reporting-sd-or-sem"><i class="fa fa-check"></i><b>22.5.1</b> Reporting SD or SEM?</a></li>
</ul></li>
<li class="chapter" data-level="22.6" data-path="ttests.html"><a href="ttests.html#t-tests-running-the-analysis"><i class="fa fa-check"></i><b>22.6</b> t Tests: Running the analysis</a><ul>
<li class="chapter" data-level="22.6.1" data-path="ttests.html"><a href="ttests.html#one-sample-t-test"><i class="fa fa-check"></i><b>22.6.1</b> One sample t test</a></li>
<li class="chapter" data-level="22.6.2" data-path="ttests.html"><a href="ttests.html#unpaired-t-test"><i class="fa fa-check"></i><b>22.6.2</b> Unpaired t test</a></li>
<li class="chapter" data-level="22.6.3" data-path="ttests.html"><a href="ttests.html#paired-t-test"><i class="fa fa-check"></i><b>22.6.3</b> Paired t Test</a></li>
</ul></li>
<li class="chapter" data-level="22.7" data-path="ttests.html"><a href="ttests.html#plotting-t-tests"><i class="fa fa-check"></i><b>22.7</b> Plotting t Tests</a><ul>
<li class="chapter" data-level="22.7.1" data-path="ttests.html"><a href="ttests.html#one-sample"><i class="fa fa-check"></i><b>22.7.1</b> One-sample</a></li>
<li class="chapter" data-level="22.7.2" data-path="ttests.html"><a href="ttests.html#unpaired"><i class="fa fa-check"></i><b>22.7.2</b> Unpaired</a></li>
<li class="chapter" data-level="22.7.3" data-path="ttests.html"><a href="ttests.html#paired"><i class="fa fa-check"></i><b>22.7.3</b> Paired</a></li>
</ul></li>
<li class="chapter" data-level="22.8" data-path="ttests.html"><a href="ttests.html#t-test-power"><i class="fa fa-check"></i><b>22.8</b> t Test Power</a><ul>
<li class="chapter" data-level="22.8.1" data-path="ttests.html"><a href="ttests.html#pwr.t.test"><i class="fa fa-check"></i><b>22.8.1</b> pwr.t.test</a></li>
<li class="chapter" data-level="22.8.2" data-path="ttests.html"><a href="ttests.html#interpretation-9"><i class="fa fa-check"></i><b>22.8.2</b> Interpretation</a></li>
<li class="chapter" data-level="22.8.3" data-path="ttests.html"><a href="ttests.html#t-pwr-a-monte-carlo-method"><i class="fa fa-check"></i><b>22.8.3</b> t-pwr: A Monte Carlo method</a></li>
</ul></li>
<li class="chapter" data-level="22.9" data-path="ttests.html"><a href="ttests.html#summary-2"><i class="fa fa-check"></i><b>22.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="ttestmc.html"><a href="ttestmc.html"><i class="fa fa-check"></i><b>23</b> Statistical design of t-tests</a><ul>
<li class="chapter" data-level="23.1" data-path="ttestmc.html"><a href="ttestmc.html#about-this-chapter"><i class="fa fa-check"></i><b>23.1</b> About this chapter</a><ul>
<li class="chapter" data-level="23.1.1" data-path="ttestmc.html"><a href="ttestmc.html#overview-of-the-monte-carlo"><i class="fa fa-check"></i><b>23.1.1</b> Overview of the Monte Carlo</a></li>
<li class="chapter" data-level="23.1.2" data-path="ttestmc.html"><a href="ttestmc.html#tldr-on-data-simulation"><i class="fa fa-check"></i><b>23.1.2</b> tl;dr on data simulation</a></li>
<li class="chapter" data-level="23.1.3" data-path="ttestmc.html"><a href="ttestmc.html#tldr-on-the-test"><i class="fa fa-check"></i><b>23.1.3</b> tl;dr on the test</a></li>
<li class="chapter" data-level="23.1.4" data-path="ttestmc.html"><a href="ttestmc.html#changing-n"><i class="fa fa-check"></i><b>23.1.4</b> Changing n</a></li>
<li class="chapter" data-level="23.1.5" data-path="ttestmc.html"><a href="ttestmc.html#diabetes-drug-scenario"><i class="fa fa-check"></i><b>23.1.5</b> Diabetes drug scenario</a></li>
<li class="chapter" data-level="23.1.6" data-path="ttestmc.html"><a href="ttestmc.html#what-would-be-a-scientifically-meaningful-response"><i class="fa fa-check"></i><b>23.1.6</b> What would be a scientifically meaningful response?</a></li>
</ul></li>
<li class="chapter" data-level="23.2" data-path="ttestmc.html"><a href="ttestmc.html#one-sample-t-test-monte-carlo"><i class="fa fa-check"></i><b>23.2</b> One sample t-test Monte Carlo</a><ul>
<li class="chapter" data-level="23.2.1" data-path="ttestmc.html"><a href="ttestmc.html#step-1"><i class="fa fa-check"></i><b>23.2.1</b> Step 1</a></li>
<li class="chapter" data-level="23.2.2" data-path="ttestmc.html"><a href="ttestmc.html#step-2"><i class="fa fa-check"></i><b>23.2.2</b> Step 2</a></li>
<li class="chapter" data-level="23.2.3" data-path="ttestmc.html"><a href="ttestmc.html#step-3"><i class="fa fa-check"></i><b>23.2.3</b> Step 3</a></li>
<li class="chapter" data-level="23.2.4" data-path="ttestmc.html"><a href="ttestmc.html#step-4"><i class="fa fa-check"></i><b>23.2.4</b> Step 4</a></li>
<li class="chapter" data-level="23.2.5" data-path="ttestmc.html"><a href="ttestmc.html#step-5"><i class="fa fa-check"></i><b>23.2.5</b> Step 5</a></li>
<li class="chapter" data-level="23.2.6" data-path="ttestmc.html"><a href="ttestmc.html#step-6"><i class="fa fa-check"></i><b>23.2.6</b> Step 6</a></li>
<li class="chapter" data-level="23.2.7" data-path="ttestmc.html"><a href="ttestmc.html#step-7"><i class="fa fa-check"></i><b>23.2.7</b> Step 7</a></li>
</ul></li>
<li class="chapter" data-level="23.3" data-path="ttestmc.html"><a href="ttestmc.html#unpaired-t-test-monte-carlo"><i class="fa fa-check"></i><b>23.3</b> Unpaired t-test Monte Carlo</a><ul>
<li class="chapter" data-level="23.3.1" data-path="ttestmc.html"><a href="ttestmc.html#step-1-1"><i class="fa fa-check"></i><b>23.3.1</b> Step 1</a></li>
<li class="chapter" data-level="23.3.2" data-path="ttestmc.html"><a href="ttestmc.html#step-2-1"><i class="fa fa-check"></i><b>23.3.2</b> Step 2</a></li>
<li class="chapter" data-level="23.3.3" data-path="ttestmc.html"><a href="ttestmc.html#step-3-1"><i class="fa fa-check"></i><b>23.3.3</b> Step 3</a></li>
<li class="chapter" data-level="23.3.4" data-path="ttestmc.html"><a href="ttestmc.html#step-4-1"><i class="fa fa-check"></i><b>23.3.4</b> Step 4</a></li>
<li class="chapter" data-level="23.3.5" data-path="ttestmc.html"><a href="ttestmc.html#step-5-1"><i class="fa fa-check"></i><b>23.3.5</b> Step 5</a></li>
<li class="chapter" data-level="23.3.6" data-path="ttestmc.html"><a href="ttestmc.html#step-6-1"><i class="fa fa-check"></i><b>23.3.6</b> Step 6</a></li>
<li class="chapter" data-level="23.3.7" data-path="ttestmc.html"><a href="ttestmc.html#step-7-1"><i class="fa fa-check"></i><b>23.3.7</b> Step 7</a></li>
</ul></li>
<li class="chapter" data-level="23.4" data-path="ttestmc.html"><a href="ttestmc.html#paired-t-test-monte-carlo"><i class="fa fa-check"></i><b>23.4</b> Paired t-test Monte Carlo</a><ul>
<li class="chapter" data-level="23.4.1" data-path="ttestmc.html"><a href="ttestmc.html#step-1-2"><i class="fa fa-check"></i><b>23.4.1</b> Step 1</a></li>
<li class="chapter" data-level="23.4.2" data-path="ttestmc.html"><a href="ttestmc.html#step-2-2"><i class="fa fa-check"></i><b>23.4.2</b> Step 2</a></li>
<li class="chapter" data-level="23.4.3" data-path="ttestmc.html"><a href="ttestmc.html#step-3-2"><i class="fa fa-check"></i><b>23.4.3</b> Step 3</a></li>
</ul></li>
<li class="chapter" data-level="23.5" data-path="ttestmc.html"><a href="ttestmc.html#step-4-2"><i class="fa fa-check"></i><b>23.5</b> Step 4</a><ul>
<li class="chapter" data-level="23.5.1" data-path="ttestmc.html"><a href="ttestmc.html#step-5-2"><i class="fa fa-check"></i><b>23.5.1</b> Step 5</a></li>
<li class="chapter" data-level="23.5.2" data-path="ttestmc.html"><a href="ttestmc.html#step-6-2"><i class="fa fa-check"></i><b>23.5.2</b> Step 6</a></li>
<li class="chapter" data-level="23.5.3" data-path="ttestmc.html"><a href="ttestmc.html#step-7-2"><i class="fa fa-check"></i><b>23.5.3</b> Step 7</a></li>
</ul></li>
<li class="chapter" data-level="23.6" data-path="ttestmc.html"><a href="ttestmc.html#comparison-to-pwr-tests"><i class="fa fa-check"></i><b>23.6</b> Comparison to pwr tests</a></li>
<li class="chapter" data-level="23.7" data-path="ttestmc.html"><a href="ttestmc.html#dt"><i class="fa fa-check"></i><b>23.7</b> dt</a></li>
<li class="chapter" data-level="23.8" data-path="ttestmc.html"><a href="ttestmc.html#pt"><i class="fa fa-check"></i><b>23.8</b> pt</a></li>
<li class="chapter" data-level="23.9" data-path="ttestmc.html"><a href="ttestmc.html#qt"><i class="fa fa-check"></i><b>23.9</b> qt</a></li>
<li class="chapter" data-level="23.10" data-path="ttestmc.html"><a href="ttestmc.html#rt"><i class="fa fa-check"></i><b>23.10</b> rt</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="simcorrelation.html"><a href="simcorrelation.html"><i class="fa fa-check"></i><b>24</b> Simulating correlated variables</a><ul>
<li class="chapter" data-level="24.1" data-path="simcorrelation.html"><a href="simcorrelation.html#estimating-correlation-between-two-variables"><i class="fa fa-check"></i><b>24.1</b> Estimating correlation between two variables</a></li>
<li class="chapter" data-level="24.2" data-path="simcorrelation.html"><a href="simcorrelation.html#simulating-correlated-variables"><i class="fa fa-check"></i><b>24.2</b> Simulating correlated variables</a></li>
<li class="chapter" data-level="24.3" data-path="simcorrelation.html"><a href="simcorrelation.html#monte-carlo-simulation"><i class="fa fa-check"></i><b>24.3</b> Monte Carlo simulation</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="introanova.html"><a href="introanova.html"><i class="fa fa-check"></i><b>25</b> Introduction to ANOVA</a><ul>
<li class="chapter" data-level="25.1" data-path="introanova.html"><a href="introanova.html#assumptions"><i class="fa fa-check"></i><b>25.1</b> Assumptions</a></li>
<li class="chapter" data-level="25.2" data-path="introanova.html"><a href="introanova.html#types-of-designs"><i class="fa fa-check"></i><b>25.2</b> Types of designs</a></li>
<li class="chapter" data-level="25.3" data-path="introanova.html"><a href="introanova.html#jargon-factors-and-levels"><i class="fa fa-check"></i><b>25.3</b> Jargon: Factors and levels</a><ul>
<li class="chapter" data-level="25.3.1" data-path="introanova.html"><a href="introanova.html#woring-with-factors-in-r"><i class="fa fa-check"></i><b>25.3.1</b> Woring with factors in R</a></li>
</ul></li>
<li class="chapter" data-level="25.4" data-path="introanova.html"><a href="introanova.html#anova-models-one--two--and-three-way"><i class="fa fa-check"></i><b>25.4</b> ANOVA models: One-, Two-, and Three-way</a></li>
<li class="chapter" data-level="25.5" data-path="introanova.html"><a href="introanova.html#inference"><i class="fa fa-check"></i><b>25.5</b> Inference</a><ul>
<li class="chapter" data-level="25.5.1" data-path="introanova.html"><a href="introanova.html#a-quick-peek-at-posthoc-testing"><i class="fa fa-check"></i><b>25.5.1</b> A quick peek at posthoc testing</a></li>
</ul></li>
<li class="chapter" data-level="25.6" data-path="introanova.html"><a href="introanova.html#anova-calculations"><i class="fa fa-check"></i><b>25.6</b> ANOVA calculations</a><ul>
<li class="chapter" data-level="25.6.1" data-path="introanova.html"><a href="introanova.html#sums-of-squares-partitioning"><i class="fa fa-check"></i><b>25.6.1</b> Sums of Squares partitioning</a></li>
<li class="chapter" data-level="25.6.2" data-path="introanova.html"><a href="introanova.html#the-anova-table"><i class="fa fa-check"></i><b>25.6.2</b> The ANOVA table</a></li>
<li class="chapter" data-level="25.6.3" data-path="introanova.html"><a href="introanova.html#post-hoc-group-comparisons"><i class="fa fa-check"></i><b>25.6.3</b> Post-hoc group comparisons</a></li>
</ul></li>
<li class="chapter" data-level="25.7" data-path="introanova.html"><a href="introanova.html#completely-randomized-or-related-measures"><i class="fa fa-check"></i><b>25.7</b> Completely randomized or related measures</a><ul>
<li class="chapter" data-level="25.7.1" data-path="introanova.html"><a href="introanova.html#the-problem-of-lost-data-in-related-measures-designs"><i class="fa fa-check"></i><b>25.7.1</b> The problem of lost data in related measures designs</a></li>
</ul></li>
<li class="chapter" data-level="25.8" data-path="introanova.html"><a href="introanova.html#two-way-anova"><i class="fa fa-check"></i><b>25.8</b> Two-way ANOVA</a></li>
<li class="chapter" data-level="25.9" data-path="introanova.html"><a href="introanova.html#other-anova-models"><i class="fa fa-check"></i><b>25.9</b> Other ANOVA models</a><ul>
<li class="chapter" data-level="25.9.1" data-path="introanova.html"><a href="introanova.html#r-and-anova"><i class="fa fa-check"></i><b>25.9.1</b> R and ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="25.10" data-path="introanova.html"><a href="introanova.html#alternatives-to-anova"><i class="fa fa-check"></i><b>25.10</b> Alternatives to ANOVA</a><ul>
<li class="chapter" data-level="25.10.1" data-path="introanova.html"><a href="introanova.html#screw-anova-just-tell-me-how-to-t-test-everything"><i class="fa fa-check"></i><b>25.10.1</b> Screw ANOVA, Just Tell Me How to t-Test Everything</a></li>
</ul></li>
<li class="chapter" data-level="25.11" data-path="introanova.html"><a href="introanova.html#summary-3"><i class="fa fa-check"></i><b>25.11</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="fdistr.html"><a href="fdistr.html"><i class="fa fa-check"></i><b>26</b> The F distribution</a><ul>
<li class="chapter" data-level="26.1" data-path="fdistr.html"><a href="fdistr.html#background-1"><i class="fa fa-check"></i><b>26.1</b> Background</a><ul>
<li class="chapter" data-level="26.1.1" data-path="fdistr.html"><a href="fdistr.html#sample-variance-and-fs-pdf"><i class="fa fa-check"></i><b>26.1.1</b> Sample Variance and F’s PDF</a></li>
</ul></li>
<li class="chapter" data-level="26.2" data-path="fdistr.html"><a href="fdistr.html#df"><i class="fa fa-check"></i><b>26.2</b> df</a></li>
<li class="chapter" data-level="26.3" data-path="fdistr.html"><a href="fdistr.html#pf"><i class="fa fa-check"></i><b>26.3</b> pf</a></li>
<li class="chapter" data-level="26.4" data-path="fdistr.html"><a href="fdistr.html#qf"><i class="fa fa-check"></i><b>26.4</b> qf</a></li>
<li class="chapter" data-level="26.5" data-path="fdistr.html"><a href="fdistr.html#rf"><i class="fa fa-check"></i><b>26.5</b> rf</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="onewayanova.html"><a href="onewayanova.html"><i class="fa fa-check"></i><b>27</b> One-way ANOVA Completely Randomized</a><ul>
<li class="chapter" data-level="27.1" data-path="onewayanova.html"><a href="onewayanova.html#using-ezanova"><i class="fa fa-check"></i><b>27.1</b> Using <code>ezANOVA</code></a></li>
<li class="chapter" data-level="27.2" data-path="onewayanova.html"><a href="onewayanova.html#the-chickwt-data-set"><i class="fa fa-check"></i><b>27.2</b> The chickwt data set</a><ul>
<li class="chapter" data-level="27.2.1" data-path="onewayanova.html"><a href="onewayanova.html#inspect-the-data"><i class="fa fa-check"></i><b>27.2.1</b> Inspect the data</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path="onewayanova.html"><a href="onewayanova.html#run-the-anova"><i class="fa fa-check"></i><b>27.3</b> Run the ANOVA</a><ul>
<li class="chapter" data-level="27.3.1" data-path="onewayanova.html"><a href="onewayanova.html#run-the-chickwts-one-way-anova"><i class="fa fa-check"></i><b>27.3.1</b> Run the chickwts One Way ANOVA</a></li>
<li class="chapter" data-level="27.3.2" data-path="onewayanova.html"><a href="onewayanova.html#interpreting-the-one-way-cr-anova-output"><i class="fa fa-check"></i><b>27.3.2</b> Interpreting the One-Way CR ANOVA Output</a></li>
</ul></li>
<li class="chapter" data-level="27.4" data-path="onewayanova.html"><a href="onewayanova.html#post-hoc-pairwise-comparisons"><i class="fa fa-check"></i><b>27.4</b> Post hoc pairwise comparisons</a><ul>
<li class="chapter" data-level="27.4.1" data-path="onewayanova.html"><a href="onewayanova.html#range-tests"><i class="fa fa-check"></i><b>27.4.1</b> Range tests</a></li>
</ul></li>
<li class="chapter" data-level="27.5" data-path="onewayanova.html"><a href="onewayanova.html#summary-4"><i class="fa fa-check"></i><b>27.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="onewayRM.html"><a href="onewayRM.html"><i class="fa fa-check"></i><b>28</b> One-way ANOVA Related Measures</a><ul>
<li class="chapter" data-level="28.1" data-path="onewayRM.html"><a href="onewayRM.html#data-prep"><i class="fa fa-check"></i><b>28.1</b> Data prep</a></li>
<li class="chapter" data-level="28.2" data-path="onewayRM.html"><a href="onewayRM.html#data-visualization"><i class="fa fa-check"></i><b>28.2</b> Data visualization</a><ul>
<li class="chapter" data-level="28.2.1" data-path="onewayRM.html"><a href="onewayRM.html#visualize-the-statistical-design"><i class="fa fa-check"></i><b>28.2.1</b> Visualize the statistical design</a></li>
</ul></li>
<li class="chapter" data-level="28.3" data-path="onewayRM.html"><a href="onewayRM.html#the-anova"><i class="fa fa-check"></i><b>28.3</b> The ANOVA</a><ul>
<li class="chapter" data-level="28.3.1" data-path="onewayRM.html"><a href="onewayRM.html#running-ezanova"><i class="fa fa-check"></i><b>28.3.1</b> Running ezANOVA</a></li>
</ul></li>
<li class="chapter" data-level="28.4" data-path="onewayRM.html"><a href="onewayRM.html#interpretation-10"><i class="fa fa-check"></i><b>28.4</b> Interpretation</a></li>
<li class="chapter" data-level="28.5" data-path="onewayRM.html"><a href="onewayRM.html#post-hoc-analysis"><i class="fa fa-check"></i><b>28.5</b> Post-hoc analysis</a></li>
<li class="chapter" data-level="28.6" data-path="onewayRM.html"><a href="onewayRM.html#write-up-12"><i class="fa fa-check"></i><b>28.6</b> Write up</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="twowayCR.html"><a href="twowayCR.html"><i class="fa fa-check"></i><b>29</b> Two-way ANOVA Completely Randomized</a><ul>
<li class="chapter" data-level="29.1" data-path="twowayCR.html"><a href="twowayCR.html#effect-of-strain-and-diet-on-liver"><i class="fa fa-check"></i><b>29.1</b> Effect of Strain and Diet on Liver</a></li>
<li class="chapter" data-level="29.2" data-path="twowayCR.html"><a href="twowayCR.html#the-test"><i class="fa fa-check"></i><b>29.2</b> The test</a></li>
<li class="chapter" data-level="29.3" data-path="twowayCR.html"><a href="twowayCR.html#interpretation-of-2-way-cr-anova-output"><i class="fa fa-check"></i><b>29.3</b> Interpretation of 2 Way CR ANOVA Output</a><ul>
<li class="chapter" data-level="29.3.1" data-path="twowayCR.html"><a href="twowayCR.html#levenes"><i class="fa fa-check"></i><b>29.3.1</b> Levene’s</a></li>
<li class="chapter" data-level="29.3.2" data-path="twowayCR.html"><a href="twowayCR.html#anova-table"><i class="fa fa-check"></i><b>29.3.2</b> ANOVA Table</a></li>
</ul></li>
<li class="chapter" data-level="29.4" data-path="twowayCR.html"><a href="twowayCR.html#post-hoc-multiple-comparisons"><i class="fa fa-check"></i><b>29.4</b> Post Hoc Multiple Comparisons</a><ul>
<li class="chapter" data-level="29.4.1" data-path="twowayCR.html"><a href="twowayCR.html#pairwise.t.tests"><i class="fa fa-check"></i><b>29.4.1</b> Pairwise.t.tests</a></li>
<li class="chapter" data-level="29.4.2" data-path="twowayCR.html"><a href="twowayCR.html#write-up-13"><i class="fa fa-check"></i><b>29.4.2</b> Write Up</a></li>
<li class="chapter" data-level="29.4.3" data-path="twowayCR.html"><a href="twowayCR.html#range-tests-1"><i class="fa fa-check"></i><b>29.4.3</b> Range tests</a></li>
</ul></li>
<li class="chapter" data-level="29.5" data-path="twowayCR.html"><a href="twowayCR.html#summary-5"><i class="fa fa-check"></i><b>29.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="twowayRM.html"><a href="twowayRM.html"><i class="fa fa-check"></i><b>30</b> Two-way ANOVA Related Measures</a><ul>
<li class="chapter" data-level="30.1" data-path="twowayRM.html"><a href="twowayRM.html#cell-culture"><i class="fa fa-check"></i><b>30.1</b> Cell culture</a></li>
<li class="chapter" data-level="30.2" data-path="twowayRM.html"><a href="twowayRM.html#the-test-1"><i class="fa fa-check"></i><b>30.2</b> The test</a></li>
<li class="chapter" data-level="30.3" data-path="twowayRM.html"><a href="twowayRM.html#interpretation-of-the-output"><i class="fa fa-check"></i><b>30.3</b> Interpretation of the output</a><ul>
<li class="chapter" data-level="30.3.1" data-path="twowayRM.html"><a href="twowayRM.html#anova-table-1"><i class="fa fa-check"></i><b>30.3.1</b> ANOVA Table</a></li>
<li class="chapter" data-level="30.3.2" data-path="twowayRM.html"><a href="twowayRM.html#mauchlys-sphericity-test"><i class="fa fa-check"></i><b>30.3.2</b> Mauchly’s Sphericity Test</a></li>
</ul></li>
<li class="chapter" data-level="30.4" data-path="twowayRM.html"><a href="twowayRM.html#post-hoc-multiple-comparisons-1"><i class="fa fa-check"></i><b>30.4</b> Post Hoc multiple comparisons</a></li>
<li class="chapter" data-level="30.5" data-path="twowayRM.html"><a href="twowayRM.html#write-up-14"><i class="fa fa-check"></i><b>30.5</b> Write Up</a></li>
<li class="chapter" data-level="30.6" data-path="twowayRM.html"><a href="twowayRM.html#summary-6"><i class="fa fa-check"></i><b>30.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="twowaymixed.html"><a href="twowaymixed.html"><i class="fa fa-check"></i><b>31</b> Two-way ANOVA RM/CR</a><ul>
<li class="chapter" data-level="31.1" data-path="twowaymixed.html"><a href="twowaymixed.html#chickweight-data-set"><i class="fa fa-check"></i><b>31.1</b> ChickWeight Data set</a></li>
<li class="chapter" data-level="31.2" data-path="twowaymixed.html"><a href="twowaymixed.html#munge-chickweight-data"><i class="fa fa-check"></i><b>31.2</b> Munge ChickWeight data</a></li>
<li class="chapter" data-level="31.3" data-path="twowaymixed.html"><a href="twowaymixed.html#the-test-2"><i class="fa fa-check"></i><b>31.3</b> The test</a></li>
<li class="chapter" data-level="31.4" data-path="twowaymixed.html"><a href="twowaymixed.html#interpreting-the-anova-output"><i class="fa fa-check"></i><b>31.4</b> Interpreting the ANOVA output</a><ul>
<li class="chapter" data-level="31.4.1" data-path="twowaymixed.html"><a href="twowaymixed.html#anova-the-anova-table-1"><i class="fa fa-check"></i><b>31.4.1</b> $ANOVA: The ANOVA table</a></li>
<li class="chapter" data-level="31.4.2" data-path="twowaymixed.html"><a href="twowaymixed.html#mauchlys-test-and-corrections"><i class="fa fa-check"></i><b>31.4.2</b> Mauchly’s Test and Corrections</a></li>
</ul></li>
<li class="chapter" data-level="31.5" data-path="twowaymixed.html"><a href="twowaymixed.html#post-hoc"><i class="fa fa-check"></i><b>31.5</b> Post hoc</a><ul>
<li class="chapter" data-level="31.5.1" data-path="twowaymixed.html"><a href="twowaymixed.html#pairwise.t.tests-1"><i class="fa fa-check"></i><b>31.5.1</b> Pairwise.t.tests</a></li>
<li class="chapter" data-level="31.5.2" data-path="twowaymixed.html"><a href="twowaymixed.html#tukey-test-a-range-test"><i class="fa fa-check"></i><b>31.5.2</b> Tukey test: A range test</a></li>
<li class="chapter" data-level="31.5.3" data-path="twowaymixed.html"><a href="twowaymixed.html#heres-whats-been-discovered-by-the-tukeyhsd-test"><i class="fa fa-check"></i><b>31.5.3</b> Here’s what’s been discovered by the TukeyHSD test</a></li>
<li class="chapter" data-level="31.5.4" data-path="twowaymixed.html"><a href="twowaymixed.html#why-is-the-tukeyhsd-result-so-different-than-the-pairwise.t.test"><i class="fa fa-check"></i><b>31.5.4</b> Why is the TukeyHSD result so different than the pairwise.t.test??</a></li>
</ul></li>
<li class="chapter" data-level="31.6" data-path="twowaymixed.html"><a href="twowaymixed.html#summary-7"><i class="fa fa-check"></i><b>31.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="posthoc.html"><a href="posthoc.html"><i class="fa fa-check"></i><b>32</b> ANOVA Posthoc Comparisons</a><ul>
<li class="chapter" data-level="32.1" data-path="posthoc.html"><a href="posthoc.html#overview-of-options"><i class="fa fa-check"></i><b>32.1</b> Overview of options</a><ul>
<li class="chapter" data-level="32.1.1" data-path="posthoc.html"><a href="posthoc.html#pairwise.t.test-with-p-value-adjustments"><i class="fa fa-check"></i><b>32.1.1</b> Pairwise.t.test with p-value adjustments</a></li>
<li class="chapter" data-level="32.1.2" data-path="posthoc.html"><a href="posthoc.html#range-tests-2"><i class="fa fa-check"></i><b>32.1.2</b> Range tests</a></li>
</ul></li>
<li class="chapter" data-level="32.2" data-path="posthoc.html"><a href="posthoc.html#reporting-the-result-1"><i class="fa fa-check"></i><b>32.2</b> Reporting the result</a></li>
<li class="chapter" data-level="32.3" data-path="posthoc.html"><a href="posthoc.html#summary-8"><i class="fa fa-check"></i><b>32.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="33" data-path="jaxwest2.html"><a href="jaxwest2.html"><i class="fa fa-check"></i><b>33</b> Reproducible Data Munging Mostly with Tidyverse</a><ul>
<li class="chapter" data-level="33.1" data-path="jaxwest2.html"><a href="jaxwest2.html#look-at-the-original-data-carefully"><i class="fa fa-check"></i><b>33.1</b> Look at the original data carefully</a></li>
<li class="chapter" data-level="33.2" data-path="jaxwest2.html"><a href="jaxwest2.html#our-goal"><i class="fa fa-check"></i><b>33.2</b> Our goal</a></li>
<li class="chapter" data-level="33.3" data-path="jaxwest2.html"><a href="jaxwest2.html#step-1-read-the-data-into-r"><i class="fa fa-check"></i><b>33.3</b> Step 1: Read the data into R</a></li>
<li class="chapter" data-level="33.4" data-path="jaxwest2.html"><a href="jaxwest2.html#step-2-select-the-variables"><i class="fa fa-check"></i><b>33.4</b> Step 2: Select the variables</a></li>
<li class="chapter" data-level="33.5" data-path="jaxwest2.html"><a href="jaxwest2.html#step-3-trim-the-cases"><i class="fa fa-check"></i><b>33.5</b> Step 3: Trim the cases</a></li>
<li class="chapter" data-level="33.6" data-path="jaxwest2.html"><a href="jaxwest2.html#step-4-we-have-a-variable-problem-to-fix"><i class="fa fa-check"></i><b>33.6</b> Step 4: We have a variable problem to fix</a></li>
<li class="chapter" data-level="33.7" data-path="jaxwest2.html"><a href="jaxwest2.html#step-5-impute-or-delete"><i class="fa fa-check"></i><b>33.7</b> Step 5: Impute or Delete</a></li>
<li class="chapter" data-level="33.8" data-path="jaxwest2.html"><a href="jaxwest2.html#step-6-go-long"><i class="fa fa-check"></i><b>33.8</b> Step 6: Go long</a></li>
<li class="chapter" data-level="33.9" data-path="jaxwest2.html"><a href="jaxwest2.html#step-7-convert-other-variables-to-factor"><i class="fa fa-check"></i><b>33.9</b> Step 7: Convert other variables to factor</a></li>
<li class="chapter" data-level="33.10" data-path="jaxwest2.html"><a href="jaxwest2.html#step-8-plot"><i class="fa fa-check"></i><b>33.10</b> Step 8: Plot</a></li>
<li class="chapter" data-level="33.11" data-path="jaxwest2.html"><a href="jaxwest2.html#step-9-run-the-anova"><i class="fa fa-check"></i><b>33.11</b> Step 9: Run the ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="anovamc.html"><a href="anovamc.html"><i class="fa fa-check"></i><b>34</b> ANOVA power using Monte Carlo</a><ul>
<li class="chapter" data-level="34.1" data-path="anovamc.html"><a href="anovamc.html#alternatives-to-monte-carlo"><i class="fa fa-check"></i><b>34.1</b> Alternatives to Monte Carlo</a></li>
<li class="chapter" data-level="34.2" data-path="anovamc.html"><a href="anovamc.html#what-is-monte-carlo"><i class="fa fa-check"></i><b>34.2</b> What is Monte Carlo</a></li>
<li class="chapter" data-level="34.3" data-path="anovamc.html"><a href="anovamc.html#one-way-completely-randomized-anova-monte-carlo"><i class="fa fa-check"></i><b>34.3</b> One-way completely randomized ANOVA Monte Carlo</a><ul>
<li class="chapter" data-level="34.3.1" data-path="anovamc.html"><a href="anovamc.html#directions"><i class="fa fa-check"></i><b>34.3.1</b> Directions</a></li>
<li class="chapter" data-level="34.3.2" data-path="anovamc.html"><a href="anovamc.html#step-1-create-initial-values"><i class="fa fa-check"></i><b>34.3.2</b> Step 1: Create initial values</a></li>
<li class="chapter" data-level="34.3.3" data-path="anovamc.html"><a href="anovamc.html#step-2-visualize-one-random-sample"><i class="fa fa-check"></i><b>34.3.3</b> Step 2: Visualize one random sample</a></li>
<li class="chapter" data-level="34.3.4" data-path="anovamc.html"><a href="anovamc.html#step-3-run-the-power-simulator"><i class="fa fa-check"></i><b>34.3.4</b> Step 3: Run The Power Simulator</a></li>
<li class="chapter" data-level="34.3.5" data-path="anovamc.html"><a href="anovamc.html#step-4-optimize-for-suitable-power"><i class="fa fa-check"></i><b>34.3.5</b> Step 4: Optimize for suitable power</a></li>
<li class="chapter" data-level="34.3.6" data-path="anovamc.html"><a href="anovamc.html#notes-and-considerations"><i class="fa fa-check"></i><b>34.3.6</b> Notes And Considerations</a></li>
</ul></li>
<li class="chapter" data-level="34.4" data-path="anovamc.html"><a href="anovamc.html#one-way-related-measures-anova-monte-carlo"><i class="fa fa-check"></i><b>34.4</b> One-way related measures ANOVA Monte Carlo</a></li>
<li class="chapter" data-level="34.5" data-path="anovamc.html"><a href="anovamc.html#directions-1"><i class="fa fa-check"></i><b>34.5</b> Directions</a><ul>
<li class="chapter" data-level="34.5.1" data-path="anovamc.html"><a href="anovamc.html#step-1-initial-values"><i class="fa fa-check"></i><b>34.5.1</b> Step 1: Initial values</a></li>
<li class="chapter" data-level="34.5.2" data-path="anovamc.html"><a href="anovamc.html#step-2-visualize-one-sample"><i class="fa fa-check"></i><b>34.5.2</b> Step 2: Visualize one sample</a></li>
<li class="chapter" data-level="34.5.3" data-path="anovamc.html"><a href="anovamc.html#step-3-run-the-power-simulator-1"><i class="fa fa-check"></i><b>34.5.3</b> Step 3: Run the power simulator</a></li>
<li class="chapter" data-level="34.5.4" data-path="anovamc.html"><a href="anovamc.html#step-4-should-anything-be-changed"><i class="fa fa-check"></i><b>34.5.4</b> Step 4: Should anything be changed?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="35" data-path="correl.html"><a href="correl.html"><i class="fa fa-check"></i><b>35</b> Correlation</a><ul>
<li class="chapter" data-level="35.1" data-path="correl.html"><a href="correl.html#correlation-causation"><i class="fa fa-check"></i><b>35.1</b> Correlation != Causation</a></li>
<li class="chapter" data-level="35.2" data-path="correl.html"><a href="correl.html#correlation-in-multivariate-outcomes-and-paired-designs"><i class="fa fa-check"></i><b>35.2</b> Correlation in Multivariate Outcomes and Paired Designs</a></li>
<li class="chapter" data-level="35.3" data-path="correl.html"><a href="correl.html#correlation-coefficients"><i class="fa fa-check"></i><b>35.3</b> Correlation coefficients</a><ul>
<li class="chapter" data-level="35.3.1" data-path="correl.html"><a href="correl.html#pearsons-correlation-coefficient"><i class="fa fa-check"></i><b>35.3.1</b> Pearson’s correlation coefficient</a></li>
<li class="chapter" data-level="35.3.2" data-path="correl.html"><a href="correl.html#spearmans-rank-correlation"><i class="fa fa-check"></i><b>35.3.2</b> Spearman’s rank correlation</a></li>
<li class="chapter" data-level="35.3.3" data-path="correl.html"><a href="correl.html#kendalls-tau"><i class="fa fa-check"></i><b>35.3.3</b> Kendall’s tau</a></li>
<li class="chapter" data-level="35.3.4" data-path="correl.html"><a href="correl.html#which-correlation-method-to-use"><i class="fa fa-check"></i><b>35.3.4</b> Which correlation method to use?</a></li>
<li class="chapter" data-level="35.3.5" data-path="correl.html"><a href="correl.html#r-correlation-analysis-functions"><i class="fa fa-check"></i><b>35.3.5</b> R correlation analysis functions</a></li>
<li class="chapter" data-level="35.3.6" data-path="correl.html"><a href="correl.html#plot-the-correlations"><i class="fa fa-check"></i><b>35.3.6</b> Plot the correlations</a></li>
<li class="chapter" data-level="35.3.7" data-path="correl.html"><a href="correl.html#calculate-a-correlation-coefficient-and-posthoc-test"><i class="fa fa-check"></i><b>35.3.7</b> Calculate a correlation coefficient and posthoc test</a></li>
<li class="chapter" data-level="35.3.8" data-path="correl.html"><a href="correl.html#interpretation-of-correlation-output"><i class="fa fa-check"></i><b>35.3.8</b> Interpretation of correlation output</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="36" data-path="regress.html"><a href="regress.html"><i class="fa fa-check"></i><b>36</b> Linear Regression</a><ul>
<li class="chapter" data-level="36.1" data-path="regress.html"><a href="regress.html#the-linear-regression-model"><i class="fa fa-check"></i><b>36.1</b> The linear regression model</a></li>
<li class="chapter" data-level="36.2" data-path="regress.html"><a href="regress.html#least-squares-fitting"><i class="fa fa-check"></i><b>36.2</b> Least squares fitting</a></li>
<li class="chapter" data-level="36.3" data-path="regress.html"><a href="regress.html#the-practical-importance-of-linear-model-parameters"><i class="fa fa-check"></i><b>36.3</b> The practical importance of linear model parameters</a></li>
<li class="chapter" data-level="36.4" data-path="regress.html"><a href="regress.html#linear-model-standard-errors"><i class="fa fa-check"></i><b>36.4</b> Linear model standard errors</a></li>
<li class="chapter" data-level="36.5" data-path="regress.html"><a href="regress.html#linear-regression-in-r"><i class="fa fa-check"></i><b>36.5</b> Linear regression in R</a></li>
<li class="chapter" data-level="36.6" data-path="regress.html"><a href="regress.html#intepretation"><i class="fa fa-check"></i><b>36.6</b> Intepretation</a><ul>
<li class="chapter" data-level="36.6.1" data-path="regress.html"><a href="regress.html#residuals"><i class="fa fa-check"></i><b>36.6.1</b> Residuals</a></li>
<li class="chapter" data-level="36.6.2" data-path="regress.html"><a href="regress.html#coefficients"><i class="fa fa-check"></i><b>36.6.2</b> Coefficients</a></li>
<li class="chapter" data-level="36.6.3" data-path="regress.html"><a href="regress.html#degrees-of-freedom-1"><i class="fa fa-check"></i><b>36.6.3</b> Degrees of freedom</a></li>
<li class="chapter" data-level="36.6.4" data-path="regress.html"><a href="regress.html#r-squared"><i class="fa fa-check"></i><b>36.6.4</b> R-squared</a></li>
<li class="chapter" data-level="36.6.5" data-path="regress.html"><a href="regress.html#f-statistic"><i class="fa fa-check"></i><b>36.6.5</b> F-statistic</a></li>
<li class="chapter" data-level="36.6.6" data-path="regress.html"><a href="regress.html#plotting-regression-results"><i class="fa fa-check"></i><b>36.6.6</b> Plotting regression results</a></li>
<li class="chapter" data-level="36.6.7" data-path="regress.html"><a href="regress.html#visualizing-residuals"><i class="fa fa-check"></i><b>36.6.7</b> Visualizing residuals</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="37" data-path="nonlinearintro.html"><a href="nonlinearintro.html"><i class="fa fa-check"></i><b>37</b> Non-linear regression introduction</a><ul>
<li class="chapter" data-level="37.1" data-path="nonlinearintro.html"><a href="nonlinearintro.html#uses-for-nonlinear-regression"><i class="fa fa-check"></i><b>37.1</b> Uses for nonlinear regression</a></li>
<li class="chapter" data-level="37.2" data-path="nonlinearintro.html"><a href="nonlinearintro.html#nonlinear-models-and-parameters"><i class="fa fa-check"></i><b>37.2</b> Nonlinear models and parameters</a><ul>
<li class="chapter" data-level="37.2.1" data-path="nonlinearintro.html"><a href="nonlinearintro.html#hyperbolic-stimulus-response-functions"><i class="fa fa-check"></i><b>37.2.1</b> Hyperbolic stimulus response functions</a></li>
<li class="chapter" data-level="37.2.2" data-path="nonlinearintro.html"><a href="nonlinearintro.html#visualizing-nonlinear-data-and-log-scaling"><i class="fa fa-check"></i><b>37.2.2</b> Visualizing nonlinear data and log scaling</a></li>
</ul></li>
<li class="chapter" data-level="37.3" data-path="nonlinearintro.html"><a href="nonlinearintro.html#how-do-regression-fits-happen"><i class="fa fa-check"></i><b>37.3</b> How do regression fits happen?</a><ul>
<li class="chapter" data-level="37.3.1" data-path="nonlinearintro.html"><a href="nonlinearintro.html#selecting-the-right-model"><i class="fa fa-check"></i><b>37.3.1</b> Selecting the right model</a></li>
<li class="chapter" data-level="37.3.2" data-path="nonlinearintro.html"><a href="nonlinearintro.html#from-models-to-formulas"><i class="fa fa-check"></i><b>37.3.2</b> From models to formulas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="38" data-path="nestedregress.html"><a href="nestedregress.html"><i class="fa fa-check"></i><b>38</b> Nested-model nonlinear regression</a><ul>
<li class="chapter" data-level="38.1" data-path="nestedregress.html"><a href="nestedregress.html#read-and-plot-the-data"><i class="fa fa-check"></i><b>38.1</b> Read and plot the data</a></li>
<li class="chapter" data-level="38.2" data-path="nestedregress.html"><a href="nestedregress.html#perform-the-nonlinear-regression"><i class="fa fa-check"></i><b>38.2</b> Perform the nonlinear regression</a><ul>
<li class="chapter" data-level="38.2.1" data-path="nestedregress.html"><a href="nestedregress.html#troubleshooting-the-regression"><i class="fa fa-check"></i><b>38.2.1</b> Troubleshooting the regression</a></li>
<li class="chapter" data-level="38.2.2" data-path="nestedregress.html"><a href="nestedregress.html#interpreting-the-parameters"><i class="fa fa-check"></i><b>38.2.2</b> Interpreting the parameters</a></li>
<li class="chapter" data-level="38.2.3" data-path="nestedregress.html"><a href="nestedregress.html#residual-plots-to-compare-fits"><i class="fa fa-check"></i><b>38.2.3</b> Residual plots to compare fits</a></li>
<li class="chapter" data-level="38.2.4" data-path="nestedregress.html"><a href="nestedregress.html#compare-aic"><i class="fa fa-check"></i><b>38.2.4</b> Compare AIC</a></li>
<li class="chapter" data-level="38.2.5" data-path="nestedregress.html"><a href="nestedregress.html#other-ways-to-compare-models"><i class="fa fa-check"></i><b>38.2.5</b> Other ways to compare models</a></li>
<li class="chapter" data-level="38.2.6" data-path="nestedregress.html"><a href="nestedregress.html#interpretation-of-this-one-replicate"><i class="fa fa-check"></i><b>38.2.6</b> Interpretation of this one replicate</a></li>
<li class="chapter" data-level="38.2.7" data-path="nestedregress.html"><a href="nestedregress.html#alternate-analysis"><i class="fa fa-check"></i><b>38.2.7</b> Alternate analysis</a></li>
</ul></li>
<li class="chapter" data-level="38.3" data-path="nestedregress.html"><a href="nestedregress.html#summary-9"><i class="fa fa-check"></i><b>38.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="nonlinearreplicates.html"><a href="nonlinearreplicates.html"><i class="fa fa-check"></i><b>39</b> Nonlinear regression of independent replicates</a><ul>
<li class="chapter" data-level="39.1" data-path="nonlinearreplicates.html"><a href="nonlinearreplicates.html#the-dataset"><i class="fa fa-check"></i><b>39.1</b> The dataset</a></li>
<li class="chapter" data-level="39.2" data-path="nonlinearreplicates.html"><a href="nonlinearreplicates.html#munging-for-regression-analysis"><i class="fa fa-check"></i><b>39.2</b> Munging for regression analysis</a><ul>
<li class="chapter" data-level="39.2.1" data-path="nonlinearreplicates.html"><a href="nonlinearreplicates.html#average-the-technical-replicates"><i class="fa fa-check"></i><b>39.2.1</b> Average the technical replicates</a></li>
<li class="chapter" data-level="39.2.2" data-path="nonlinearreplicates.html"><a href="nonlinearreplicates.html#create-one-table"><i class="fa fa-check"></i><b>39.2.2</b> Create one table</a></li>
<li class="chapter" data-level="39.2.3" data-path="nonlinearreplicates.html"><a href="nonlinearreplicates.html#plot-the-data"><i class="fa fa-check"></i><b>39.2.3</b> Plot the data</a></li>
<li class="chapter" data-level="39.2.4" data-path="nonlinearreplicates.html"><a href="nonlinearreplicates.html#clean-up-regression-results"><i class="fa fa-check"></i><b>39.2.4</b> Clean up regression results</a></li>
</ul></li>
<li class="chapter" data-level="39.3" data-path="nonlinearreplicates.html"><a href="nonlinearreplicates.html#t-test-on-half-lives"><i class="fa fa-check"></i><b>39.3</b> T-test on half-lives</a></li>
<li class="chapter" data-level="39.4" data-path="nonlinearreplicates.html"><a href="nonlinearreplicates.html#conclusion"><i class="fa fa-check"></i><b>39.4</b> Conclusion</a></li>
<li class="chapter" data-level="39.5" data-path="nonlinearreplicates.html"><a href="nonlinearreplicates.html#summary-figure"><i class="fa fa-check"></i><b>39.5</b> Summary figure</a></li>
</ul></li>
<li class="chapter" data-level="40" data-path="multregress.html"><a href="multregress.html"><i class="fa fa-check"></i><b>40</b> Multiple regression</a><ul>
<li class="chapter" data-level="40.1" data-path="multregress.html"><a href="multregress.html#the-linear-regression-model-1"><i class="fa fa-check"></i><b>40.1</b> The linear regression model</a></li>
<li class="chapter" data-level="40.2" data-path="multregress.html"><a href="multregress.html#multiple-regression-models"><i class="fa fa-check"></i><b>40.2</b> Multiple regression models</a></li>
<li class="chapter" data-level="40.3" data-path="multregress.html"><a href="multregress.html#experimental-multiple-regression"><i class="fa fa-check"></i><b>40.3</b> Experimental multiple regression</a><ul>
<li class="chapter" data-level="40.3.1" data-path="multregress.html"><a href="multregress.html#a-one-factor-experiment-with-3-groups"><i class="fa fa-check"></i><b>40.3.1</b> A one factor experiment with 3 groups</a></li>
<li class="chapter" data-level="40.3.2" data-path="multregress.html"><a href="multregress.html#a-two-factor-experiment-with-6-groups"><i class="fa fa-check"></i><b>40.3.2</b> A two factor experiment with 6 groups</a></li>
</ul></li>
<li class="chapter" data-level="40.4" data-path="multregress.html"><a href="multregress.html#multiple-linear-mixed-models"><i class="fa fa-check"></i><b>40.4</b> Multiple linear mixed models</a></li>
<li class="chapter" data-level="40.5" data-path="multregress.html"><a href="multregress.html#multiple-regression-of-observational-data"><i class="fa fa-check"></i><b>40.5</b> Multiple regression of observational data</a></li>
</ul></li>
<li class="chapter" data-level="41" data-path="logregress.html"><a href="logregress.html"><i class="fa fa-check"></i><b>41</b> Logistic regression</a><ul>
<li class="chapter" data-level="41.1" data-path="logregress.html"><a href="logregress.html#uses-of-logistic-regression"><i class="fa fa-check"></i><b>41.1</b> Uses of logistic regression</a><ul>
<li class="chapter" data-level="41.1.1" data-path="logregress.html"><a href="logregress.html#sidebar-doing-logistic-regression-is-machine-learning"><i class="fa fa-check"></i><b>41.1.1</b> Sidebar: Doing logistic regression is machine learning</a></li>
</ul></li>
<li class="chapter" data-level="41.2" data-path="logregress.html"><a href="logregress.html#derivation-of-the-logistic-regression-model"><i class="fa fa-check"></i><b>41.2</b> Derivation of the logistic regression model</a><ul>
<li class="chapter" data-level="41.2.1" data-path="logregress.html"><a href="logregress.html#relationship-of-logit-to-odds-to-the-model-coefficients-and-probability"><i class="fa fa-check"></i><b>41.2.1</b> Relationship of logit to odds to the model coefficients and probability</a></li>
<li class="chapter" data-level="41.2.2" data-path="logregress.html"><a href="logregress.html#additional-types-of-logistic-regression-models"><i class="fa fa-check"></i><b>41.2.2</b> Additional types of logistic regression models</a></li>
</ul></li>
<li class="chapter" data-level="41.3" data-path="logregress.html"><a href="logregress.html#stress-and-survival"><i class="fa fa-check"></i><b>41.3</b> Stress and survival</a><ul>
<li class="chapter" data-level="41.3.1" data-path="logregress.html"><a href="logregress.html#interpretation-of-output"><i class="fa fa-check"></i><b>41.3.1</b> Interpretation of output</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="42" data-path="mixedlogistic.html"><a href="mixedlogistic.html"><i class="fa fa-check"></i><b>42</b> Mixed model logistic regression</a><ul>
<li class="chapter" data-level="42.1" data-path="mixedlogistic.html"><a href="mixedlogistic.html#mixed-models-fixed-and-random-effects"><i class="fa fa-check"></i><b>42.1</b> Mixed models, fixed and random effects</a><ul>
<li class="chapter" data-level="42.1.1" data-path="mixedlogistic.html"><a href="mixedlogistic.html#nfat-localization-within-smooth-muscle-cells"><i class="fa fa-check"></i><b>42.1.1</b> NFAT localization within smooth muscle cells</a></li>
</ul></li>
<li class="chapter" data-level="42.2" data-path="mixedlogistic.html"><a href="mixedlogistic.html#data-1"><i class="fa fa-check"></i><b>42.2</b> Data</a><ul>
<li class="chapter" data-level="42.2.1" data-path="mixedlogistic.html"><a href="mixedlogistic.html#inference-2"><i class="fa fa-check"></i><b>42.2.1</b> Inference</a></li>
</ul></li>
<li class="chapter" data-level="42.3" data-path="mixedlogistic.html"><a href="mixedlogistic.html#alternative-analysis"><i class="fa fa-check"></i><b>42.3</b> Alternative analysis</a></li>
</ul></li>
<li class="chapter" data-level="43" data-path="lognormal.html"><a href="lognormal.html"><i class="fa fa-check"></i><b>43</b> The lognormal distribution</a><ul>
<li class="chapter" data-level="43.1" data-path="lognormal.html"><a href="lognormal.html#dlnorm"><i class="fa fa-check"></i><b>43.1</b> dlnorm</a></li>
<li class="chapter" data-level="43.2" data-path="lognormal.html"><a href="lognormal.html#plnorm"><i class="fa fa-check"></i><b>43.2</b> plnorm</a></li>
<li class="chapter" data-level="43.3" data-path="lognormal.html"><a href="lognormal.html#qlnorm"><i class="fa fa-check"></i><b>43.3</b> qlnorm</a></li>
<li class="chapter" data-level="43.4" data-path="lognormal.html"><a href="lognormal.html#rlnorm"><i class="fa fa-check"></i><b>43.4</b> rlnorm</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">JABSTB: Statistical Design and Analysis of Experiments with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="nonparametrics" class="section level1">
<h1><span class="header-section-number">Chapter 19</span> Nonparametric Statistical Tests</h1>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb313-1" title="1"><span class="kw">library</span>(tidyverse)</a>
<a class="sourceLine" id="cb313-2" title="2"><span class="kw">library</span>(PMCMR)</a>
<a class="sourceLine" id="cb313-3" title="3"><span class="kw">library</span>(PMCMRplus)</a>
<a class="sourceLine" id="cb313-4" title="4"><span class="kw">library</span>(PropCIs)</a>
<a class="sourceLine" id="cb313-5" title="5"><span class="kw">library</span>(knitr)</a></code></pre></div>
<p>Non-parametric statistical tests are quite versatile with respect to the dependent variables they tolerate and the experimental designs.</p>
<p>Nonparametric tests allow for statistical analysis of discrete ordinal data, such as likert survey data or other assessment instruments comprised of discrete scoring levels. Nonparametric tests can also be used for data on measured, equal interval scales, particularly when the normality and equal variance assumptions of parametric statistical testing are not satisfied or cannot be assumed.</p>
<p>Nonparametric statistics are parameter-less. They don’t compare means, or even medians. Though people frequently treat nonparametrics as tests of medians, that is not strictly true. They don’t involve least squares calculations, or standard deviations, or variance, or SE’s.</p>
<p>They do compare distributions of data. This happens by transforming the data into a standardized measure of ranks–either into signs, or sign ranks or rank sums. The experimental design dictates which of these measures of ranks is used for testing.</p>
<p><strong>The tests, essentially, evaluate whether the distribution of ranks in an experimental outcome differs from a null distribution of ranks, given a sample size. That can seem pretty abstract. But it’s actually a simple and elegant way to think about these tests.</strong></p>
<p>With the exception of the Sign Test, which has a probability as an effect size, strictly speaking there really isn’t an effect size that describes non-parametric outcomes other than the value of the test statistic.</p>
<p>However, it is possible to use confidence interval arguments in R’s tests to coerce them into providing effect size output as estimates of medians. This can be sometimes useful in write ups of the results.</p>
<p>Non-parametric analogs exist for each of the major parametric statistical tests (t-tests and one-way completely randomized anova and one-way repeated/related measures anova). Which nonparametric analog to use for a given data set analysis depends entirely upon the experimental design.</p>
<ul>
<li>Sign Test -&gt; analog to the binomial Test -&gt; when events are categorized as either successes or failures.</li>
<li>Wilcoxon Sign Rank Test for one group -&gt; analog to the one sample t-test -&gt; compare the values of a one group data set to a standard value.</li>
<li>Mann Whitney Rank Sum Test for 2 independent groups -&gt; analog to the unpaired t test -&gt; for comparing two groups in a data set.</li>
<li>Wilcoxon Sign Rank Test for paired groups -&gt; analog to the paired t-test -&gt; comparing a group of paired outcomes in a data set to no effect null.</li>
<li>Kruskal-Wallis Test -&gt; analog to one way completely randomized ANOVA -&gt; comparing 3 or more groups</li>
<li>Friedman Test -&gt; analog to one way repeated/related measures ANOVA -&gt; comparing 3 or more differences.</li>
</ul>
<p>In R, the <code>wilcox.test</code>function is a work horse for non-parametric analysis. By simply changing the function’s arguments it can do either a WSRT, or MW, or a WSRT for paired groups analysis. For the Sign Test, we’ll just use the <code>binom.test</code> function in R which was discussed previously in chapter @(categorical).</p>
<div id="nonparametric-sampling-distributions" class="section level2">
<h2><span class="header-section-number">19.1</span> Nonparametric sampling distributions</h2>
<p>As for other statistical tests, when conducting nonparametric analysis the experimental data are transformed into a test statistic that represents the signal-to-noise in the results. The question, as always, is whether this signal-to-noise is too extreme for a null effect.</p>
<p>The key nonparametric test statistics are the Wilcoxon Signed Rank (see chapter @(signrank)) and the Wilcoxon Rank Sum (see chapter @(ranksum)). For each, there is a unique distribution for every sample size and the p-values are themselves discrete.</p>
</div>
<div id="experiments-involving-discrete-data" class="section level2">
<h2><span class="header-section-number">19.2</span> Experiments involving discrete data</h2>
<p>Discrete data can be either sorted or ordered. Discrete data arises from counting objects or events, which is sorted data. They also occur when measurements taken from the experimental units are assigned discrete values, which is ordinal data.</p>
<p>Counted objects are easy to spot—they are indivisible. They belong in one bucket or some other bucket(s). Dependent variables that have discrete values are also easy to spot. On scatter plots they exist as discrete rows. There is no continuum of values between the rows.</p>
<div id="ordered-data-1" class="section level3">
<h3><span class="header-section-number">19.2.1</span> Ordered data</h3>
<p>When planning an experiment ask whether the data will be sorted into categories on the basis of nominal characteristics (eg, dead vs alive, in vs out).</p>
<p>Or will the data be categorized on some ordered basis. For example, a score of 1 = the attribute, a score of 2 = more of the attribute, a score of 3= even more of the attribute, …and so on.</p>
<p>The sum of the discrete counts within one category of an ordered scale mean that they have more or less of some feature than do the counts in another category in the ordered group.</p>
<p>Thus, compared to nominal sorted data, ordered data have more information. Whereas nominal events are just sorted into one bucket or another, ordered events are inherently categorized by rank.</p>
<p>Ordered data are common in survey instruments. These are likert scales. For example, you might take a survey that asks you to rate your enthusiasm for taking a biostats course. Your choice options are discrete values, on a scale of 1 to 10, where 1= “undetectable enthusiasm” and 10 = “giddy with excitement”. Obviously, a selection of 2 implies more enthusiasm than 1, and so on up the scale. The values are ordered.</p>
<p>Certain experimental designs generate inherently ordered data as well.</p>
<p>For example, imagine a test that scores dermal inflammatory responses.</p>
<p>Given a subject,
* Score 1 if we don’t see any signs of inflammation.
* Score 2 if there was a faint red spot.
* Score 3 for a raised pustule.
* Score 4 for a large swollen area that feels hot to the touch.
* Score 5 for anything worse than that, if it is possible!</p>
<p>Using that ordered scale system, we’d run experiments, for example, to compare a steroid treatment that might reduce inflammation compared to a vehicle control. Or we’d look at a gene knockout, or CRISP-R fix, or whatever, and score an outcome response compared to a control group. After an evaluation by a trained observer, each experimental unit receives a score from the scale.</p>
<p>In quantifying effect sizes for such studies, a mistake you often see is parametric analysis. The researcher uses parameters such as means, and standard deviations, performs t-tests, and so forth on the scored rank values.</p>
<p>This isn’t always bad, but it assumes a couple of things. First, that the distribution of the residuals for the data is approximately normal, as is the population that was sampled. Second, the scoring scale is equal interval. That is to say, “the difference between inflammation scores of 1 and 2 is the same as the difference between scores 2 and 3, and so on…”.</p>
<p>Suffice to say that researchers should validate whether these assumptions are true before resorting to parametric tests. If the assumptions cannot be validated nonparametric tests are perfectly suitable for such data.</p>
<p>It happens the other way, too. Sometimes we take measurements of some variable on a perfectly good measurement scale, one that satisfies these assumptions, but then break the data out to some ordered scale.</p>
<p>Take blood pressure, for example, which is a continuous variable, usually in standardized units of mm-Hg. We might measure it’s value for each subject, but on the basis of that measurement sort the subjects into ordered categories of low, medium and high pressure. Our scientific expertise drives what blood pressure values are used to define the margins of those categories. And we should have good reasons to resort to a categorization because doing so tends to throw away perfect good scalar information. Which is not a good idea, generally.</p>
<p>It is on this ordered scale, of discrete events, rather than the original measurements on a continuous scale, that we might then run statistical tests.</p>
<p>My point for this latter example is, of course, that not all ordered scales are based upon subjective assessments.</p>
</div>
</div>
<div id="experiments-involving-deviant-data" class="section level2">
<h2><span class="header-section-number">19.3</span> Experiments involving deviant Data</h2>
<p>Any scale, whether discrete or continuous, can yield deviant data. What I mean by deviant data is non-normal, skewed, has unequal variances among groups, has outliers, and is just plain ugly.</p>
<p>When data are deviant there are two options:</p>
<ol style="list-style-type: decimal">
<li>Use reciprocal or log transform functions to transform the data distribution into something more normal-like. Run the statistical tests intended for normal data on the transformed values.</li>
<li>Run non-parametric statistical tests on the raw, untransformed data. These tests transform the data into a rank-based distribution. These (the sign rank and the rank sum distributions), are discrete normal-like, and are used to cough up p-values.</li>
<li>Tossing outliers is almost always a bad and unnecessary option. Outlier tossing introduces bias when the only reason to toss it is because it is an outlier. Because they are based on ranks, the nonparametric tests condense outliers back with the rest of the variables, providing a very slick way to deal with deviant data.</li>
</ol>
</div>
<div id="sign-test" class="section level2">
<h2><span class="header-section-number">19.4</span> Sign Test</h2>
<p>The Sign Test is a non-parametric way of saying a binomial test.</p>
<p>An experiment is conducted on a group of subjects, who are graded in some way for either passing (+) or failing (- ) some test. Did a cell depolarize, or not? Is a stain in the cell nucleus, or not? Did the animal move fast enough, or not? Did the subject meet some other threshold you’ve established as a success, or not?</p>
<p>Simply count the number that passed. Given them a “+” sign. The number that failed receive a “-” sign. Using scientific judgement, assume a probability for the frequency of successes under the null hypothesis. For example, the null might be to expect 50% successes. If after analyzing the data the proportion of successes differs from this null proportion, you may have a winner!</p>
<p>Here’s an analysis of a behavioral test, the latency to exit a dark chamber into a brief field, as an index of anxiety. Let’s say that exiting a chamber in less than 60 seconds is a threshold for what we’d consider “non-anxious” behavior. Scientific judgement sets that threshold value. Fifteen subjects are given an anti-anxiety drug.</p>
<p>The null probability of exiting the chamber is 0.5. Which is to say there is a 50/50 chance a mouse will, at random, exit the chamber at any given time before or after 60 sec. Or put another way, under the null, neither exiting nor remaining in the chamber by 60 seconds is favored.</p>
<p>Let’s imagine we have an alarm set to go off 60 seconds after placing the subject in the chamber. When the alarm sounds, we score the subject as either (+) or (-). If the subject is out of the chamber, a success is (+). If still in the chamber after 60 s it is a failure (-).</p>
<p>This experiment tests the null hypothesis that the probability of successes are less than or equal to 50%.</p>
<p>We’ll write in our notebook this hypothesis. We are testing the null. The alternate is mutually exclusive and exhaustive of the null, so it is that the probability of successes are greater than 50%.</p>
<p>We’ll also jot down our error tolerance. Our tolerance for a type1 error is 5%, or 0.05. Thus our threshold rule is that we will reject the null if the p-value of the statistical test is below this tolerance level. Finally, we’ll write down that once the data are collected, we’ll run the binomial test to analyze the results.</p>
<p>The results are that twelve exited the chamber in less than 60 seconds, and 5 did not. We have not recorded times because that isn’t part of the protocol.</p>
<p>If something is not less than or equal to another, it can only be greater. Thus, we choose the “greater” for the alternative hypothesis argument in the binomial test function. We think on an anti-anxiety drug the probability is greater that the subjects will successfully exit the chamber.</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb314-1" title="1"><span class="kw">binom.test</span>(<span class="dt">x=</span><span class="dv">12</span>, <span class="dt">n=</span><span class="dv">15</span>, <span class="dt">p=</span><span class="fl">0.5</span>, </a>
<a class="sourceLine" id="cb314-2" title="2">           <span class="dt">alternative =</span><span class="st">&quot;greater&quot;</span>, </a>
<a class="sourceLine" id="cb314-3" title="3">           <span class="dt">conf.level=</span><span class="fl">0.95</span> )</a></code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  12 and 15
## number of successes = 12, number of trials = 15, p-value = 0.01758
## alternative hypothesis: true probability of success is greater than 0.5
## 95 percent confidence interval:
##  0.5602156 1.0000000
## sample estimates:
## probability of success 
##                    0.8</code></pre>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb316-1" title="1"><span class="kw">scoreci</span>(<span class="dt">x=</span><span class="dv">12</span>, <span class="dt">n=</span><span class="dv">15</span>, </a>
<a class="sourceLine" id="cb316-2" title="2">        <span class="dt">conf.level =</span> <span class="fl">0.95</span>)</a></code></pre></div>
<pre><code>## 
## 
## 
## data:  
## 
## 95 percent confidence interval:
##  0.5481 0.9295</code></pre>
<div id="interpretation-1" class="section level3">
<h3><span class="header-section-number">19.4.1</span> Interpretation</h3>
<p>The effect size is 0.8, which represents the fraction of subjects that left the chamber prior to the 60 second threshold we set. The p-value is the probability of observing an effect size this large or larger, if the null hypothesis is actually true.</p>
<p>The interpretation of the confidence interval is as follows. On the basis of this sample, there is 95% confidence the true value for the fraction of subjects that would leave the chamber prior to 60 seconds is within the range of 0.56 to 1.</p>
<p>Note that this 95% CI range includes values, eg, 0.56, that are pretty close to the null expectation. The fact that p-value beat the threshold should be tempered by the fact that we are also 95% confident that the proportion of successes includes values that are pretty darn close to what we predicted is the null.</p>
<p>To get a clearer sense of what’s going on, here is the distribution of the binomial function for the null hypothesis. You can see that it is symmetrical. If the drug were ineffective, we’d expect half to exit prior to 60 s, and the other half after 60 s.</p>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb318-1" title="1"><span class="co"># I&#39;ll use the rbinom function to simulate </span></a>
<a class="sourceLine" id="cb318-2" title="2">data &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">15</span>),<span class="dt">y=</span><span class="kw">dbinom</span>(<span class="kw">c</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">15</span>), <span class="dv">15</span>, <span class="dt">prob=</span><span class="fl">0.5</span>))</a>
<a class="sourceLine" id="cb318-3" title="3"></a>
<a class="sourceLine" id="cb318-4" title="4"><span class="kw">ggplot</span>(data, <span class="kw">aes</span>(x, y))<span class="op">+</span></a>
<a class="sourceLine" id="cb318-5" title="5"><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">fill=</span><span class="st">&quot;blue&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb318-6" title="6"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;exits before 60s&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb318-7" title="7"><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;prob of that many exits&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb318-8" title="8"><span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">x=</span><span class="dv">1</span>, <span class="dt">y=</span>.<span class="dv">20</span>, </a>
<a class="sourceLine" id="cb318-9" title="9">                <span class="dt">label=</span><span class="st">&quot;H0 distribution&quot;</span>))</a></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-185"></span>
<img src="jabstb_files/figure-html/unnamed-chunk-185-1.png" alt="Distribution of chamber exits in a trial sized 15 for the null for a 50% chance of chamber exits priort to 60 seconds, on a binomial model." width="672" />
<p class="caption">
Figure 19.1: Distribution of chamber exits in a trial sized 15 for the null for a 50% chance of chamber exits priort to 60 seconds, on a binomial model.
</p>
</div>
<p>And here is the distribution for the alternate hypothesis, given the effect size: If the drug were effective at reducing anxiety, we’d expect 80% would exit the chamber prior to 60 second.</p>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb319-1" title="1">data &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">15</span>),<span class="dt">y=</span><span class="kw">dbinom</span>(<span class="kw">c</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">15</span>), <span class="dv">15</span>, <span class="dt">prob=</span><span class="fl">0.8</span>))</a>
<a class="sourceLine" id="cb319-2" title="2"></a>
<a class="sourceLine" id="cb319-3" title="3"><span class="kw">ggplot</span>(data, <span class="kw">aes</span>(x, y))<span class="op">+</span></a>
<a class="sourceLine" id="cb319-4" title="4"><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">fill=</span><span class="st">&quot;green&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb319-5" title="5"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;exits before 60s&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb319-6" title="6"><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;prob of that many exits&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb319-7" title="7"><span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">x=</span><span class="dv">1</span>, <span class="dt">y=</span>.<span class="dv">20</span>, </a>
<a class="sourceLine" id="cb319-8" title="8">                <span class="dt">label=</span><span class="st">&quot;H1 distribution&quot;</span>)</a>
<a class="sourceLine" id="cb319-9" title="9">            )</a></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-186"></span>
<img src="jabstb_files/figure-html/unnamed-chunk-186-1.png" alt="Distribution of chamber exits in a trial sized 15 for the alternate expectation that 80% would exit prior to 60 seconds, based upon the binomial." width="672" />
<p class="caption">
Figure 19.2: Distribution of chamber exits in a trial sized 15 for the alternate expectation that 80% would exit prior to 60 seconds, based upon the binomial.
</p>
</div>
<p>This is to emphasize that the binomial distribution is used here as a model of the experimental data. Thus, we might also conclude that our data is consistent with a binomial distribution of 15 trials wherein the probability of event success is 80%.</p>
</div>
<div id="write-up-6" class="section level3">
<h3><span class="header-section-number">19.4.2</span> Write Up</h3>
<p>Here’s a way to write up the result.</p>
<p><em>Drug treatment increases fearlessness (one-sided binomial test, p = 0.01759). The fraction exiting the chamber (0.8) is greater than expected for the null of 0.5 (95% CI = 0.55 to 1.0, Wilson’s CI)</em></p>
</div>
</div>
<div id="wilcoxon-sign-rank-test-for-one-group" class="section level2">
<h2><span class="header-section-number">19.5</span> Wilcoxon Sign Rank Test for One Group</h2>
<p>The test statistic for the Wilcoxon Sign Rank is determined as follows.</p>
<ol style="list-style-type: decimal">
<li>Assert a theoretical threshold value of the dependent variable, such as a median.</li>
<li>Calculate the difference between the theoretical threshold value and the values recorded for each independent replicate.</li>
<li>Rank those differences from lowest (rank = 1) to highest (rank = n).</li>
<li>Assign a negative value to the replicate values that are less than the median.</li>
<li>The test statistic <code>V</code> is the sum of the positive values. (software other than <code>wilcox.test</code> in R may calculate W, the sum of the positive and negative values).</li>
</ol>
<p>The test statistic V has a symmetrical discrete distribution. The cumulative function of V is <code>psignrank</code> and is used to compute p-values.</p>
<div id="wilcoxon-sign-rank-experimental-designs" class="section level3">
<h3><span class="header-section-number">19.5.1</span> Wilcoxon Sign Rank Experimental Designs</h3>
<p>This experimental design is similar to the Sign Rank test above except in one important detail: <strong>We actually measure the time it takes for the subjects to exit the chamber.</strong> No alarm sounds to end the game at 60 sec. If subjects dawdle about and take longer than 60 sec to exit, we wait and record that time!</p>
<p>Thus, because the data set is comprised of the actual values for the latency variable, rather than counts of a simple (+) or (-) score, the Wilcoxon Sign Rank design collects more information than does the Sign Rank Test.</p>
<p>Let’s say we have a chamber test on 7 subjects who’ve all been given an anti-anxiety drug. After placement in the chamber, their exit times (in seconds) are 3, 5, 8, 15, 19, 21 and 108. Based upon our scientific expertise, we assume exiting sooner than 60 s would represent fearlessness (less anxiety).</p>
<p>This test ranks each subject’s performance relative to that reference time and then “signs” it as negative or positive based on whether it’s original value was below or above the 60 second threshold.</p>
<p>In our data, only one subject exceeded that value…108 sec.</p>
<p>Our prediction is that less anxious subjects should exit the comfort of the dark chamber sooner than would be expected. The null hypothesis is that the “location”" of the null distribution is greater than or equal to 60 seconds. The alternate is the location of the distribution is “less” than 60 seconds, since less is everything that greater than or equal to cannot be.</p>
<p>We run the Wilcoxon Sign Rank test to test this hypothesis using the arguments below.</p>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb320-1" title="1"><span class="kw">wilcox.test</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">8</span>,<span class="dv">15</span>,<span class="dv">19</span>,<span class="dv">21</span>,<span class="dv">108</span>), </a>
<a class="sourceLine" id="cb320-2" title="2">            <span class="dt">mu=</span><span class="dv">60</span>, </a>
<a class="sourceLine" id="cb320-3" title="3">            <span class="dt">alternative =</span> <span class="st">&quot;less&quot;</span>, </a>
<a class="sourceLine" id="cb320-4" title="4">            <span class="dt">conf.level =</span> <span class="fl">0.95</span>, </a>
<a class="sourceLine" id="cb320-5" title="5">            <span class="dt">conf.int =</span> <span class="fl">0.95</span></a>
<a class="sourceLine" id="cb320-6" title="6">            )</a></code></pre></div>
<pre><code>## 
##  Wilcoxon signed rank test
## 
## data:  c(3, 5, 8, 15, 19, 21, 108)
## V = 4, p-value = 0.05469
## alternative hypothesis: true location is less than 60
## 95 percent confidence interval:
##  -Inf 61.5
## sample estimates:
## (pseudo)median 
##             14</code></pre>
</div>
<div id="interpretation-2" class="section level3">
<h3><span class="header-section-number">19.5.2</span> Interpretation</h3>
<p>The value of the test statistic, V is four. How extreme is that? It is pretty far to the left on the test statistic distribution (see below) for this particular sample size. However, the p-value is above the threshold of 5%. The evidence is not enough to reject the null hypothesis. Otherwise, the probability of making an error doing so would be 0.05469.</p>
<p>What does V = 4 mean? It is the value corresponding to the sum of the positively signed ranks in the sample. The pseudo-median of the latency time is 14 seconds. The one-sided 95% confidence ranges from -infinity to 61.5.</p>
<p>Here’s a null signrank distribution for a sample size of 7. The values of the x scale are V, the test statistic. These are all the possible values that V can take on, given the sample size. For example, if all the signed ranks were positive…if every subject took longer than 60 sec to exit)…then V would equal 28. If all subjects exited before 60 sec, then V would equal zero.</p>
<p>Which is to say the location of this distribution is, by coincidence, also centered on 14. The value of 4 is less than this location, but not extremely-enough lower to be considered as belonging to some other distribution with a different location!
The 95% confidence interval of the location on the V test statistic ranges from -infinity to 62.5.</p>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb322-1" title="1"><span class="kw">psignrank</span>(<span class="dt">q=</span><span class="dv">4</span>, <span class="dt">n=</span><span class="dv">7</span>)</a></code></pre></div>
<pre><code>## [1] 0.0546875</code></pre>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb324-1" title="1"><span class="kw">psignrank</span>(<span class="dt">q=</span><span class="dv">1</span>, <span class="dt">n=</span><span class="dv">7</span>)</a></code></pre></div>
<pre><code>## [1] 0.015625</code></pre>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb326-1" title="1"><span class="co"># sign rank distribution for sample size of 7</span></a>
<a class="sourceLine" id="cb326-2" title="2"></a>
<a class="sourceLine" id="cb326-3" title="3">upper &lt;-<span class="st"> </span><span class="dv">28</span></a>
<a class="sourceLine" id="cb326-4" title="4">n &lt;-<span class="st"> </span><span class="dv">7</span></a>
<a class="sourceLine" id="cb326-5" title="5">df &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">x=</span><span class="dv">0</span><span class="op">:</span>upper, <span class="dt">y=</span><span class="kw">dsignrank</span>(<span class="dv">0</span><span class="op">:</span>upper, n))</a>
<a class="sourceLine" id="cb326-6" title="6"></a>
<a class="sourceLine" id="cb326-7" title="7"><span class="kw">ggplot</span>(df, (<span class="kw">aes</span>(x,y)))<span class="op">+</span></a>
<a class="sourceLine" id="cb326-8" title="8"><span class="st">  </span><span class="kw">geom_col</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb326-9" title="9"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;V&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb326-10" title="10"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span>(<span class="kw">seq</span>(<span class="dv">0</span>,upper,<span class="dv">1</span>)))</a></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-187"></span>
<img src="jabstb_files/figure-html/unnamed-chunk-187-1.png" alt="Null sign rank test statistic distribution for sample size of 7" width="672" />
<p class="caption">
Figure 19.3: Null sign rank test statistic distribution for sample size of 7
</p>
</div>
</div>
<div id="write-up-7" class="section level3">
<h3><span class="header-section-number">19.5.3</span> Write Up</h3>
<p><em>Analysis of the chamber test results indicates the anti-anxiety drug has no effect (Wilcoxon Signed Rank test, V = 4, n = 7, p= 0.0547)</em></p>
</div>
</div>
<div id="wilcoxon-mann-whitney-rank-sum-test-for-2-independent-groups" class="section level2">
<h2><span class="header-section-number">19.6</span> Wilcoxon Mann Whitney Rank Sum Test for 2 independent groups</h2>
<p>This nonparametric test, often referred to simply as the Mann-Whitney test, is analogous to the parametric unpaired t-test.</p>
<p>It is for comparing two groups that receive either of 2 levels of a predictor variable. For example, in an experiment where one group of <code>m</code> independent replicates is exposed to some control or null condition, while a second group with <code>n</code> independent replicates is exposed to some treatment. More generally, the two groups represent two levels of a predictor variable given to <code>m+n</code>independent replicates.</p>
<p>The rank sum is calculated as follows:</p>
<ol style="list-style-type: decimal">
<li>The data are collected from any scale, combined into a single list, whose values are ranked from lowest (rank 1) to highest (rank <code>m+n</code>), irrespective of the level of the predictor variable.</li>
<li>Let <span class="math inline">\(R_1\)</span> represent the sum of the ranks for the one level of the predictor variable (eg, group2).</li>
<li>Let <span class="math inline">\(U_1\)</span> represent the number of times a data value from group2 is less than a data point from group1.</li>
<li><span class="math inline">\(U_1=m*n+\frac{m(m+1)}{2}-R_1\)</span></li>
<li>And <span class="math inline">\(U_2=m*n-U_1\)</span></li>
</ol>
<p>The rank sum test computes two test statistics, <span class="math inline">\(U_1\)</span> and <span class="math inline">\(U_2\)</span> that are complementary to each other.</p>
<p>Here’s another in the line of the mighty mouse experiments.</p>
<p>55 independent subjects were split into two groups. One group received an anti-anxiety drug and the second a vehicle as control. The subjects were run through the dark chamber test. The scientific prediction is the drug will reduce anxiety levels and so the drug treated mice will exit the chamber more quickly compared to the control mice.</p>
<p>Since this is a parameter-less test, the null hypothesis is that location of the distribution of the drug-treated population is greater than or equal to the location of the vehicle distribution. The alternative hypothesis is that the location of the distribution of the drug-treated population is less than that of the vehicle distribution. The alternative is consistent with our scientific prediction and represents an outcome that is exclusive and comprehensive of the null!</p>
<p>We choose the “less” option for the alternative argument in the test.</p>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb327-1" title="1">mightymouse &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;datasets/mightymouse.csv&quot;</span>)</a></code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   Group = col_character(),
##   Time = col_double(),
##   Rank = col_double()
## )</code></pre>
<div class="sourceCode" id="cb329"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb329-1" title="1"><span class="co"># note use of naming variables with the formula syntax </span></a>
<a class="sourceLine" id="cb329-2" title="2"></a>
<a class="sourceLine" id="cb329-3" title="3"><span class="kw">wilcox.test</span>(Time <span class="op">~</span><span class="st"> </span>Group, </a>
<a class="sourceLine" id="cb329-4" title="4">            <span class="dt">data =</span> mightymouse, </a>
<a class="sourceLine" id="cb329-5" title="5">            <span class="dt">alternative =</span><span class="st">&quot;less&quot;</span>, </a>
<a class="sourceLine" id="cb329-6" title="6">            <span class="dt">conf.level=</span><span class="fl">0.95</span>, </a>
<a class="sourceLine" id="cb329-7" title="7">            <span class="dt">conf.int=</span>T)</a></code></pre></div>
<pre><code>## 
##  Wilcoxon rank sum test
## 
## data:  Time by Group
## W = 55, p-value = 0.1804
## alternative hypothesis: true location shift is less than 0
## 95 percent confidence interval:
##  -Inf    6
## sample estimates:
## difference in location 
##                   -9.8</code></pre>
<div id="interpretation-3" class="section level3">
<h3><span class="header-section-number">19.6.1</span> Interpretation</h3>
<p>The test statistic you see in the output, <span class="math inline">\(W\)</span>, warrants some discussion. <span class="math inline">\(W\)</span> is equal to <span class="math inline">\(U_2\)</span> as defined above.</p>
<p>By default, R produces <span class="math inline">\(U_2\)</span> (labeled W!) as the test statistic. Most other software packages use <span class="math inline">\(U_1\)</span>, which in this case would be 88 (easy to compute in the console given <span class="math inline">\(U_2\)</span>).</p>
<p>Think of <span class="math inline">\(W\)</span> as a value on the x axis of a rank sum distribution for a sample size of <code>m+n</code>. The rank sum distribution has a function in R called <code>dwilcox</code>. Here it is (note the large value this distribution can take on is <code>m*n</code> and the smallest is zero):</p>
<div class="sourceCode" id="cb331"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb331-1" title="1">df &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">x=</span><span class="dv">0</span><span class="op">:</span><span class="dv">143</span>, <span class="dt">y=</span><span class="kw">dwilcox</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">143</span>, <span class="dv">11</span>, <span class="dv">13</span>))</a>
<a class="sourceLine" id="cb331-2" title="2"></a>
<a class="sourceLine" id="cb331-3" title="3"><span class="kw">ggplot</span>(df, (<span class="kw">aes</span>(x,y)))<span class="op">+</span></a>
<a class="sourceLine" id="cb331-4" title="4"><span class="st">  </span><span class="kw">geom_col</span>()<span class="op">+</span></a>
<a class="sourceLine" id="cb331-5" title="5"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;W&quot;</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb331-6" title="6"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span><span class="kw">c</span>(<span class="dv">55</span>, <span class="dv">88</span>))</a></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-188"></span>
<img src="jabstb_files/figure-html/unnamed-chunk-188-1.png" alt="The null rank sum test statistic distribution for a sample size of m=11 and n=13" width="672" />
<p class="caption">
Figure 19.4: The null rank sum test statistic distribution for a sample size of m=11 and n=13
</p>
</div>
<p>All this can seem confusing, but it is very elegant. First, the rank sums of samples, like the rank signs of samples, take on symmetrical, normal-like distributions. The greater the sample sizes, the more normal-like they become.</p>
<p>Second, the bottom line is the same as for all other statistical tests: test statistic values at either extreme of these null distributions are associated with large effect sizes.</p>
<p>The non-extreme-ness of the test statistic value for our sample is illustrated in that plot. Clearly, W=55, it is well within the null distribution. I calculated it’s symmetrical counterpart, <span class="math inline">\(U_1\)</span> = 88, from the relationship above. As you can see, the value of the test statistic and 88 frame the central location of this null ranksum distribution null quite nicely:</p>
<p>The p-value for W=55 indicates that the probability of creating a false positive by rejecting the null is 18.04%, well above the 5% type1 error threshold. So we should not reject the null given we’d have a 1 in 5 chance of being wrong if we did!</p>
<p>The “effect size” is in the output is the magnitude of the difference between the location parameters (pseudo-medians) of the two groups, on the scale of the original data.</p>
<p>The 95% confidence interval indicates there is a 95% chance the difference in locations is between negative infinity and 6. Since the 95% confidence interval includes zero, the possibility exists that there is zero difference between the two locations. That provides additional statistical reasoning not to reject the null.</p>
</div>
<div id="write-up-8" class="section level3">
<h3><span class="header-section-number">19.6.2</span> Write Up</h3>
<p><em>There is no difference in performance using the closed chamber test between subjects randomized to anti-anxiety drug (n=11) or to vehicle (n=13) (Mann-Whitney test, W = 55, p = 0.1804).</em></p>
</div>
<div id="plot" class="section level3">
<h3><span class="header-section-number">19.6.3</span> Plot</h3>
<p>This is a two group experiment. Every data point represents an independent replicate.</p>
<p>The <code>aes</code> function defines the plot axis. The x-axis is the factor “Group” and it has two levels, “Drugs” and “Vehicle”. The y-axis is “Time” in seconds.</p>
<p>It is customary to illustrate summary statistics of nonparametric data with box plots. By default these illustrate the median (mid horizontal bar), interquartile ranges (outer horizontal bars) and full ranges (verticle bars). The small dot is a value the <code>geom_boxplot</code> function recognizes as an outlier. It can be surpressed with an argument.</p>
<p>It is becoming customary to show all data points. Thus, overlaying the points on a box plot shows all the data and its summary. The visualization illustrates quite well the deviant data. Nonparametric analysis handles this well. This isn’t suitable for a t-test.</p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb332-1" title="1"><span class="kw">ggplot</span>(mightymouse, <span class="kw">aes</span>(<span class="dt">x=</span>Group, <span class="dt">y=</span>Time))<span class="op">+</span></a>
<a class="sourceLine" id="cb332-2" title="2"><span class="st">  </span><span class="kw">geom_boxplot</span>(<span class="dt">width=</span><span class="fl">0.3</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb332-3" title="3"><span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">height=</span><span class="dv">0</span>, </a>
<a class="sourceLine" id="cb332-4" title="4">              <span class="dt">width =</span> <span class="fl">0.1</span>, </a>
<a class="sourceLine" id="cb332-5" title="5">              <span class="dt">size =</span> <span class="dv">4</span>, </a>
<a class="sourceLine" id="cb332-6" title="6">              <span class="dt">alpha=</span><span class="fl">0.4</span>)</a></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-189"></span>
<img src="jabstb_files/figure-html/unnamed-chunk-189-1.png" alt="A minimal configuration for plotting a 2 group nonparametric experimental design." width="672" />
<p class="caption">
Figure 19.5: A minimal configuration for plotting a 2 group nonparametric experimental design.
</p>
</div>
</div>
</div>
<div id="wilcoxon-sign-rank-test-for-paired-groups" class="section level2">
<h2><span class="header-section-number">19.7</span> Wilcoxon Sign Rank Test for paired groups</h2>
<p>The classic paired experimental design happens when two measurements are taken from a single independent subject.</p>
<p>For example, we take a mouse, give it a sham treatment, and measure it’s latency in the chamber test. Later on we take the same mouse, give it an anti-anxiety drug treatment, and then measure its latency once again.</p>
<p>This kind of design can control for confounding factors, like inter-subject variability. But it can also introduce other confounds. For example, what if the mouse “remembers” that there is no real risk of leaving the dark chamber?</p>
<p>Pairing can happen in many other ways. A classic pairing paradigm is the use of identical twins. Individuals of inbred mouse strains are all immortal clones. Two litter mates would be identical twins and would also be, essentially, clones of their parents and their brothers and sisters from prior litters! Two dishes of cultured cells, passed together and now side-by-side on a bench are intrinsically-linked. All of these can be treated, statistically, as pairs.</p>
<p>In this example, we take a pair of mice from each of 6 independent litters produced by mating two heterozygotes of a nogo receptor knockout. One of the pair is nogo(-/-). The other is nogo(+/+). We think the nogo receptor causes the animals to be fearful, and predict animals in which the receptor is knocked out will be more fearless.</p>
<p>The independent experimental unit in this design is a pair. We have six pairs, Therefore, the sample size is 6 (even though 12 animals will be used!)</p>
<p>We’ll measure latency in the dark chamber test. Our random variable will be the difference in latency time between the knockout and the wild type, for each pair.</p>
<p>Here’s the data, latency times are in sec units. Each animal generates two measurements and has an id value:</p>
<div class="sourceCode" id="cb333"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb333-1" title="1"><span class="co"># enter the data by hand, no need to use csv files </span></a>
<a class="sourceLine" id="cb333-2" title="2"></a>
<a class="sourceLine" id="cb333-3" title="3">mmko &lt;-<span class="st"> </span><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb333-4" title="4">  <span class="dt">id=</span><span class="kw">c</span>(<span class="st">&quot;a&quot;</span>, <span class="st">&quot;b&quot;</span>, <span class="st">&quot;c&quot;</span>, <span class="st">&quot;d&quot;</span>, <span class="st">&quot;e&quot;</span>, <span class="st">&quot;f&quot;</span>),</a>
<a class="sourceLine" id="cb333-5" title="5">  <span class="dt">knockout=</span><span class="kw">c</span>(<span class="dv">19</span>, <span class="dv">24</span>, <span class="dv">4</span>, <span class="dv">22</span>, <span class="dv">15</span>, <span class="dv">18</span>), </a>
<a class="sourceLine" id="cb333-6" title="6">  <span class="dt">wildtype=</span><span class="kw">c</span>(<span class="dv">99</span>, <span class="dv">81</span>, <span class="dv">70</span>, <span class="dv">62</span>, <span class="dv">120</span>, <span class="dv">55</span>)</a>
<a class="sourceLine" id="cb333-7" title="7">  )</a>
<a class="sourceLine" id="cb333-8" title="8"></a>
<a class="sourceLine" id="cb333-9" title="9"><span class="co">#create a long data fram to do formula arguments in wilcox test</span></a>
<a class="sourceLine" id="cb333-10" title="10"></a>
<a class="sourceLine" id="cb333-11" title="11">mmkotidy &lt;-<span class="st"> </span><span class="kw">pivot_longer</span>(mmko, </a>
<a class="sourceLine" id="cb333-12" title="12">                         <span class="op">-</span><span class="st"> </span>id, </a>
<a class="sourceLine" id="cb333-13" title="13">                         <span class="dt">names_to =</span> <span class="st">&quot;genotype&quot;</span>, </a>
<a class="sourceLine" id="cb333-14" title="14">                         <span class="dt">values_to =</span> <span class="st">&quot;latency&quot;</span> </a>
<a class="sourceLine" id="cb333-15" title="15">                         )</a></code></pre></div>
<p>Scientifically, we predict there will be a difference in latency times within the pairs. Specifically, the knockout will have lower times than their paired wild-type. The null hypothesis is that the difference within pairs will be greater than or equal to zero. The alternative hypothesis is the difference will be less than zero.</p>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb334-1" title="1"><span class="kw">wilcox.test</span>(latency <span class="op">~</span><span class="st"> </span>genotype, </a>
<a class="sourceLine" id="cb334-2" title="2">            <span class="dt">data=</span>mmkotidy, </a>
<a class="sourceLine" id="cb334-3" title="3">            <span class="dt">paired=</span>T, </a>
<a class="sourceLine" id="cb334-4" title="4">            <span class="dt">conf.level=</span><span class="fl">0.95</span>, </a>
<a class="sourceLine" id="cb334-5" title="5">            <span class="dt">conf.int=</span>T, </a>
<a class="sourceLine" id="cb334-6" title="6">            <span class="dt">alternative=</span><span class="st">&quot;less&quot;</span></a>
<a class="sourceLine" id="cb334-7" title="7">            )</a></code></pre></div>
<pre><code>## 
##  Wilcoxon signed rank test
## 
## data:  latency by genotype
## V = 0, p-value = 0.01563
## alternative hypothesis: true location shift is less than 0
## 95 percent confidence interval:
##  -Inf  -40
## sample estimates:
## (pseudo)median 
##          -61.5</code></pre>
<div id="interpretation-4" class="section level3">
<h3><span class="header-section-number">19.7.1</span> Interpretation</h3>
<p>Note that this is not a rank sum test as for the Mann-Whitney, but a signed rank test.</p>
<p>So we have seen the V test statistic before. It’s value of 0 is as extreme as can be had on the null distribution, as is evident in the distribution below! That happened because in each of the six pairs, the knockout had a lower latency time than its paired wildtype. All of the signed ranks were negative!</p>
<p>In terms of position differences, it is as strong of an effect size as possible.</p>
<div class="sourceCode" id="cb336"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb336-1" title="1">upper &lt;-<span class="st"> </span><span class="dv">21</span></a>
<a class="sourceLine" id="cb336-2" title="2">n &lt;-<span class="st"> </span><span class="dv">6</span></a>
<a class="sourceLine" id="cb336-3" title="3"></a>
<a class="sourceLine" id="cb336-4" title="4">df &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">x=</span><span class="dv">0</span><span class="op">:</span>upper, </a>
<a class="sourceLine" id="cb336-5" title="5">             <span class="dt">y=</span><span class="kw">dsignrank</span>(<span class="dv">0</span><span class="op">:</span>upper, n)</a>
<a class="sourceLine" id="cb336-6" title="6">             )</a>
<a class="sourceLine" id="cb336-7" title="7"></a>
<a class="sourceLine" id="cb336-8" title="8"><span class="kw">ggplot</span>(df, (<span class="kw">aes</span>(x,y)))<span class="op">+</span></a>
<a class="sourceLine" id="cb336-9" title="9"><span class="st">  </span><span class="kw">geom_col</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb336-10" title="10"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;V&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb336-11" title="11"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span>(<span class="kw">seq</span>(<span class="dv">0</span>,upper,<span class="dv">1</span>)))</a></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-190"></span>
<img src="jabstb_files/figure-html/unnamed-chunk-190-1.png" alt="Null sign rank test statistic distribution when n= 6 pairs." width="672" />
<p class="caption">
Figure 19.6: Null sign rank test statistic distribution when n= 6 pairs.
</p>
</div>
<p>The p-value is exact…and it can never be lower, given this sample size. We can reject the null since it is below our 5% threshold and it says the probably that we are accepting a type1 error is 1.563%.</p>
<p>The pseudo-median is in units of latency time. It represents the median for the differences in latency within the pairs. In other words, there are six values of differences, one difference value for each pair. -61.5 is the median of those 6 differences.</p>
<p>There is a 95% chance the true median of the differences lies between negative infinity and -40. Note that the 95% CI does not include the value of zero.</p>
</div>
<div id="write-up-9" class="section level3">
<h3><span class="header-section-number">19.7.2</span> Write up</h3>
<p><em>Dark chamber test latency differs markedly within pairs of knockout and wildtype subjects (Wilcoxon Signed Rank Test for pairs, n=6, V = 0, p=0.01563)</em></p>
</div>
<div id="plot-1" class="section level3">
<h3><span class="header-section-number">19.7.3</span> Plot</h3>
<p>Since this is a paired experimental design we create a dot-line-dot plot that illustrates this point. A very common mistake is for people who have a paired experiment to plot means of the two groups, or two bars, without connecting the paired data.</p>
<p>The statistical test, in fact, is not performed on the latency values for the two groups.Group means or medians are irrelevant. Instead, it is performed on the <em>differences within the pairs</em>. In other words, the test is run, essentially, on sign ranked values related to the <em>slopes</em> of the red lines, not on the values of the dots.</p>
<p>The plot should always reflect the experimental design.</p>
<p>Here is a minimal concept for this. The <code>group</code> aesthetic is the key and definitely a trick worth remembering. If you want to really bob ross this, add <code>color = id</code> to the aesthetics.</p>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb337-1" title="1"><span class="kw">ggplot</span>(mmkotidy, <span class="kw">aes</span>(genotype, latency, <span class="dt">group=</span>id))<span class="op">+</span></a>
<a class="sourceLine" id="cb337-2" title="2"><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">color=</span><span class="st">&quot;red&quot;</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb337-3" title="3"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size=</span><span class="dv">4</span>)</a></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-191"></span>
<img src="jabstb_files/figure-html/unnamed-chunk-191-1.png" alt="Paired experimental designs should always be plotted dot-line-dot." width="672" />
<p class="caption">
Figure 19.7: Paired experimental designs should always be plotted dot-line-dot.
</p>
</div>
</div>
</div>
<div id="kruskal-wallis" class="section level2">
<h2><span class="header-section-number">19.8</span> Kruskal-Wallis</h2>
<p>The <code>kruskal.test</code> is a non-parametric method for comparing 3 or more treatment groups. It serves as an omnibus test for the null hypothesis that each of the treatment groups belong to the same population. If the null is rejected, post hoc comparison tests are then used to determine which groups differ from each other.</p>
<p>A post hoc test for this purpose in base R is <code>pairwise.wilcox.test</code>. The <code>PMCMRplus</code> package has others. Documentation within the <code>PMCMR</code>package vignette provides excellent background and instructions for these tests.</p>
<p>The Kruskal-Wallis test statistic is computed as follows. Values of the outcome variables across the groups are first converted into ranks, from high to low. Tied values are rank-averaged. The test can be corrected for large numbers of tied values.</p>
<p>The Kruskal-Wallis rank sum test statistic is H:</p>
<p><span class="math display">\[H=\frac{12}{n(n+1)}\sum_{i=1}^k\frac{R_{i}^2}{n_i}-3(n+1)\]</span></p>
<p><span class="math inline">\(n\)</span> is the total sample size, <span class="math inline">\(k\)</span> is the number of treatment groups, <span class="math inline">\(n_i\)</span> is the sample size in the <span class="math inline">\(ith\)</span> group and <span class="math inline">\(R_i^2\)</span> is the squared rank sum of the <span class="math inline">\(ith\)</span> group. Under the null, <span class="math inline">\(\bar{R_i} = (n+1)/2\)</span>.</p>
<p>Because it is, effectively, the sum of a squared value, the <code>H</code> statistic is approximated using the <span class="math inline">\(\chi^2\)</span> distribution with <span class="math inline">\(k-1\)</span> degrees of freedom to produce p-values.</p>
<div id="the-experimental-design" class="section level3">
<h3><span class="header-section-number">19.8.1</span> The experimental design</h3>
<p>Let’s analyze the InsectSprays data set, which comes with the <code>PMCMRplus</code> package. This is a multifactorial experiment in which insects were counted in agricultural field plots that had been sprayed with 1 of 6 different insecticides. Each row in the data set represents an independent field plot.</p>
<p>Do the insecticides differ?</p>
<div class="sourceCode" id="cb338"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb338-1" title="1"><span class="kw">ggplot</span>(InsectSprays, <span class="kw">aes</span>(spray, count))<span class="op">+</span></a>
<a class="sourceLine" id="cb338-2" title="2"><span class="st">  </span><span class="kw">geom_violin</span>(<span class="dt">fill=</span><span class="st">&quot;blue&quot;</span>, </a>
<a class="sourceLine" id="cb338-3" title="3">              <span class="dt">color=</span><span class="st">&quot;red&quot;</span>,</a>
<a class="sourceLine" id="cb338-4" title="4">              <span class="dt">size =</span> <span class="fl">1.5</span>)</a></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-192"></span>
<img src="jabstb_files/figure-html/unnamed-chunk-192-1.png" alt="Violin plot for counts of insects in crop fields somewhere in Kansas following treatment with different insecticides." width="672" />
<p class="caption">
Figure 19.8: Violin plot for counts of insects in crop fields somewhere in Kansas following treatment with different insecticides.
</p>
</div>
<p>The violin plots (modern day versions of box plots) illustrate how the groups have unequal variance. Such data are appropriate for non-parametric analysis.</p>
<div class="sourceCode" id="cb339"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb339-1" title="1"><span class="co">#insectsprays &lt;- read.csv(&quot;insectsprays.csv&quot;)</span></a>
<a class="sourceLine" id="cb339-2" title="2"><span class="kw">kruskal.test</span>(count <span class="op">~</span><span class="st"> </span>spray, </a>
<a class="sourceLine" id="cb339-3" title="3">             <span class="dt">data=</span>InsectSprays</a>
<a class="sourceLine" id="cb339-4" title="4">             )</a></code></pre></div>
<pre><code>## 
##  Kruskal-Wallis rank sum test
## 
## data:  count by spray
## Kruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10</code></pre>
<div class="sourceCode" id="cb341"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb341-1" title="1"><span class="kw">kwAllPairsConoverTest</span>(count <span class="op">~</span><span class="st"> </span>spray, </a>
<a class="sourceLine" id="cb341-2" title="2">                      <span class="dt">data=</span>InsectSprays, </a>
<a class="sourceLine" id="cb341-3" title="3">                      <span class="dt">p.adjust =</span><span class="st">&quot;bonf&quot;</span></a>
<a class="sourceLine" id="cb341-4" title="4">                      )</a></code></pre></div>
<pre><code>## Warning in kwAllPairsConoverTest.default(c(10, 7, 20, 14, 14, 12, 10, 23, : Ties
## are present. Quantiles were corrected for ties.</code></pre>
<pre><code>## 
##  Pairwise comparisons using Conover&#39;s all-pairs test</code></pre>
<pre><code>## data: count by spray</code></pre>
<pre><code>##   A       B       C       D       E      
## B 1.000   -       -       -       -      
## C 5.6e-13 4.5e-14 -       -       -      
## D 4.7e-07 3.6e-08 0.021   -       -      
## E 1.1e-09 8.5e-11 1.000   1.000   -      
## F 1.000   1.000   2.1e-14 1.7e-08 3.9e-11</code></pre>
<pre><code>## 
## P value adjustment method: bonferroni</code></pre>
<p>We first do a Kruskal-Wallis rank sum omnibus test to test the null hypothesis that the locations of the insect distributions for several insecticide groups are the same.</p>
<p>The null is rejected given the large <span class="math inline">\(\chi^2\)</span> test statistic, which has a p-value well below the threshold of 5% type1 error.</p>
<p>That’s followed by a pairwise post hoc test with a p-value adjustment. The number of pairwise tests for 6 groups is <code>choose(6, 2)</code>= 15.</p>
<p>Each pairwise test is a single hypothesis test associated with 5% type1 error risk. If we don’t make a correction for doing the multiple comparisons, the family-wise type1 error we allow ourselves would inflate to <span class="math inline">\(15 x 5% = 75%\)</span>!</p>
<p>The Bonferroni adjustment is simple to understand. It multiplies every unadjusted p-value by 15, the number of comparisons made. Thus, each of the p-values in the grid is 15X larger than had the adjustment not been made.</p>
<p>Every p-value less than 0.05 in the grid is therefore cause for rejecting the null hypothesis those two compared groups. The highest among these is the comparisons between sprays C and D, which has a p-value of 0.03977.</p>
</div>
<div id="write-up-10" class="section level3">
<h3><span class="header-section-number">19.8.2</span> Write Up</h3>
<p><em>A non-parametric omnibus test establishes that the locations of the insecticide effects of the six sprays differ (Kruskal-Wallis, <span class="math inline">\(\Chi^2\)</span> = 54.69, df=5, p=1.511e-10). Posthoc pairwise multiple comparisons by the Mann-Whitney test (Bonferroni adjusted p-values) indicate the following sprays differ from each other: A v(0.00058), D(0.00117), E(0.0051), …and so on</em></p>
</div>
</div>
<div id="friedman-test" class="section level2">
<h2><span class="header-section-number">19.9</span> Friedman test</h2>
<p>The Friedman test is used for nonparametric analysis of three or more levels of an independent variable for experimental designs that involve repeated/related measures. These are otherwise known as block designs. The Friedman test is a nonparametric analog of the one-way repeated/related measures ANOVA.</p>
<p>The test statistic is calculated in a multistep process from matrix-like data <span class="math inline">\({x_{i,j}}\)</span>. Each row, <span class="math inline">\(n_i\)</span>, is an independent block within which repeated/related measures are collected. Each column, <span class="math inline">\(k_j\)</span> represents one level of the independent variable.</p>
<p>The <code>friedman.test</code> function works as follows: The first step involves ranking response values in ascending order within each row, transforming into a matrix of ranks, <span class="math inline">\(r_{i,j}\)</span>. The mean ranks are derived for each column <span class="math inline">\(\bar r_j=\frac{1}{n}\sum_{i=1}^n(r_{i,j})\)</span>.</p>
<p>The Friedman test statistic is then <span class="math display">\[Q=\frac{12n}{k(k+1)}\sum_{j=1}^k(\bar r_j-\frac{k+1}{2})^2\]</span></p>
<p>Note how this is in the form of a sum of squared values. The distribution of <span class="math inline">\(Q\)</span> is therefore approximately <span class="math inline">\(\chi^2\)</span>.</p>
<p>The function output is very simple: a p-value derived from the <span class="math inline">\(\chi^2\)</span> distribution.</p>
<div id="blocked-experimental-design" class="section level3">
<h3><span class="header-section-number">19.9.1</span> Blocked experimental design</h3>
<p>Protein kinase A activity (PKA) was measured in extracts of cultured VSMC after exposure to either of four possible treatments.</p>
<p>There are a few critical questions this experiment hopes to answer. Does isoproterenol stimulate activity? Does the presence of a GFP_PKI inhibit stimulated activity? Is that inhibitory effect absent in a negative control for GFP_PKI?</p>
<p>Each week serves as a block, which is an independent replicate wherein all recorded measurements are more related to each other than they are to measurements in other weeks. The VSMC used each week have a common source, are treated in parallel, and are subject to vagaries peculiar to that week for the multi-step protocol.</p>
<p>The results are entered in the code below, creating a wide format data frame:</p>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb347-1" title="1">pki &lt;-<span class="st"> </span><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb347-2" title="2">  <span class="dt">replicate=</span><span class="kw">c</span>(<span class="st">&#39;week1&#39;</span>, <span class="st">&#39;week2&#39;</span>, <span class="st">&#39;week3&#39;</span>, <span class="st">&#39;week4&#39;</span>, <span class="st">&#39;week5&#39;</span>),</a>
<a class="sourceLine" id="cb347-3" title="3">  <span class="dt">basal=</span><span class="kw">c</span>(<span class="fl">20.0</span>, <span class="fl">5.0</span>, <span class="fl">2.1</span>, <span class="fl">9.0</span>, <span class="fl">23.7</span>),</a>
<a class="sourceLine" id="cb347-4" title="4">  <span class="dt">isoproterenol=</span><span class="kw">c</span>(<span class="fl">38.3</span>, <span class="fl">9.1</span>, <span class="fl">3.6</span>, <span class="fl">15.5</span>, <span class="fl">38.9</span>),</a>
<a class="sourceLine" id="cb347-5" title="5">  <span class="dt">iso_GFP_PKI=</span><span class="kw">c</span>(<span class="fl">27.5</span>, <span class="fl">6.7</span>, <span class="fl">2.7</span>, <span class="fl">12.1</span>,<span class="fl">28.0</span> ),</a>
<a class="sourceLine" id="cb347-6" title="6">  <span class="dt">iso_GFP=</span><span class="kw">c</span>(<span class="fl">36.1</span>, <span class="fl">8.5</span>, <span class="fl">4.2</span>, <span class="fl">16.0</span>,<span class="fl">39.9</span> )</a>
<a class="sourceLine" id="cb347-7" title="7">)</a></code></pre></div>
<p>Here is a plot of the VSMC data. Note how it was converted to long format within the ggplot function:</p>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb348-1" title="1"><span class="kw">ggplot</span>(pki <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb348-2" title="2"><span class="st">         </span><span class="kw">pivot_longer</span>(<span class="op">-</span>replicate, </a>
<a class="sourceLine" id="cb348-3" title="3">                      <span class="dt">names_to=</span><span class="st">&quot;stimulus&quot;</span>, </a>
<a class="sourceLine" id="cb348-4" title="4">                      <span class="dt">values_to =</span><span class="st">&quot;pka&quot;</span>), </a>
<a class="sourceLine" id="cb348-5" title="5">       <span class="kw">aes</span>(stimulus, pka, <span class="dt">group=</span>replicate, <span class="dt">color=</span>replicate)</a>
<a class="sourceLine" id="cb348-6" title="6">       )<span class="op">+</span></a>
<a class="sourceLine" id="cb348-7" title="7"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size=</span><span class="dv">4</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb348-8" title="8"><span class="st">  </span><span class="kw">geom_line</span>()<span class="op">+</span></a>
<a class="sourceLine" id="cb348-9" title="9"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y=</span><span class="st">&quot;PKA activity, pmole/mg/min&quot;</span>)</a></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-193"></span>
<img src="jabstb_files/figure-html/unnamed-chunk-193-1.png" alt="PKA activity in VSMC, note related measures within each replicate." width="672" />
<p class="caption">
Figure 19.9: PKA activity in VSMC, note related measures within each replicate.
</p>
</div>
<table>
<caption>
(#tab:Table of PKA activity data)Replicate measurements of PKA enzyme activity (pmole/mg/min) in cultured rat vascular smooth muscle cells (VSMC).
</caption>
<thead>
<tr>
<th style="text-align:left;">
replicate
</th>
<th style="text-align:right;">
basal
</th>
<th style="text-align:right;">
isoproterenol
</th>
<th style="text-align:right;">
iso_GFP_PKI
</th>
<th style="text-align:right;">
iso_GFP
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
week1
</td>
<td style="text-align:right;">
20.0
</td>
<td style="text-align:right;">
38.3
</td>
<td style="text-align:right;">
27.5
</td>
<td style="text-align:right;">
36.1
</td>
</tr>
<tr>
<td style="text-align:left;">
week2
</td>
<td style="text-align:right;">
5.0
</td>
<td style="text-align:right;">
9.1
</td>
<td style="text-align:right;">
6.7
</td>
<td style="text-align:right;">
8.5
</td>
</tr>
<tr>
<td style="text-align:left;">
week3
</td>
<td style="text-align:right;">
2.1
</td>
<td style="text-align:right;">
3.6
</td>
<td style="text-align:right;">
2.7
</td>
<td style="text-align:right;">
4.2
</td>
</tr>
<tr>
<td style="text-align:left;">
week4
</td>
<td style="text-align:right;">
9.0
</td>
<td style="text-align:right;">
15.5
</td>
<td style="text-align:right;">
12.1
</td>
<td style="text-align:right;">
16.0
</td>
</tr>
<tr>
<td style="text-align:left;">
week5
</td>
<td style="text-align:right;">
23.7
</td>
<td style="text-align:right;">
38.9
</td>
<td style="text-align:right;">
28.0
</td>
<td style="text-align:right;">
39.9
</td>
</tr>
</tbody>
</table>
<p>As seen in the graph and the table, for a given predictor variable there is as much as a 10-fold difference in activity from week to week. But within each row are consistent fold-differences between treatments.</p>
<p>The inconsistent levels of raw enzymatic activity from week-to-week make this suitable for nonparametric testing, whereas the weekly block design calls for related measures analysis. Thus the Friedman test.</p>
<p>The Friedman test can answer this question: Do any of these treatments differ? The test does not provide information on which groups differ, serving instead as an omnibus. The test output is simply a p-value, derived from the so-called Friedman chisquare.</p>
<p>There are a couple of options for performing the test.</p>
<p>The first involves converting the data to a matrix, omitting the values of the <code>replicate</code> variable, and passing that matrix of responses into the <code>friendman.test</code> function. The final row names decoration is not essential for <code>friedman.test</code>, but does help the posthoc tests play nicer.</p>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb349-1" title="1">pkiM &lt;-<span class="st"> </span>pki <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb349-2" title="2"><span class="st">  </span><span class="kw">select</span>(basal<span class="op">:</span>iso_GFP) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb349-3" title="3"><span class="st">  </span><span class="kw">as.matrix</span>()</a>
<a class="sourceLine" id="cb349-4" title="4"><span class="kw">rownames</span>(pkiM) &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">5</span></a></code></pre></div>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb350-1" title="1"><span class="kw">friedman.test</span>(pkiM)</a></code></pre></div>
<pre><code>## 
##  Friedman rank sum test
## 
## data:  pkiM
## Friedman chi-squared = 13.56, df = 3, p-value = 0.00357</code></pre>
<p>The second approach is the so-called formula method, which we’ll use a lot when we get to regression. First, convert the data to a long format data frame.</p>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb352-1" title="1">pkiL &lt;-<span class="st"> </span>pki <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb352-2" title="2"><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="op">-</span>replicate, </a>
<a class="sourceLine" id="cb352-3" title="3">               <span class="dt">names_to =</span> <span class="st">&quot;stimulus&quot;</span>, </a>
<a class="sourceLine" id="cb352-4" title="4">               <span class="dt">values_to=</span><span class="st">&quot;pka&quot;</span>)</a></code></pre></div>
<p>Now pass that format into <code>friedman.test</code>. In English, this formula reads, “run the Friedman test on pka activity by stimulus levels, with related measures by replicate”.</p>
<div class="sourceCode" id="cb353"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb353-1" title="1"><span class="kw">friedman.test</span>(pka<span class="op">~</span>stimulus<span class="op">|</span>replicate, </a>
<a class="sourceLine" id="cb353-2" title="2">              <span class="dt">data=</span>pkiL)</a></code></pre></div>
<pre><code>## 
##  Friedman rank sum test
## 
## data:  pka and stimulus and replicate
## Friedman chi-squared = 13.56, df = 3, p-value = 0.00357</code></pre>
<p>Because this p-value is below a 5% type1 error threshold, this result indicates that levels of the stimulus variable cause differences in PKA activities.</p>
<p>However, posthoc comparison tests are necessary to find out which differences between stimulus levels are reliable.</p>
<div class="sourceCode" id="cb355"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb355-1" title="1"><span class="kw">frdAllPairsConoverTest</span>(pkiM, </a>
<a class="sourceLine" id="cb355-2" title="2">                       <span class="dt">p.adjust=</span><span class="st">&quot;bonf&quot;</span>)</a></code></pre></div>
<pre><code>## 
##  Pairwise comparisons using Conover&#39;s all-pairs test for a two-way balanced complete block design</code></pre>
<pre><code>## data: y</code></pre>
<pre><code>##               basal isoproterenol iso_GFP_PKI
## isoproterenol 0.087 -             -          
## iso_GFP_PKI   1.000 0.733         -          
## iso_GFP       0.056 1.000         0.489</code></pre>
<pre><code>## 
## P value adjustment method: bonferroni</code></pre>
<p>You’ll find a handful of pairwise posthoc comparison functions like the two used in this chapter in the <code>PMCMRplus</code> package. They are based upon different formulas and perform differently. It is not possible to conclude that one is better than another, except those that allow for a p-value adjustment should be used.</p>
<p>In this particular case, we have an ambiguous and underpowered data set. If you play with this data on your own machine, you’ll find there is ample latitude for prosperous p-hacking in the post hoc testing.</p>
<p>For example, if the p-values are unadjusted for multiple comparisons, all of the post hoc functions yield statistical differences. But unadjusted comparisons are not very stringent.</p>
<p>Alternately, certain post hoc tests with other p-value adjustment options yield statistical differences.</p>
<p>The question is not “which one is better”? The approach to take is to run realistic simulations in advance of collecting data, learn about the options by playing with familiar variables, and choose accordingly. Write down your choices for how you you intend to post hoc once the new data is collected, and stick with that plan.</p>
</div>
<div id="interpretation-5" class="section level3">
<h3><span class="header-section-number">19.9.2</span> Interpretation</h3>
<p>Because the p-value of the Friedman test statistic is below the 5% threshold, we can reject the null that there are no differences in PKA activity caused by the four stimulus conditions.</p>
<p>However, the post hoc multiple comparison testing, with appropriate p-value adjustment, is inconclusive. The bloody obvious evidence (as seen by inspecting the table and figure) that the GFP-PKI construct inhibits PKA is unsupported by the statistical analysis. The experiment is underpowered. There are too few independent replicates.</p>
<p>Although there is a proverbial “trending towards significance”<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> for two of the comparisons, neither of these speak to the most important outcome, which is to observe that GFP-PKI inhibits PKA activity.</p>
<p>It turns out transfection inefficiency explained this failure. The data reflect that the inhibitor was working, just not in enough cells. This was overcome by a significant protocol adjustment so that more cells expressed the inhibitor.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></p>
</div>
<div id="write-up-11" class="section level3">
<h3><span class="header-section-number">19.9.3</span> Write up</h3>
<p><em>Although a positive nonparametric Friedman test indicates there are differences in PKA activity among levels of the stimuli (Friedman chi-squared = 13.56, df = 3, p-value = 0.00357), no statistical differences are observed in pairwise post hoc comparisons, likely because the effects are small and the experiment is underpowered (Conover test with Holm p-value adjustment, experimentwise type 1 error threshold of 5%).</em></p>
</div>
</div>
<div id="nonparametric-power-calculations" class="section level2">
<h2><span class="header-section-number">19.10</span> Nonparametric power calculations</h2>
<p>The function below, <code>nonpara.pwr</code> is configured to simulate the power of nonparametric one- and two-group comparisons using the Wilcoxon test function of R.</p>
<p>The intended use of this function is to establish <em>a priori</em> the sample size needed to yield a level of power that you deem acceptable.</p>
<p>The function simulates a long run sample results at a given sample size, running a statistical test on each. Power is simply the fraction of these tests that have p-values below a chosen threshold. This is a Monte Carlo method.</p>
<p>The function strictly takes the argument of a sample size value and returns an experimental power that sample size generates. For example, after loading the function in your environment, typing <code>nonparam.pwr(n=5)</code> in the console will return the power for the test you configured.</p>
<p>That configuration customization of the function’s initialization. Do this by entering estimates for parameters of the population you expect to sample. All you need for that is a scientific hunch about the values for the outcome variable you expect your experiment will produce.</p>
<div id="how-it-works" class="section level3">
<h3><span class="header-section-number">19.10.1</span> How it works</h3>
<p>Monte Carlo is general statistical jargon for repeated simulation. This is a technique widely used in many applications across statistics and data science.</p>
<p>In this course, Monte Carlo power calculations means that we are mostly running repeated simulations to determine a sample size for a planned experiment.</p>
<div id="tldr" class="section level4">
<h4><span class="header-section-number">19.10.1.1</span> tl;dr</h4>
<ol style="list-style-type: decimal">
<li>Simulate a random sample.</li>
<li>Run a statistical test on the sample.</li>
<li>Collect the p-value from that test.</li>
<li>Repeat steps 1 through 3 ~1000 times or more.</li>
<li>Count the p-values that are below a type1 threshold, such as 0.05.</li>
</ol>
</div>
</div>
<div id="simulating-response-data" class="section level3">
<h3><span class="header-section-number">19.10.2</span> Simulating response data</h3>
<p>Nonparametric tests are useful for a diverse array of data types. So it is useful to know there are many ways to mimic this diversity. What’s most important is mimicking the effect sizes (eg, differences) and variation as realistically as possible.</p>
<p>Using the random number generator functions of the various probability distributions in R is suitable for many cases. Bear in mind, the base distributions we cover in this course are just tip of the iceberg.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
<p>For other problems, random sampling functions like <code>sample</code> can be configured to do the trick.</p>
<p>For example, use <code>rnorm</code> for measured variables for which you believe you can predict means and standard deviations. Make sure your <code>sd</code> estimate is realistic. Most people underestimate <code>sd</code>.</p>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb360-1" title="1"><span class="co"># simulate a sample size of 5 for a normally-distributed </span></a>
<a class="sourceLine" id="cb360-2" title="2"><span class="co">#variable with mean of 100 units and standard deviation of 25 units</span></a>
<a class="sourceLine" id="cb360-3" title="3">control<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">5</span>, <span class="dt">mean=</span><span class="dv">100</span>, <span class="dt">sd=</span><span class="dv">25</span>)</a>
<a class="sourceLine" id="cb360-4" title="4">treatment<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">5</span>, <span class="dt">mean=</span><span class="dv">150</span>, <span class="dt">sd=</span><span class="dv">25</span>)</a>
<a class="sourceLine" id="cb360-5" title="5">sim.set1 &lt;-<span class="st"> </span><span class="kw">tibble</span>(control<span class="fl">.1</span>, </a>
<a class="sourceLine" id="cb360-6" title="6">                   treatment<span class="fl">.1</span>) </a>
<a class="sourceLine" id="cb360-7" title="7">sim.set1</a></code></pre></div>
<pre><code>## # A tibble: 5 x 2
##   control.1 treatment.1
##       &lt;dbl&gt;       &lt;dbl&gt;
## 1     108.         176.
## 2      91.8        137.
## 3     120.         104.
## 4     127.         158.
## 5     167.         138.</code></pre>
<p>Use <code>rpois</code> to simulate variables that represent discrete events, such as frequencies. How many depolarizations do you expect at baseline? How many more (or less) do you think your treatment will cause?</p>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb362-1" title="1"><span class="co">#simulate 5 events, where each occurs at an average frequency of 7.</span></a>
<a class="sourceLine" id="cb362-2" title="2"></a>
<a class="sourceLine" id="cb362-3" title="3">control<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">rpois</span>(<span class="dt">n=</span><span class="dv">5</span>, <span class="dt">lambda=</span><span class="dv">7</span>)</a>
<a class="sourceLine" id="cb362-4" title="4">treatment<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">rpois</span>(<span class="dt">n=</span><span class="dv">5</span>, <span class="dt">lambda=</span><span class="dv">10</span>)</a>
<a class="sourceLine" id="cb362-5" title="5">sim.set2 &lt;-<span class="st"> </span><span class="kw">tibble</span>(control<span class="fl">.2</span>, treatment<span class="fl">.2</span>); sim.set2</a></code></pre></div>
<pre><code>## # A tibble: 5 x 2
##   control.2 treatment.2
##       &lt;int&gt;       &lt;int&gt;
## 1        11           9
## 2         7           8
## 3         4          10
## 4         3           7
## 5         5           7</code></pre>
<p>Use <code>rlnorm</code> to simulate variables that have log normal distributions, which just happens a lot in biological systems. It takes some playing to get used to simulating with <code>rlnorm</code> but the results can look scary realistic compared to <code>rnorm</code>.</p>
<div class="sourceCode" id="cb364"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb364-1" title="1"><span class="co"># simulate 5 events, from a log normal distribution</span></a>
<a class="sourceLine" id="cb364-2" title="2">control<span class="fl">.3</span> &lt;-<span class="st"> </span><span class="kw">rlnorm</span>(<span class="dt">n=</span><span class="dv">5</span>, <span class="dt">meanlog=</span><span class="dv">0</span>, <span class="dt">sdlog=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb364-3" title="3">treatment<span class="fl">.3</span> &lt;-<span class="st"> </span><span class="kw">rlnorm</span>(<span class="dt">n=</span><span class="dv">5</span>, <span class="dt">meanlog=</span><span class="dv">2</span>, <span class="dt">sdlog=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb364-4" title="4">sim.set3 &lt;-<span class="st"> </span><span class="kw">tibble</span>(control<span class="fl">.3</span>, treatment<span class="fl">.3</span>); sim.set3</a></code></pre></div>
<pre><code>## # A tibble: 5 x 2
##   control.3 treatment.3
##       &lt;dbl&gt;       &lt;dbl&gt;
## 1     0.267       42.7 
## 2     1.53         5.87
## 3     1.81        14.1 
## 4     1.60         6.34
## 5     0.561        3.15</code></pre>
<p>It’s even possible to simulate ordinal data, such as the outcome of likert tests. The <code>sample()</code> function can be configured for this purpose. Note how a probability vector argument is used to cast expected distributions of the values</p>
<div class="sourceCode" id="cb366"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb366-1" title="1"><span class="co">#simulate 6 replicates scored on a 5-unit ordinal scale, </span></a>
<a class="sourceLine" id="cb366-2" title="2"><span class="co">#where 1 is the lowest level of an observed outcome and 5 is the highest.</span></a>
<a class="sourceLine" id="cb366-3" title="3"></a>
<a class="sourceLine" id="cb366-4" title="4">control<span class="fl">.4</span> &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>), <span class="dt">size=</span><span class="dv">6</span>, </a>
<a class="sourceLine" id="cb366-5" title="5">       <span class="dt">replace=</span>T, <span class="dt">prob=</span><span class="kw">c</span>(.<span class="dv">70</span>, <span class="fl">.25</span>, <span class="fl">.05</span>, <span class="dv">0</span>, <span class="dv">0</span>))</a>
<a class="sourceLine" id="cb366-6" title="6">treatment<span class="fl">.4</span> &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>), <span class="dt">size=</span><span class="dv">6</span>, </a>
<a class="sourceLine" id="cb366-7" title="7">       <span class="dt">replace=</span>T, <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="fl">0.15</span>, <span class="fl">0.70</span>, <span class="fl">0.15</span>))</a>
<a class="sourceLine" id="cb366-8" title="8">results &lt;-<span class="st"> </span><span class="kw">tibble</span>(control<span class="fl">.4</span>, treatment<span class="fl">.4</span>); results</a></code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   control.4 treatment.4
##       &lt;int&gt;       &lt;int&gt;
## 1         1           5
## 2         1           3
## 3         1           4
## 4         1           4
## 5         1           3
## 6         1           4</code></pre>
<p>If a more sophisticated simulation of ordinal data is needed, you’ll find it is <a href="https://www.rdatagen.net/post/generating-and-displaying-likert-type-data/">doable but suprisingly not trivial</a>.</p>
<p>Please recognize that simulating data for these functions mostly depends upon your scientific understanding of the variables. You have to make scientific judgments about the values your variable will take on under control and treatment conditions.</p>
<p>To get started statistically, go back to the basics. Is the variable discrete or continuous. Is it measured or ordered or sorted? What means and standard deviations, or frequencies, or rank sizes should you estimate? Those are all scientific judgments.</p>
<p>Either select the values you predict will occur, OR enter values that you believe would be a minimal, scientifically meaningful effect size.</p>
</div>
<div id="an-example" class="section level3">
<h3><span class="header-section-number">19.10.3</span> An example</h3>
<p>Let’s say we study mouse models of diabetes. In non-diabetic control subjects, mean plasma glucose concentration is typically ~100 mg/dL and the variability tends to be quite low (15 mg/dL).</p>
<p>Most everybody in the field agrees that average blood glucose concentration of 300 mg/dL represents successful induction of diabetes in these models.</p>
<p>However, experience shows these higher levels of glucose are associated with considerably greater variability (SD=150 mg/dL) than under normal states. Large differences in variability between two groups are called heteroscedaticity. The presence of heteroscedaticity can preclude the use of parametric statistical tests since it raises type1 error risk. Thus, nonparametric testing would be used when expecting such outcomes.</p>
<p>Let’s say you want to test a new idea for diabetes induction. What sample size would be necessary, assuming an nonparametric testing and an unpaired design, to reliably detect a difference between these two groups at 80% power or better?</p>
<p>The function below calculates the power of experiments that might be expected to generate such results, at given sample sizes.</p>
</div>
<div id="nonpara.pwr" class="section level3">
<h3><span class="header-section-number">19.10.4</span> nonpara.pwr</h3>
<p>Running this first code chunk reads the custom function into the environment. There’s no output, yet. You’ll see some code later that uses this function.</p>
<p>Read it line-by-line to see if you can follow the logic. Or read the comments which explain it.</p>
<div class="sourceCode" id="cb368"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb368-1" title="1">nonpara.pwr &lt;-<span class="st"> </span><span class="cf">function</span>(n){</a>
<a class="sourceLine" id="cb368-2" title="2">  </a>
<a class="sourceLine" id="cb368-3" title="3"><span class="co">#Intitializers. Place expected values for the means and standard deviations of two groups to be compared here. These values will be called by the function a few lines below</span></a>
<a class="sourceLine" id="cb368-4" title="4">  </a>
<a class="sourceLine" id="cb368-5" title="5">  m1=<span class="st"> </span><span class="dv">100</span> <span class="co">#mean of group 1</span></a>
<a class="sourceLine" id="cb368-6" title="6">  sd1=<span class="st"> </span><span class="dv">10</span> <span class="co">#standard deviation of group 1</span></a>
<a class="sourceLine" id="cb368-7" title="7">  </a>
<a class="sourceLine" id="cb368-8" title="8">  m2=<span class="st"> </span><span class="dv">300</span> <span class="co">#mean of group 2</span></a>
<a class="sourceLine" id="cb368-9" title="9">  sd2=<span class="st"> </span><span class="dv">150</span> <span class="co">#standard deviation of group 2</span></a>
<a class="sourceLine" id="cb368-10" title="10">  </a>
<a class="sourceLine" id="cb368-11" title="11">  </a>
<a class="sourceLine" id="cb368-12" title="12">  <span class="co"># the monte carlo just repeats the random sampling i times. It runs a t-test on each sample, i, grabs the p-value and places it in a growing vector, p.values[i]</span></a>
<a class="sourceLine" id="cb368-13" title="13">  ssims=<span class="dv">1000</span></a>
<a class="sourceLine" id="cb368-14" title="14">  </a>
<a class="sourceLine" id="cb368-15" title="15">  <span class="co">#The function below produced p-values. This empty vector has to exist before the first p-value is generated. It will be filled successfully with p-values as the repeat component below...repeats.</span></a>
<a class="sourceLine" id="cb368-16" title="16">  </a>
<a class="sourceLine" id="cb368-17" title="17">  p.values &lt;-<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb368-18" title="18">  </a>
<a class="sourceLine" id="cb368-19" title="19">  <span class="co">#This repeat function is a function inside a function. It repeats the simulation ssims times, collecting a p-value each time, and depositing that new p-value in our growing vector. Importantly, change the arguments for the statitical test to suit your experimental design. Want to simulate a &quot;greater&quot; hypothesis? Change it here. What about a paired model? Change it here, not after you run an experiment.</span></a>
<a class="sourceLine" id="cb368-20" title="20">  </a>
<a class="sourceLine" id="cb368-21" title="21">  i &lt;-<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb368-22" title="22">  <span class="cf">repeat</span>{</a>
<a class="sourceLine" id="cb368-23" title="23">    x=<span class="kw">rnorm</span>(n, m1, sd1); <span class="co"># random data generator motifs</span></a>
<a class="sourceLine" id="cb368-24" title="24">    y=<span class="kw">rnorm</span>(n, m2, sd2);</a>
<a class="sourceLine" id="cb368-25" title="25">    p &lt;-<span class="st"> </span><span class="kw">wilcox.test</span>(x, y, </a>
<a class="sourceLine" id="cb368-26" title="26">                <span class="dt">paired=</span>F, </a>
<a class="sourceLine" id="cb368-27" title="27">                <span class="dt">alternative=</span><span class="st">&quot;two.sided&quot;</span>, </a>
<a class="sourceLine" id="cb368-28" title="28">                <span class="dt">var.equal=</span>F,</a>
<a class="sourceLine" id="cb368-29" title="29">                <span class="dt">conf.level=</span><span class="fl">0.95</span>)<span class="op">$</span>p.value</a>
<a class="sourceLine" id="cb368-30" title="30">    p.values[i] &lt;-<span class="st"> </span>p</a>
<a class="sourceLine" id="cb368-31" title="31">    </a>
<a class="sourceLine" id="cb368-32" title="32">    <span class="cf">if</span> (i<span class="op">==</span>ssims) <span class="cf">break</span></a>
<a class="sourceLine" id="cb368-33" title="33">    i =<span class="st"> </span>i<span class="op">+</span><span class="dv">1</span></a>
<a class="sourceLine" id="cb368-34" title="34">    <span class="co">#This calculates the power from the values in the p.value vector.</span></a>
<a class="sourceLine" id="cb368-35" title="35">    pwr &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">which</span>(p.values<span class="op">&lt;</span><span class="fl">0.05</span>))<span class="op">/</span>ssims</a>
<a class="sourceLine" id="cb368-36" title="36">  }</a>
<a class="sourceLine" id="cb368-37" title="37">  <span class="kw">return</span>(pwr)</a>
<a class="sourceLine" id="cb368-38" title="38">  </a>
<a class="sourceLine" id="cb368-39" title="39">}</a></code></pre></div>
<p>To get some output, pass a sample size of n= 5 per group into the function.</p>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb369-1" title="1"><span class="co"># test it!</span></a>
<a class="sourceLine" id="cb369-2" title="2"><span class="kw">set.seed</span>(<span class="dv">1234</span>)</a>
<a class="sourceLine" id="cb369-3" title="3"><span class="kw">nonpara.pwr</span>(<span class="dv">5</span>)</a></code></pre></div>
<pre><code>## [1] 0.626</code></pre>
<p>At this seed, the power is 62.6% for a sample size of 5 per group. YMMV if on a Mac.</p>
<p>A slightly higher power would be desirable. Change the value of <code>n</code> in the test it code chunk to see what’s necessary to get 80% power.</p>
<p>Or, more easily, just run <code>nonpara.pwr</code> over a range of sample sizes, plotting a power vs sample size curve.</p>
<p>There are a couple of keys here. First, make a simple dataframe with only one variable, a bunch of n values.</p>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb371-1" title="1"><span class="co">#frame is a data frame with only one variable, sample size</span></a>
<a class="sourceLine" id="cb371-2" title="2">frame &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">n=</span><span class="dv">2</span><span class="op">:</span><span class="dv">50</span>)</a></code></pre></div>
<p>Second, use R’s <code>apply</code> function to, row by row, calculate power for each value of n. This will take some time to run. Hopefully just a few seconds if you have a decent machine.</p>
<div class="sourceCode" id="cb372"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb372-1" title="1"><span class="co">#data is a data frame with two variables, sample size and a power value for each</span></a>
<a class="sourceLine" id="cb372-2" title="2">data &lt;-<span class="st"> </span><span class="kw">bind_cols</span>(frame, </a>
<a class="sourceLine" id="cb372-3" title="3">                  <span class="dt">power=</span><span class="kw">apply</span>(frame, <span class="dv">1</span>, nonpara.pwr))</a></code></pre></div>
<p>Now plot it out!</p>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb373-1" title="1"><span class="co">#plot</span></a>
<a class="sourceLine" id="cb373-2" title="2"><span class="kw">ggplot</span>(data, <span class="kw">aes</span>(n, power))<span class="op">+</span></a>
<a class="sourceLine" id="cb373-3" title="3"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb373-4" title="4"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks=</span><span class="kw">c</span>(<span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.1</span>)))<span class="op">+</span></a>
<a class="sourceLine" id="cb373-5" title="5"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span><span class="kw">c</span>(<span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">50</span>,<span class="dv">2</span>)))</a></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-194"></span>
<img src="jabstb_files/figure-html/unnamed-chunk-194-1.png" alt="A power curve for simulated Wilcox testing for an antidiabetic drug effect. " width="672" />
<p class="caption">
Figure 19.10: A power curve for simulated Wilcox testing for an antidiabetic drug effect.
</p>
</div>
<p>This result shows that a sample size of 7, 8, or 9 per group would give ~85% power. Thus, a sample size of 7 per group would be the minimal size necessary to test the two-sided null that there is no difference between the groups, at a 95% confidence level.</p>
<p>Notice how the power is discrete for the early runs? That’s a byproduct of the discrete nature of nonparametric sampling distributions.</p>
<p>Think about the general way this Monte Carlo technique worked: simulate, test, repeat that many times, count up the p-values.</p>
<p>It shouldn’t be much of a leap for you to realize this approach can be run for any experimental design. If you know what experiment you want to run, you can simulate how it will work thousands of times in just a few seconds. Minutes at the worst.</p>
</div>
</div>
<div id="summary-1" class="section level2">
<h2><span class="header-section-number">19.11</span> Summary</h2>
<p>If you’re used to comparing means of groups, nonparametrics can be somewhat disorienting. There are no parameters to compare! And the concept of location shifts or vague differences seems rather abstract.</p>
<p>The tests transform the values of experimental outcome variables into either sign rank or into rank sum units. That abstraction can be disorientating, too. But it is important to recognize that sign ranks and rank sum distributions are approximately normal.</p>
<p>Therefore, perhaps its best to think of nonparametrics as a way to transform non-normal data into more normal data, from which predictable p-values can be derived.</p>
<p>The nonparametrics are powerful statistical tests that should be used more widely than they are.</p>
<p>Power analysis is really important when designing experiments. It allows you to determine a proper sample size to give your idea the severe test it deserves. The process can also help you evaluate the feasibility and even cost of an experiment. Are there enough mice in the world to test your idea? Will you still be young after doing your laborious protocol on as many replicates as the power analysis suggests is necessary?</p>
<p>Embrace the Monte Carlo technique if you agree it is better to try to work out these questions over the course of a few hours coding in R, rather than jumping into a rabbit hole and hoping for an exit.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="4">
<li id="fn4"><p><a href="http://www.academiaobscura.com/still-not-significant/" class="uri">http://www.academiaobscura.com/still-not-significant/</a><a href="nonparametrics.html#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p><a href="http://molpharm.aspetjournals.org/content/54/3/514" class="uri">http://molpharm.aspetjournals.org/content/54/3/514</a><a href="nonparametrics.html#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>For a comprehensive list of distribution functions in R see <a href="https://cran.r-project.org/web/views/Distributions.html" class="uri">https://cran.r-project.org/web/views/Distributions.html</a><a href="nonparametrics.html#fnref6" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chisquare.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="signrank.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["jabstb.pdf", "jabstb.epub"],
"toc": {
"collapse": "subsection"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
