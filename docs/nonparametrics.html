<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 17 Nonparametric Statistical Tests | JABSTB: Statistical Design and Analysis of Experiments with R</title>
  <meta name="description" content="Experimental biostatistics using R.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 17 Nonparametric Statistical Tests | JABSTB: Statistical Design and Analysis of Experiments with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Experimental biostatistics using R." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 17 Nonparametric Statistical Tests | JABSTB: Statistical Design and Analysis of Experiments with R" />
  
  <meta name="twitter:description" content="Experimental biostatistics using R." />
  

<meta name="author" content="TJ Murphy PhD, Department of Pharmacology and Chemical Biology, School of Medicine, Emory University, Atlanta, GA biostats538@gmail.com">


<meta name="date" content="2019-02-26">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="chisquare.html">
<link rel="next" href="signrank.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">JABSTB</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="author.html"><a href="author.html"><i class="fa fa-check"></i><b>1</b> About the author</a></li>
<li class="chapter" data-level="2" data-path="history.html"><a href="history.html"><i class="fa fa-check"></i><b>2</b> A Brief History of Experimental Design</a></li>
<li class="chapter" data-level="3" data-path="software.html"><a href="software.html"><i class="fa fa-check"></i><b>3</b> Software</a><ul>
<li class="chapter" data-level="3.1" data-path="software.html"><a href="software.html#my-code-is-your-code"><i class="fa fa-check"></i><b>3.1</b> My code is your code</a></li>
<li class="chapter" data-level="3.2" data-path="software.html"><a href="software.html#install-r-and-rstudio"><i class="fa fa-check"></i><b>3.2</b> Install R and RStudio</a></li>
<li class="chapter" data-level="3.3" data-path="software.html"><a href="software.html#getting-started-with-r"><i class="fa fa-check"></i><b>3.3</b> Getting started with R</a></li>
<li class="chapter" data-level="3.4" data-path="software.html"><a href="software.html#other-resources"><i class="fa fa-check"></i><b>3.4</b> Other resources</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="bigpic.html"><a href="bigpic.html"><i class="fa fa-check"></i><b>4</b> The Big Picture</a><ul>
<li class="chapter" data-level="4.1" data-path="bigpic.html"><a href="bigpic.html#what-are-experimental-statistics"><i class="fa fa-check"></i><b>4.1</b> What are experimental statistics?</a><ul>
<li class="chapter" data-level="4.1.1" data-path="bigpic.html"><a href="bigpic.html#descriptive-modeling"><i class="fa fa-check"></i><b>4.1.1</b> Descriptive modeling</a></li>
<li class="chapter" data-level="4.1.2" data-path="bigpic.html"><a href="bigpic.html#statistical-inference"><i class="fa fa-check"></i><b>4.1.2</b> Statistical inference</a></li>
<li class="chapter" data-level="4.1.3" data-path="bigpic.html"><a href="bigpic.html#experimental-design"><i class="fa fa-check"></i><b>4.1.3</b> Experimental design</a></li>
<li class="chapter" data-level="4.1.4" data-path="bigpic.html"><a href="bigpic.html#statistics-as-an-anti-bias-framework"><i class="fa fa-check"></i><b>4.1.4</b> Statistics as an anti-bias framework</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="sampling.html"><a href="sampling.html"><i class="fa fa-check"></i><b>5</b> Statistical Sampling</a><ul>
<li class="chapter" data-level="5.1" data-path="sampling.html"><a href="sampling.html#experimental-units"><i class="fa fa-check"></i><b>5.1</b> Experimental units</a><ul>
<li class="chapter" data-level="5.1.1" data-path="sampling.html"><a href="sampling.html#a-simple-test-to-define-the-experimental-unit"><i class="fa fa-check"></i><b>5.1.1</b> A simple test to define the experimental unit</a></li>
<li class="chapter" data-level="5.1.2" data-path="sampling.html"><a href="sampling.html#blocking"><i class="fa fa-check"></i><b>5.1.2</b> Blocking</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="sampling.html"><a href="sampling.html#independent-replicates"><i class="fa fa-check"></i><b>5.2</b> Independent Replicates</a><ul>
<li class="chapter" data-level="5.2.1" data-path="sampling.html"><a href="sampling.html#a-simple-test-for-independence"><i class="fa fa-check"></i><b>5.2.1</b> A simple test for independence</a></li>
<li class="chapter" data-level="5.2.2" data-path="sampling.html"><a href="sampling.html#some-replication-examples"><i class="fa fa-check"></i><b>5.2.2</b> Some replication examples</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="sampling.html"><a href="sampling.html#random-process"><i class="fa fa-check"></i><b>5.3</b> Random process</a></li>
<li class="chapter" data-level="5.4" data-path="sampling.html"><a href="sampling.html#statistically-valid-samples"><i class="fa fa-check"></i><b>5.4</b> Statistically valid samples</a><ul>
<li class="chapter" data-level="5.4.1" data-path="sampling.html"><a href="sampling.html#select-random-subjects"><i class="fa fa-check"></i><b>5.4.1</b> Select random subjects</a></li>
<li class="chapter" data-level="5.4.2" data-path="sampling.html"><a href="sampling.html#randomize-to-sequence"><i class="fa fa-check"></i><b>5.4.2</b> Randomize to sequence</a></li>
<li class="chapter" data-level="5.4.3" data-path="sampling.html"><a href="sampling.html#randomize-to-location"><i class="fa fa-check"></i><b>5.4.3</b> Randomize to location</a></li>
<li class="chapter" data-level="5.4.4" data-path="sampling.html"><a href="sampling.html#randomize-to-block"><i class="fa fa-check"></i><b>5.4.4</b> Randomize to block</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="sampling.html"><a href="sampling.html#independence-of-replicates"><i class="fa fa-check"></i><b>5.5</b> Independence of replicates</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>6</b> Data Classification</a><ul>
<li class="chapter" data-level="6.1" data-path="data.html"><a href="data.html#dependent-and-independent-variables"><i class="fa fa-check"></i><b>6.1</b> Dependent and independent variables</a><ul>
<li class="chapter" data-level="6.1.1" data-path="data.html"><a href="data.html#when-there-is-no-independent-variable"><i class="fa fa-check"></i><b>6.1.1</b> When there is no independent variable</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="data.html"><a href="data.html#discrete-or-continuous-variables"><i class="fa fa-check"></i><b>6.2</b> Discrete or continuous variables</a><ul>
<li class="chapter" data-level="6.2.1" data-path="data.html"><a href="data.html#measured-variables"><i class="fa fa-check"></i><b>6.2.1</b> Measured variables</a></li>
<li class="chapter" data-level="6.2.2" data-path="data.html"><a href="data.html#discrete-categorical-and-ordinal-variables"><i class="fa fa-check"></i><b>6.2.2</b> Discrete categorical and ordinal variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="dispersion.html"><a href="dispersion.html"><i class="fa fa-check"></i><b>7</b> Variability, Accuracy and Precision</a><ul>
<li class="chapter" data-level="7.1" data-path="dispersion.html"><a href="dispersion.html#variance-quantifying-variation-by-least-squares"><i class="fa fa-check"></i><b>7.1</b> Variance: Quantifying variation by least squares</a></li>
<li class="chapter" data-level="7.2" data-path="dispersion.html"><a href="dispersion.html#standard-deviation"><i class="fa fa-check"></i><b>7.2</b> Standard deviation</a><ul>
<li class="chapter" data-level="7.2.1" data-path="dispersion.html"><a href="dispersion.html#what-does-the-standard-deviation-tell-us"><i class="fa fa-check"></i><b>7.2.1</b> What does the standard deviation tell us</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="dispersion.html"><a href="dispersion.html#other-ways-of-describing-variability"><i class="fa fa-check"></i><b>7.3</b> Other ways of describing variability</a></li>
<li class="chapter" data-level="7.4" data-path="dispersion.html"><a href="dispersion.html#precision-and-accuracy"><i class="fa fa-check"></i><b>7.4</b> Precision and Accuracy</a></li>
<li class="chapter" data-level="7.5" data-path="dispersion.html"><a href="dispersion.html#standard-error"><i class="fa fa-check"></i><b>7.5</b> Standard error</a><ul>
<li class="chapter" data-level="7.5.1" data-path="dispersion.html"><a href="dispersion.html#what-exactly-does-the-standard-error-represent"><i class="fa fa-check"></i><b>7.5.1</b> What exactly does the standard error represent?</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="dispersion.html"><a href="dispersion.html#confidence-intervals"><i class="fa fa-check"></i><b>7.6</b> Confidence intervals</a><ul>
<li class="chapter" data-level="7.6.1" data-path="dispersion.html"><a href="dispersion.html#simulations"><i class="fa fa-check"></i><b>7.6.1</b> Simulations</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="dispersion.html"><a href="dispersion.html#key-take-aways"><i class="fa fa-check"></i><b>7.7</b> Key take aways</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="hypotheses.html"><a href="hypotheses.html"><i class="fa fa-check"></i><b>8</b> Framing statistical hypotheses</a><ul>
<li class="chapter" data-level="8.1" data-path="hypotheses.html"><a href="hypotheses.html#the-decision-process"><i class="fa fa-check"></i><b>8.1</b> The decision process</a></li>
<li class="chapter" data-level="8.2" data-path="hypotheses.html"><a href="hypotheses.html#popper-and-falsification"><i class="fa fa-check"></i><b>8.2</b> Popper and falsification</a></li>
<li class="chapter" data-level="8.3" data-path="hypotheses.html"><a href="hypotheses.html#statistical-hypothesis-rubric"><i class="fa fa-check"></i><b>8.3</b> Statistical hypothesis rubric</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="error.html"><a href="error.html"><i class="fa fa-check"></i><b>9</b> Error</a><ul>
<li class="chapter" data-level="9.1" data-path="error.html"><a href="error.html#setting-type-1-and-type-2-error-thresholds"><i class="fa fa-check"></i><b>9.1</b> Setting type 1 and type 2 error thresholds</a><ul>
<li class="chapter" data-level="9.1.1" data-path="error.html"><a href="error.html#setting-alpha-the-type-1-error"><i class="fa fa-check"></i><b>9.1.1</b> Setting alpha-the type 1 error</a></li>
<li class="chapter" data-level="9.1.2" data-path="error.html"><a href="error.html#power-setting-beta-the-type-2-error"><i class="fa fa-check"></i><b>9.1.2</b> Power: Setting beta-the type 2 error</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="error.html"><a href="error.html#striking-the-right-balance"><i class="fa fa-check"></i><b>9.2</b> Striking the right balance</a></li>
<li class="chapter" data-level="9.3" data-path="error.html"><a href="error.html#false-discovery-rate"><i class="fa fa-check"></i><b>9.3</b> False discovery rate</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="pvalues.html"><a href="pvalues.html"><i class="fa fa-check"></i><b>10</b> P Values</a><ul>
<li class="chapter" data-level="10.1" data-path="pvalues.html"><a href="pvalues.html#how-p-values-are-calculated"><i class="fa fa-check"></i><b>10.1</b> How p-values are calculated</a></li>
<li class="chapter" data-level="10.2" data-path="pvalues.html"><a href="pvalues.html#how-p-values-should-be-interpreted"><i class="fa fa-check"></i><b>10.2</b> How p-values should be interpreted</a></li>
<li class="chapter" data-level="10.3" data-path="pvalues.html"><a href="pvalues.html#interpretation"><i class="fa fa-check"></i><b>10.3</b> Interpretation</a></li>
<li class="chapter" data-level="10.4" data-path="pvalues.html"><a href="pvalues.html#criticisms-of-p-values"><i class="fa fa-check"></i><b>10.4</b> Criticisms of p-values</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="jaxwest7.html"><a href="jaxwest7.html"><i class="fa fa-check"></i><b>11</b> Reproducible Data Munging in R</a><ul>
<li class="chapter" data-level="11.1" data-path="jaxwest7.html"><a href="jaxwest7.html#jaxwest7-glucose-data"><i class="fa fa-check"></i><b>11.1</b> Jaxwest7 glucose data</a><ul>
<li class="chapter" data-level="11.1.1" data-path="jaxwest7.html"><a href="jaxwest7.html#inspect-the-jaxwest7-data"><i class="fa fa-check"></i><b>11.1.1</b> Inspect the Jaxwest7 data</a></li>
<li class="chapter" data-level="11.1.2" data-path="jaxwest7.html"><a href="jaxwest7.html#munge-the-glucose-concentration-data-into-r"><i class="fa fa-check"></i><b>11.1.2</b> Munge the glucose concentration data into R</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="jaxwest7.html"><a href="jaxwest7.html#explore-the-jaxwest7-data"><i class="fa fa-check"></i><b>11.2</b> Explore the Jaxwest7 data</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="binomial.html"><a href="binomial.html"><i class="fa fa-check"></i><b>12</b> The Binomial Distribution</a><ul>
<li class="chapter" data-level="12.1" data-path="binomial.html"><a href="binomial.html#dbinom"><i class="fa fa-check"></i><b>12.1</b> dbinom</a></li>
<li class="chapter" data-level="12.2" data-path="binomial.html"><a href="binomial.html#pbinom"><i class="fa fa-check"></i><b>12.2</b> pbinom</a></li>
<li class="chapter" data-level="12.3" data-path="binomial.html"><a href="binomial.html#qbinom"><i class="fa fa-check"></i><b>12.3</b> qbinom</a></li>
<li class="chapter" data-level="12.4" data-path="binomial.html"><a href="binomial.html#rbinom"><i class="fa fa-check"></i><b>12.4</b> rbinom</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="poisson.html"><a href="poisson.html"><i class="fa fa-check"></i><b>13</b> The Poisson Distribution</a><ul>
<li class="chapter" data-level="13.1" data-path="poisson.html"><a href="poisson.html#poisson-events"><i class="fa fa-check"></i><b>13.1</b> Poisson Events</a></li>
<li class="chapter" data-level="13.2" data-path="poisson.html"><a href="poisson.html#dpois"><i class="fa fa-check"></i><b>13.2</b> dpois</a></li>
<li class="chapter" data-level="13.3" data-path="poisson.html"><a href="poisson.html#ppois"><i class="fa fa-check"></i><b>13.3</b> ppois</a></li>
<li class="chapter" data-level="13.4" data-path="poisson.html"><a href="poisson.html#rpois"><i class="fa fa-check"></i><b>13.4</b> rpois</a></li>
<li class="chapter" data-level="13.5" data-path="poisson.html"><a href="poisson.html#overdispersion"><i class="fa fa-check"></i><b>13.5</b> Overdispersion</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="normal.html"><a href="normal.html"><i class="fa fa-check"></i><b>14</b> The Normal Distribution</a><ul>
<li class="chapter" data-level="14.0.1" data-path="normal.html"><a href="normal.html#the-standard-normal"><i class="fa fa-check"></i><b>14.0.1</b> The Standard Normal</a></li>
<li class="chapter" data-level="14.1" data-path="normal.html"><a href="normal.html#dnorm"><i class="fa fa-check"></i><b>14.1</b> dnorm</a></li>
<li class="chapter" data-level="14.2" data-path="normal.html"><a href="normal.html#pnorm"><i class="fa fa-check"></i><b>14.2</b> pnorm</a><ul>
<li class="chapter" data-level="" data-path="normal.html"><a href="normal.html#calculating-p-values-using-pnorm"><i class="fa fa-check"></i>Calculating “p-values”&quot; using pnorm</a></li>
<li class="chapter" data-level="" data-path="normal.html"><a href="normal.html#calculating-percentiles-using-pnorm"><i class="fa fa-check"></i>Calculating percentiles using pnorm</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="normal.html"><a href="normal.html#qnorm"><i class="fa fa-check"></i><b>14.3</b> qnorm</a></li>
<li class="chapter" data-level="14.4" data-path="normal.html"><a href="normal.html#rnorm"><i class="fa fa-check"></i><b>14.4</b> rnorm</a><ul>
<li class="chapter" data-level="14.4.1" data-path="normal.html"><a href="normal.html#plotting-histograms-of-some-rnorm-samples"><i class="fa fa-check"></i><b>14.4.1</b> Plotting histograms of some rnorm samples</a></li>
<li class="chapter" data-level="14.4.2" data-path="normal.html"><a href="normal.html#bins-and-binwidth"><i class="fa fa-check"></i><b>14.4.2</b> Bins and Binwidth</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="categorical.html"><a href="categorical.html"><i class="fa fa-check"></i><b>15</b> Statistics for Categorical Data</a><ul>
<li class="chapter" data-level="15.1" data-path="categorical.html"><a href="categorical.html#types-of-categorical-data"><i class="fa fa-check"></i><b>15.1</b> Types of categorical data</a><ul>
<li class="chapter" data-level="15.1.1" data-path="categorical.html"><a href="categorical.html#proportions"><i class="fa fa-check"></i><b>15.1.1</b> Proportions</a></li>
<li class="chapter" data-level="15.1.2" data-path="categorical.html"><a href="categorical.html#frequencies"><i class="fa fa-check"></i><b>15.1.2</b> Frequencies</a></li>
<li class="chapter" data-level="15.1.3" data-path="categorical.html"><a href="categorical.html#associations"><i class="fa fa-check"></i><b>15.1.3</b> Associations</a></li>
<li class="chapter" data-level="15.1.4" data-path="categorical.html"><a href="categorical.html#statistics-covered-here"><i class="fa fa-check"></i><b>15.1.4</b> Statistics Covered Here</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="categorical.html"><a href="categorical.html#exact-v-asymptotic-calculations-of-p-values"><i class="fa fa-check"></i><b>15.2</b> Exact v Asymptotic Calculations of p-values</a><ul>
<li class="chapter" data-level="15.2.1" data-path="categorical.html"><a href="categorical.html#choosing-exact-or-asymptotic"><i class="fa fa-check"></i><b>15.2.1</b> Choosing exact or asymptotic</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="categorical.html"><a href="categorical.html#overview-of-the-types-of-hypothesis-testing"><i class="fa fa-check"></i><b>15.3</b> Overview of the types of hypothesis testing</a><ul>
<li class="chapter" data-level="15.3.1" data-path="categorical.html"><a href="categorical.html#proportion-analysis"><i class="fa fa-check"></i><b>15.3.1</b> Proportion analysis</a></li>
<li class="chapter" data-level="15.3.2" data-path="categorical.html"><a href="categorical.html#goodness-of-fit-testing"><i class="fa fa-check"></i><b>15.3.2</b> Goodness of fit testing</a></li>
<li class="chapter" data-level="15.3.3" data-path="categorical.html"><a href="categorical.html#contingency-analysis"><i class="fa fa-check"></i><b>15.3.3</b> Contingency Analysis</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="categorical.html"><a href="categorical.html#comparing-proportions"><i class="fa fa-check"></i><b>15.4</b> Comparing proportions</a><ul>
<li class="chapter" data-level="15.4.1" data-path="categorical.html"><a href="categorical.html#a-mouse-t-cell-pilot-experiment-the-cytokine-inducible-antigen-gradstudin"><i class="fa fa-check"></i><b>15.4.1</b> A Mouse T Cell Pilot Experiment: The Cytokine-inducible antigen gradstudin</a></li>
<li class="chapter" data-level="15.4.2" data-path="categorical.html"><a href="categorical.html#calculating-proportions"><i class="fa fa-check"></i><b>15.4.2</b> Calculating Proportions</a></li>
<li class="chapter" data-level="15.4.3" data-path="categorical.html"><a href="categorical.html#what-a-proportion-estimates"><i class="fa fa-check"></i><b>15.4.3</b> What A Proportion Estimates</a></li>
<li class="chapter" data-level="15.4.4" data-path="categorical.html"><a href="categorical.html#confidence-intervals-of-proportions"><i class="fa fa-check"></i><b>15.4.4</b> Confidence Intervals of Proportions</a></li>
<li class="chapter" data-level="15.4.5" data-path="categorical.html"><a href="categorical.html#a-one-sample-proportion-test"><i class="fa fa-check"></i><b>15.4.5</b> A One-Sample Proportion Test</a></li>
<li class="chapter" data-level="15.4.6" data-path="categorical.html"><a href="categorical.html#comparing-two-proportions"><i class="fa fa-check"></i><b>15.4.6</b> Comparing Two Proportions</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="categorical.html"><a href="categorical.html#exact-tests-for-two-proportions"><i class="fa fa-check"></i><b>15.5</b> Exact tests for two proportions</a></li>
<li class="chapter" data-level="15.6" data-path="categorical.html"><a href="categorical.html#goodness-of-fit-tests"><i class="fa fa-check"></i><b>15.6</b> Goodness of fit Tests</a><ul>
<li class="chapter" data-level="15.6.1" data-path="categorical.html"><a href="categorical.html#an-exact-goodness-of-fit-test"><i class="fa fa-check"></i><b>15.6.1</b> An Exact Goodness of Fit test</a></li>
<li class="chapter" data-level="15.6.2" data-path="categorical.html"><a href="categorical.html#an-approximate-goodness-of-fit-test"><i class="fa fa-check"></i><b>15.6.2</b> An Approximate Goodness of Fit test</a></li>
</ul></li>
<li class="chapter" data-level="15.7" data-path="categorical.html"><a href="categorical.html#contingency-testing"><i class="fa fa-check"></i><b>15.7</b> Contingency Testing</a><ul>
<li class="chapter" data-level="15.7.1" data-path="categorical.html"><a href="categorical.html#intepretation-of-contingency-results"><i class="fa fa-check"></i><b>15.7.1</b> Intepretation of Contingency Results</a></li>
<li class="chapter" data-level="15.7.2" data-path="categorical.html"><a href="categorical.html#write-up-3"><i class="fa fa-check"></i><b>15.7.2</b> Write Up</a></li>
<li class="chapter" data-level="15.7.3" data-path="categorical.html"><a href="categorical.html#interpretation-of-chi-square-output"><i class="fa fa-check"></i><b>15.7.3</b> Interpretation of chi-square output</a></li>
<li class="chapter" data-level="15.7.4" data-path="categorical.html"><a href="categorical.html#write-up-4"><i class="fa fa-check"></i><b>15.7.4</b> Write Up</a></li>
<li class="chapter" data-level="15.7.5" data-path="categorical.html"><a href="categorical.html#which-contingency-test-is-best"><i class="fa fa-check"></i><b>15.7.5</b> Which contingency test is best?</a></li>
<li class="chapter" data-level="15.7.6" data-path="categorical.html"><a href="categorical.html#higher-dimension-contingency-analysis"><i class="fa fa-check"></i><b>15.7.6</b> Higher dimension contingency analysis</a></li>
<li class="chapter" data-level="15.7.7" data-path="categorical.html"><a href="categorical.html#other-experimental-designs-involving-categorical-data"><i class="fa fa-check"></i><b>15.7.7</b> Other experimental designs involving categorical data</a></li>
</ul></li>
<li class="chapter" data-level="15.8" data-path="categorical.html"><a href="categorical.html#doing-a-priori-power-analysis-for-proportion-tests"><i class="fa fa-check"></i><b>15.8</b> Doing <em>a priori</em> power analysis for proportion tests</a></li>
<li class="chapter" data-level="15.9" data-path="categorical.html"><a href="categorical.html#power-analysis-functions-for-proportion-tests"><i class="fa fa-check"></i><b>15.9</b> Power analysis functions for proportion tests</a></li>
<li class="chapter" data-level="15.10" data-path="categorical.html"><a href="categorical.html#graphing-proportions"><i class="fa fa-check"></i><b>15.10</b> Graphing Proportions</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="chisquare.html"><a href="chisquare.html"><i class="fa fa-check"></i><b>16</b> The Chi-square Distribution</a><ul>
<li class="chapter" data-level="16.1" data-path="chisquare.html"><a href="chisquare.html#background"><i class="fa fa-check"></i><b>16.1</b> Background</a></li>
<li class="chapter" data-level="16.2" data-path="chisquare.html"><a href="chisquare.html#dchisq"><i class="fa fa-check"></i><b>16.2</b> dchisq</a></li>
<li class="chapter" data-level="16.3" data-path="chisquare.html"><a href="chisquare.html#pchisq"><i class="fa fa-check"></i><b>16.3</b> pchisq</a><ul>
<li class="chapter" data-level="16.3.1" data-path="chisquare.html"><a href="chisquare.html#calculating-p-values-from-pchisq"><i class="fa fa-check"></i><b>16.3.1</b> Calculating p-values from pchisq</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="chisquare.html"><a href="chisquare.html#qchisq"><i class="fa fa-check"></i><b>16.4</b> qchisq</a></li>
<li class="chapter" data-level="16.5" data-path="chisquare.html"><a href="chisquare.html#rchisq"><i class="fa fa-check"></i><b>16.5</b> rchisq</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="nonparametrics.html"><a href="nonparametrics.html"><i class="fa fa-check"></i><b>17</b> Nonparametric Statistical Tests</a><ul>
<li class="chapter" data-level="17.1" data-path="nonparametrics.html"><a href="nonparametrics.html#experiments-involving-discrete-data"><i class="fa fa-check"></i><b>17.1</b> Experiments involving discrete data</a></li>
<li class="chapter" data-level="17.2" data-path="nonparametrics.html"><a href="nonparametrics.html#deviant-data"><i class="fa fa-check"></i><b>17.2</b> Deviant Data</a></li>
<li class="chapter" data-level="17.3" data-path="nonparametrics.html"><a href="nonparametrics.html#sign-test"><i class="fa fa-check"></i><b>17.3</b> Sign Test</a><ul>
<li class="chapter" data-level="17.3.1" data-path="nonparametrics.html"><a href="nonparametrics.html#interpretation-1"><i class="fa fa-check"></i><b>17.3.1</b> Interpretation</a></li>
<li class="chapter" data-level="17.3.2" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-5"><i class="fa fa-check"></i><b>17.3.2</b> Write Up</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="nonparametrics.html"><a href="nonparametrics.html#wilcoxon-sign-rank-test-for-one-group"><i class="fa fa-check"></i><b>17.4</b> Wilcoxon Sign Rank Test for One Group</a><ul>
<li class="chapter" data-level="17.4.1" data-path="nonparametrics.html"><a href="nonparametrics.html#wilcoxon-sign-rank-experimental-designs"><i class="fa fa-check"></i><b>17.4.1</b> Wilcoxon Sign Rank Experimental Designs</a></li>
<li class="chapter" data-level="17.4.2" data-path="nonparametrics.html"><a href="nonparametrics.html#interpretation-2"><i class="fa fa-check"></i><b>17.4.2</b> Interpretation</a></li>
<li class="chapter" data-level="17.4.3" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-6"><i class="fa fa-check"></i><b>17.4.3</b> Write Up</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="nonparametrics.html"><a href="nonparametrics.html#wilcoxon-mann-whitney-rank-sum-test-for-2-independent-groups"><i class="fa fa-check"></i><b>17.5</b> Wilcoxon Mann Whitney Rank Sum Test for 2 independent groups</a><ul>
<li class="chapter" data-level="17.5.1" data-path="nonparametrics.html"><a href="nonparametrics.html#interpretation-3"><i class="fa fa-check"></i><b>17.5.1</b> Interpretation</a></li>
<li class="chapter" data-level="17.5.2" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-7"><i class="fa fa-check"></i><b>17.5.2</b> Write Up</a></li>
</ul></li>
<li class="chapter" data-level="17.6" data-path="nonparametrics.html"><a href="nonparametrics.html#wilcoxon-sign-rank-test-for-paired-groups"><i class="fa fa-check"></i><b>17.6</b> Wilcoxon Sign Rank Test for paired groups</a><ul>
<li class="chapter" data-level="17.6.1" data-path="nonparametrics.html"><a href="nonparametrics.html#interpretation-4"><i class="fa fa-check"></i><b>17.6.1</b> Interpretation</a></li>
<li class="chapter" data-level="17.6.2" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-8"><i class="fa fa-check"></i><b>17.6.2</b> Write up</a></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="nonparametrics.html"><a href="nonparametrics.html#kruskal-wallis"><i class="fa fa-check"></i><b>17.7</b> Kruskal-Wallis</a><ul>
<li class="chapter" data-level="17.7.1" data-path="nonparametrics.html"><a href="nonparametrics.html#write-up-9"><i class="fa fa-check"></i><b>17.7.1</b> Write Up</a></li>
</ul></li>
<li class="chapter" data-level="17.8" data-path="nonparametrics.html"><a href="nonparametrics.html#friedman-test"><i class="fa fa-check"></i><b>17.8</b> Friedman test</a></li>
<li class="chapter" data-level="17.9" data-path="nonparametrics.html"><a href="nonparametrics.html#nonparametric-power-calculations"><i class="fa fa-check"></i><b>17.9</b> Nonparametric power calculations</a><ul>
<li class="chapter" data-level="17.9.1" data-path="nonparametrics.html"><a href="nonparametrics.html#how-it-works"><i class="fa fa-check"></i><b>17.9.1</b> How it works</a></li>
<li class="chapter" data-level="17.9.2" data-path="nonparametrics.html"><a href="nonparametrics.html#initialization-with-population-parameters"><i class="fa fa-check"></i><b>17.9.2</b> Initialization with population parameters</a></li>
<li class="chapter" data-level="17.9.3" data-path="nonparametrics.html"><a href="nonparametrics.html#an-example"><i class="fa fa-check"></i><b>17.9.3</b> An example</a></li>
<li class="chapter" data-level="17.9.4" data-path="nonparametrics.html"><a href="nonparametrics.html#nonpara.pwr"><i class="fa fa-check"></i><b>17.9.4</b> nonpara.pwr</a></li>
</ul></li>
<li class="chapter" data-level="17.10" data-path="nonparametrics.html"><a href="nonparametrics.html#summary"><i class="fa fa-check"></i><b>17.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="signrank.html"><a href="signrank.html"><i class="fa fa-check"></i><b>18</b> Signed Rank Distribution</a><ul>
<li class="chapter" data-level="18.1" data-path="signrank.html"><a href="signrank.html#transformation-of-data-into-sign-ranks"><i class="fa fa-check"></i><b>18.1</b> Transformation of data into sign ranks</a><ul>
<li class="chapter" data-level="18.1.1" data-path="signrank.html"><a href="signrank.html#for-a-one-group-sample"><i class="fa fa-check"></i><b>18.1.1</b> For a one group sample</a></li>
<li class="chapter" data-level="18.1.2" data-path="signrank.html"><a href="signrank.html#for-a-paired-sample"><i class="fa fa-check"></i><b>18.1.2</b> For a paired sample</a></li>
<li class="chapter" data-level="18.1.3" data-path="signrank.html"><a href="signrank.html#the-sign-rank-test-statistic-in-r"><i class="fa fa-check"></i><b>18.1.3</b> The sign rank test statistic in R</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="signrank.html"><a href="signrank.html#rs-four-sign-rank-distribution-functions"><i class="fa fa-check"></i><b>18.2</b> R’s Four Sign Rank Distribution Functions</a><ul>
<li class="chapter" data-level="18.2.1" data-path="signrank.html"><a href="signrank.html#dsignrank"><i class="fa fa-check"></i><b>18.2.1</b> dsignrank</a></li>
<li class="chapter" data-level="18.2.2" data-path="signrank.html"><a href="signrank.html#psignrank"><i class="fa fa-check"></i><b>18.2.2</b> psignrank</a></li>
<li class="chapter" data-level="18.2.3" data-path="signrank.html"><a href="signrank.html#qsignrank"><i class="fa fa-check"></i><b>18.2.3</b> qsignrank</a></li>
<li class="chapter" data-level="18.2.4" data-path="signrank.html"><a href="signrank.html#rsignrank"><i class="fa fa-check"></i><b>18.2.4</b> rsignrank</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="ranksum.html"><a href="ranksum.html"><i class="fa fa-check"></i><b>19</b> Rank Sum Distribution</a><ul>
<li class="chapter" data-level="19.0.1" data-path="ranksum.html"><a href="ranksum.html#transformation-of-data-into-rank-summs"><i class="fa fa-check"></i><b>19.0.1</b> Transformation of data into rank summs</a></li>
<li class="chapter" data-level="19.0.2" data-path="ranksum.html"><a href="ranksum.html#the-sign-rank-test-statistic-in-r-1"><i class="fa fa-check"></i><b>19.0.2</b> The sign rank test statistic in R</a></li>
<li class="chapter" data-level="19.1" data-path="ranksum.html"><a href="ranksum.html#rs-four-sign-rank-distribution-functions-1"><i class="fa fa-check"></i><b>19.1</b> R’s Four Sign Rank Distribution Functions</a><ul>
<li class="chapter" data-level="19.1.1" data-path="ranksum.html"><a href="ranksum.html#dwilcox"><i class="fa fa-check"></i><b>19.1.1</b> dwilcox</a></li>
<li class="chapter" data-level="19.1.2" data-path="ranksum.html"><a href="ranksum.html#pwilcox"><i class="fa fa-check"></i><b>19.1.2</b> pwilcox</a></li>
<li class="chapter" data-level="19.1.3" data-path="ranksum.html"><a href="ranksum.html#qwilcox"><i class="fa fa-check"></i><b>19.1.3</b> qwilcox</a></li>
<li class="chapter" data-level="19.1.4" data-path="ranksum.html"><a href="ranksum.html#rwilcox"><i class="fa fa-check"></i><b>19.1.4</b> rwilcox</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="ttests.html"><a href="ttests.html"><i class="fa fa-check"></i><b>20</b> The t-tests</a><ul>
<li class="chapter" data-level="20.1" data-path="ttests.html"><a href="ttests.html#data-assumptions-for-t-tests"><i class="fa fa-check"></i><b>20.1</b> Data assumptions for t-tests</a></li>
<li class="chapter" data-level="20.2" data-path="ttests.html"><a href="ttests.html#the-t-statistic"><i class="fa fa-check"></i><b>20.2</b> The t Statistic</a><ul>
<li class="chapter" data-level="20.2.1" data-path="ttests.html"><a href="ttests.html#one-sample-t-tests"><i class="fa fa-check"></i><b>20.2.1</b> One sample t tests</a></li>
<li class="chapter" data-level="20.2.2" data-path="ttests.html"><a href="ttests.html#unpaired-t-tests"><i class="fa fa-check"></i><b>20.2.2</b> Unpaired t tests</a></li>
<li class="chapter" data-level="20.2.3" data-path="ttests.html"><a href="ttests.html#paired-t-tests"><i class="fa fa-check"></i><b>20.2.3</b> Paired t tests</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="ttests.html"><a href="ttests.html#t-test-hypotheses"><i class="fa fa-check"></i><b>20.3</b> t Test Hypotheses</a><ul>
<li class="chapter" data-level="20.3.1" data-path="ttests.html"><a href="ttests.html#one-sample-hypotheses"><i class="fa fa-check"></i><b>20.3.1</b> One sample hypotheses</a></li>
<li class="chapter" data-level="20.3.2" data-path="ttests.html"><a href="ttests.html#unpaired-hypotheses"><i class="fa fa-check"></i><b>20.3.2</b> Unpaired hypotheses</a></li>
<li class="chapter" data-level="20.3.3" data-path="ttests.html"><a href="ttests.html#paired-hypotheses"><i class="fa fa-check"></i><b>20.3.3</b> Paired hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="ttests.html"><a href="ttests.html#confidence-intervals-of-means"><i class="fa fa-check"></i><b>20.4</b> Confidence Intervals of Means</a></li>
<li class="chapter" data-level="20.5" data-path="ttests.html"><a href="ttests.html#t-tests-running-the-analysis"><i class="fa fa-check"></i><b>20.5</b> t Tests: Running the analysis</a><ul>
<li class="chapter" data-level="20.5.1" data-path="ttests.html"><a href="ttests.html#one-sample-t-test"><i class="fa fa-check"></i><b>20.5.1</b> One sample t test</a></li>
<li class="chapter" data-level="20.5.2" data-path="ttests.html"><a href="ttests.html#unpaired-t-test"><i class="fa fa-check"></i><b>20.5.2</b> Unpaired t test</a></li>
<li class="chapter" data-level="20.5.3" data-path="ttests.html"><a href="ttests.html#paired-t-test"><i class="fa fa-check"></i><b>20.5.3</b> Paired t Test</a></li>
</ul></li>
<li class="chapter" data-level="20.6" data-path="ttests.html"><a href="ttests.html#plotting-t-tests"><i class="fa fa-check"></i><b>20.6</b> Plotting t Tests</a><ul>
<li class="chapter" data-level="20.6.1" data-path="ttests.html"><a href="ttests.html#unpaired"><i class="fa fa-check"></i><b>20.6.1</b> Unpaired</a></li>
<li class="chapter" data-level="20.6.2" data-path="ttests.html"><a href="ttests.html#paired"><i class="fa fa-check"></i><b>20.6.2</b> Paired</a></li>
</ul></li>
<li class="chapter" data-level="20.7" data-path="ttests.html"><a href="ttests.html#t-test-power"><i class="fa fa-check"></i><b>20.7</b> t Test Power</a><ul>
<li class="chapter" data-level="20.7.1" data-path="ttests.html"><a href="ttests.html#interpretation-7"><i class="fa fa-check"></i><b>20.7.1</b> Interpretation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="ttestmc.html"><a href="ttestmc.html"><i class="fa fa-check"></i><b>21</b> Statistical design of t-tests</a><ul>
<li class="chapter" data-level="21.1" data-path="ttestmc.html"><a href="ttestmc.html#about-this-chapter"><i class="fa fa-check"></i><b>21.1</b> About this chapter</a><ul>
<li class="chapter" data-level="21.1.1" data-path="ttestmc.html"><a href="ttestmc.html#scenario"><i class="fa fa-check"></i><b>21.1.1</b> Scenario</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="ttestmc.html"><a href="ttestmc.html#one-sample-t-test-monte-carlo"><i class="fa fa-check"></i><b>21.2</b> One sample t-test Monte Carlo</a></li>
<li class="chapter" data-level="21.3" data-path="ttestmc.html"><a href="ttestmc.html#unpaired-t-test-monte-carlo"><i class="fa fa-check"></i><b>21.3</b> Unpaired t-test Monte Carlo</a></li>
<li class="chapter" data-level="21.4" data-path="ttestmc.html"><a href="ttestmc.html#paired-t-test-monte-carlo"><i class="fa fa-check"></i><b>21.4</b> Paired t-test Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="tdist.html"><a href="tdist.html"><i class="fa fa-check"></i><b>22</b> t Distributions</a><ul>
<li class="chapter" data-level="22.1" data-path="tdist.html"><a href="tdist.html#dt"><i class="fa fa-check"></i><b>22.1</b> dt</a></li>
<li class="chapter" data-level="22.2" data-path="tdist.html"><a href="tdist.html#pt"><i class="fa fa-check"></i><b>22.2</b> pt</a></li>
<li class="chapter" data-level="22.3" data-path="tdist.html"><a href="tdist.html#qt"><i class="fa fa-check"></i><b>22.3</b> qt</a></li>
<li class="chapter" data-level="22.4" data-path="tdist.html"><a href="tdist.html#rt"><i class="fa fa-check"></i><b>22.4</b> rt</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="simcorrelation.html"><a href="simcorrelation.html"><i class="fa fa-check"></i><b>23</b> Simulating correlated variables</a><ul>
<li class="chapter" data-level="23.1" data-path="simcorrelation.html"><a href="simcorrelation.html#estimating-correlation-between-two-variables"><i class="fa fa-check"></i><b>23.1</b> Estimating correlation between two variables</a></li>
<li class="chapter" data-level="23.2" data-path="simcorrelation.html"><a href="simcorrelation.html#simulating-correlated-variables"><i class="fa fa-check"></i><b>23.2</b> Simulating correlated variables</a></li>
<li class="chapter" data-level="23.3" data-path="simcorrelation.html"><a href="simcorrelation.html#monte-carlo-simulation"><i class="fa fa-check"></i><b>23.3</b> Monte Carlo simulation</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="introanova.html"><a href="introanova.html"><i class="fa fa-check"></i><b>24</b> Introduction to ANOVA</a><ul>
<li class="chapter" data-level="24.1" data-path="introanova.html"><a href="introanova.html#factors-and-levels"><i class="fa fa-check"></i><b>24.1</b> Factors and levels</a></li>
<li class="chapter" data-level="24.2" data-path="introanova.html"><a href="introanova.html#anova-models-one--two--and-three-way"><i class="fa fa-check"></i><b>24.2</b> ANOVA models: One-, Two-, and Three-way</a></li>
<li class="chapter" data-level="24.3" data-path="introanova.html"><a href="introanova.html#anova-inference-protocol"><i class="fa fa-check"></i><b>24.3</b> ANOVA inference protocol</a></li>
<li class="chapter" data-level="24.4" data-path="introanova.html"><a href="introanova.html#anova-calculations"><i class="fa fa-check"></i><b>24.4</b> ANOVA calculations</a><ul>
<li class="chapter" data-level="24.4.1" data-path="introanova.html"><a href="introanova.html#sums-of-squares-partitioning"><i class="fa fa-check"></i><b>24.4.1</b> Sums of Squares partitioning</a></li>
<li class="chapter" data-level="24.4.2" data-path="introanova.html"><a href="introanova.html#degrees-of-freedom"><i class="fa fa-check"></i><b>24.4.2</b> Degrees of freedom</a></li>
<li class="chapter" data-level="24.4.3" data-path="introanova.html"><a href="introanova.html#the-mean-squares"><i class="fa fa-check"></i><b>24.4.3</b> The mean squares</a></li>
<li class="chapter" data-level="24.4.4" data-path="introanova.html"><a href="introanova.html#the-anova-table"><i class="fa fa-check"></i><b>24.4.4</b> The ANOVA table</a></li>
<li class="chapter" data-level="24.4.5" data-path="introanova.html"><a href="introanova.html#the-f-test"><i class="fa fa-check"></i><b>24.4.5</b> The F-test</a></li>
<li class="chapter" data-level="24.4.6" data-path="introanova.html"><a href="introanova.html#post-hoc-group-comparisons"><i class="fa fa-check"></i><b>24.4.6</b> Post-hoc group comparisons</a></li>
</ul></li>
<li class="chapter" data-level="24.5" data-path="introanova.html"><a href="introanova.html#completely-randomized-or-related-measures"><i class="fa fa-check"></i><b>24.5</b> Completely randomized or related measures</a><ul>
<li class="chapter" data-level="24.5.1" data-path="introanova.html"><a href="introanova.html#the-problem-of-lost-data-in-related-measures-designs"><i class="fa fa-check"></i><b>24.5.1</b> The problem of lost data in related measures designs</a></li>
</ul></li>
<li class="chapter" data-level="24.6" data-path="introanova.html"><a href="introanova.html#two-way-anova"><i class="fa fa-check"></i><b>24.6</b> Two-way ANOVA</a></li>
<li class="chapter" data-level="24.7" data-path="introanova.html"><a href="introanova.html#other-anova-models"><i class="fa fa-check"></i><b>24.7</b> Other ANOVA models</a><ul>
<li class="chapter" data-level="24.7.1" data-path="introanova.html"><a href="introanova.html#r-and-anova"><i class="fa fa-check"></i><b>24.7.1</b> R and ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="24.8" data-path="introanova.html"><a href="introanova.html#alternatives-to-anova"><i class="fa fa-check"></i><b>24.8</b> Alternatives to ANOVA</a><ul>
<li class="chapter" data-level="24.8.1" data-path="introanova.html"><a href="introanova.html#screw-anova-just-tell-me-how-to-t-test-everything"><i class="fa fa-check"></i><b>24.8.1</b> Screw ANOVA, Just Tell Me How to t-Test Everything</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="fdistr.html"><a href="fdistr.html"><i class="fa fa-check"></i><b>25</b> The F distribution</a><ul>
<li class="chapter" data-level="25.1" data-path="fdistr.html"><a href="fdistr.html#background-1"><i class="fa fa-check"></i><b>25.1</b> Background</a><ul>
<li class="chapter" data-level="25.1.1" data-path="fdistr.html"><a href="fdistr.html#sample-variance-and-fs-pdf"><i class="fa fa-check"></i><b>25.1.1</b> Sample Variance and F’s PDF</a></li>
</ul></li>
<li class="chapter" data-level="25.2" data-path="fdistr.html"><a href="fdistr.html#df"><i class="fa fa-check"></i><b>25.2</b> df</a></li>
<li class="chapter" data-level="25.3" data-path="fdistr.html"><a href="fdistr.html#pf"><i class="fa fa-check"></i><b>25.3</b> pf</a></li>
<li class="chapter" data-level="25.4" data-path="fdistr.html"><a href="fdistr.html#qf"><i class="fa fa-check"></i><b>25.4</b> qf</a></li>
<li class="chapter" data-level="25.5" data-path="fdistr.html"><a href="fdistr.html#rf"><i class="fa fa-check"></i><b>25.5</b> rf</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="onewayanova.html"><a href="onewayanova.html"><i class="fa fa-check"></i><b>26</b> One-way ANOVA Completely Randomized</a><ul>
<li class="chapter" data-level="26.1" data-path="onewayanova.html"><a href="onewayanova.html#using-ezanova"><i class="fa fa-check"></i><b>26.1</b> Using <code>ezANOVA</code></a></li>
<li class="chapter" data-level="26.2" data-path="onewayanova.html"><a href="onewayanova.html#the-chickwt-data-set"><i class="fa fa-check"></i><b>26.2</b> The chickwt data set</a><ul>
<li class="chapter" data-level="26.2.1" data-path="onewayanova.html"><a href="onewayanova.html#inspect-the-data"><i class="fa fa-check"></i><b>26.2.1</b> Inspect the data</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="onewayanova.html"><a href="onewayanova.html#run-the-anova"><i class="fa fa-check"></i><b>26.3</b> Run the ANOVA</a><ul>
<li class="chapter" data-level="26.3.1" data-path="onewayanova.html"><a href="onewayanova.html#run-the-chickwts-one-way-anova"><i class="fa fa-check"></i><b>26.3.1</b> Run the chickwts One Way ANOVA</a></li>
<li class="chapter" data-level="26.3.2" data-path="onewayanova.html"><a href="onewayanova.html#interpreting-the-one-way-cr-anova-output"><i class="fa fa-check"></i><b>26.3.2</b> Interpreting the One-Way CR ANOVA Output</a></li>
</ul></li>
<li class="chapter" data-level="26.4" data-path="onewayanova.html"><a href="onewayanova.html#posthoc"><i class="fa fa-check"></i><b>26.4</b> Post hoc pairwise comparisons</a><ul>
<li class="chapter" data-level="26.4.1" data-path="onewayanova.html"><a href="onewayanova.html#overview-of-options"><i class="fa fa-check"></i><b>26.4.1</b> Overview of options</a></li>
</ul></li>
<li class="chapter" data-level="26.5" data-path="onewayanova.html"><a href="onewayanova.html#reporting-the-result"><i class="fa fa-check"></i><b>26.5</b> Reporting the result</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="onewayRM.html"><a href="onewayRM.html"><i class="fa fa-check"></i><b>27</b> One-way ANOVA Related Measures</a><ul>
<li class="chapter" data-level="27.1" data-path="onewayRM.html"><a href="onewayRM.html#data-prep"><i class="fa fa-check"></i><b>27.1</b> Data prep</a></li>
<li class="chapter" data-level="27.2" data-path="onewayRM.html"><a href="onewayRM.html#run-the-anova-1"><i class="fa fa-check"></i><b>27.2</b> Run the ANOVA</a></li>
<li class="chapter" data-level="27.3" data-path="onewayRM.html"><a href="onewayRM.html#interpretation-8"><i class="fa fa-check"></i><b>27.3</b> Interpretation</a></li>
<li class="chapter" data-level="27.4" data-path="onewayRM.html"><a href="onewayRM.html#post-hoc-analysis"><i class="fa fa-check"></i><b>27.4</b> Post-hoc analysis</a></li>
<li class="chapter" data-level="27.5" data-path="onewayRM.html"><a href="onewayRM.html#write-up-10"><i class="fa fa-check"></i><b>27.5</b> Write up</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="twowayCR.html"><a href="twowayCR.html"><i class="fa fa-check"></i><b>28</b> Two-way ANOVA Completely Randomized</a><ul>
<li class="chapter" data-level="28.1" data-path="twowayCR.html"><a href="twowayCR.html#effect-of-strain-and-diet-on-liver"><i class="fa fa-check"></i><b>28.1</b> Effect of Strain and Diet on Liver</a></li>
<li class="chapter" data-level="28.2" data-path="twowayCR.html"><a href="twowayCR.html#the-test"><i class="fa fa-check"></i><b>28.2</b> The test</a></li>
<li class="chapter" data-level="28.3" data-path="twowayCR.html"><a href="twowayCR.html#interpretation-of-2-way-cr-anova-output"><i class="fa fa-check"></i><b>28.3</b> Interpretation of 2 Way CR ANOVA Output</a><ul>
<li class="chapter" data-level="28.3.1" data-path="twowayCR.html"><a href="twowayCR.html#levenes"><i class="fa fa-check"></i><b>28.3.1</b> Levene’s</a></li>
<li class="chapter" data-level="28.3.2" data-path="twowayCR.html"><a href="twowayCR.html#anova-table"><i class="fa fa-check"></i><b>28.3.2</b> ANOVA Table</a></li>
</ul></li>
<li class="chapter" data-level="28.4" data-path="twowayCR.html"><a href="twowayCR.html#post-hoc-multiple-comparisons"><i class="fa fa-check"></i><b>28.4</b> Post Hoc Multiple Comparisons</a><ul>
<li class="chapter" data-level="28.4.1" data-path="twowayCR.html"><a href="twowayCR.html#write-up-11"><i class="fa fa-check"></i><b>28.4.1</b> Write Up</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path="twowayRM.html"><a href="twowayRM.html"><i class="fa fa-check"></i><b>29</b> Two-way ANOVA Related Measures</a><ul>
<li class="chapter" data-level="29.1" data-path="twowayRM.html"><a href="twowayRM.html#cell-culture"><i class="fa fa-check"></i><b>29.1</b> Cell culture</a></li>
<li class="chapter" data-level="29.2" data-path="twowayRM.html"><a href="twowayRM.html#the-test-1"><i class="fa fa-check"></i><b>29.2</b> The test</a></li>
<li class="chapter" data-level="29.3" data-path="twowayRM.html"><a href="twowayRM.html#interpretation-of-the-output"><i class="fa fa-check"></i><b>29.3</b> Interpretation of the output</a><ul>
<li class="chapter" data-level="29.3.1" data-path="twowayRM.html"><a href="twowayRM.html#anova-table-1"><i class="fa fa-check"></i><b>29.3.1</b> ANOVA Table</a></li>
<li class="chapter" data-level="29.3.2" data-path="twowayRM.html"><a href="twowayRM.html#mauchlys-sphericity-test"><i class="fa fa-check"></i><b>29.3.2</b> Mauchly’s Sphericity Test</a></li>
</ul></li>
<li class="chapter" data-level="29.4" data-path="twowayRM.html"><a href="twowayRM.html#post-hoc-multiple-comparisons-1"><i class="fa fa-check"></i><b>29.4</b> Post Hoc multiple comparisons</a></li>
<li class="chapter" data-level="29.5" data-path="twowayRM.html"><a href="twowayRM.html#write-up-12"><i class="fa fa-check"></i><b>29.5</b> Write Up</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="twowaymixed.html"><a href="twowaymixed.html"><i class="fa fa-check"></i><b>30</b> Two-way ANOVA RM/CR</a><ul>
<li class="chapter" data-level="30.1" data-path="twowaymixed.html"><a href="twowaymixed.html#chickweight-dataset"><i class="fa fa-check"></i><b>30.1</b> ChickWeight Dataset</a></li>
<li class="chapter" data-level="30.2" data-path="twowaymixed.html"><a href="twowaymixed.html#munge-chickweight-data"><i class="fa fa-check"></i><b>30.2</b> Munge ChickWeight data</a></li>
<li class="chapter" data-level="30.3" data-path="twowaymixed.html"><a href="twowaymixed.html#the-test-2"><i class="fa fa-check"></i><b>30.3</b> The test</a></li>
<li class="chapter" data-level="30.4" data-path="twowaymixed.html"><a href="twowaymixed.html#interpreting-the-anova-output"><i class="fa fa-check"></i><b>30.4</b> Interpreting the ANOVA output</a><ul>
<li class="chapter" data-level="30.4.1" data-path="twowaymixed.html"><a href="twowaymixed.html#anova-the-anova-table-1"><i class="fa fa-check"></i><b>30.4.1</b> $ANOVA: The ANOVA table</a></li>
<li class="chapter" data-level="30.4.2" data-path="twowaymixed.html"><a href="twowaymixed.html#mauchlys-test-and-corrections"><i class="fa fa-check"></i><b>30.4.2</b> Mauchly’s Test and Corrections</a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path="twowaymixed.html"><a href="twowaymixed.html#post-hoc-pairwise-tests"><i class="fa fa-check"></i><b>30.5</b> Post hoc pairwise tests</a><ul>
<li class="chapter" data-level="30.5.1" data-path="twowaymixed.html"><a href="twowaymixed.html#heres-whats-been-discovered"><i class="fa fa-check"></i><b>30.5.1</b> Here’s what’s been discovered</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="31" data-path="jaxwest2.html"><a href="jaxwest2.html"><i class="fa fa-check"></i><b>31</b> Reproducible Data Munging Mostly with Tidyverse</a><ul>
<li class="chapter" data-level="31.1" data-path="jaxwest2.html"><a href="jaxwest2.html#look-at-the-original-data-carefully"><i class="fa fa-check"></i><b>31.1</b> Look at the original data carefully</a></li>
<li class="chapter" data-level="31.2" data-path="jaxwest2.html"><a href="jaxwest2.html#our-goal"><i class="fa fa-check"></i><b>31.2</b> Our goal</a></li>
<li class="chapter" data-level="31.3" data-path="jaxwest2.html"><a href="jaxwest2.html#read-the-data-into-r"><i class="fa fa-check"></i><b>31.3</b> Read the data into R</a></li>
<li class="chapter" data-level="31.4" data-path="jaxwest2.html"><a href="jaxwest2.html#select-the-variables"><i class="fa fa-check"></i><b>31.4</b> Select the variables</a></li>
<li class="chapter" data-level="31.5" data-path="jaxwest2.html"><a href="jaxwest2.html#trim-the-cases"><i class="fa fa-check"></i><b>31.5</b> Trim the cases</a></li>
<li class="chapter" data-level="31.6" data-path="jaxwest2.html"><a href="jaxwest2.html#go-long"><i class="fa fa-check"></i><b>31.6</b> Go long</a></li>
<li class="chapter" data-level="31.7" data-path="jaxwest2.html"><a href="jaxwest2.html#pull-out-the-values-for-the-day-variable"><i class="fa fa-check"></i><b>31.7</b> Pull out the values for the day variable</a></li>
<li class="chapter" data-level="31.8" data-path="jaxwest2.html"><a href="jaxwest2.html#convert-day-to-numeric"><i class="fa fa-check"></i><b>31.8</b> Convert day to numeric</a></li>
<li class="chapter" data-level="31.9" data-path="jaxwest2.html"><a href="jaxwest2.html#convert-tumor_vol-to-numeric"><i class="fa fa-check"></i><b>31.9</b> Convert tumor_vol to numeric</a></li>
<li class="chapter" data-level="31.10" data-path="jaxwest2.html"><a href="jaxwest2.html#deal-with-that-na"><i class="fa fa-check"></i><b>31.10</b> Deal with that NA</a></li>
<li class="chapter" data-level="31.11" data-path="jaxwest2.html"><a href="jaxwest2.html#convert-variables-to-factor"><i class="fa fa-check"></i><b>31.11</b> Convert variables to factor</a></li>
<li class="chapter" data-level="31.12" data-path="jaxwest2.html"><a href="jaxwest2.html#plot-the-data"><i class="fa fa-check"></i><b>31.12</b> Plot the data</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="correl.html"><a href="correl.html"><i class="fa fa-check"></i><b>32</b> Correlation</a><ul>
<li class="chapter" data-level="32.1" data-path="correl.html"><a href="correl.html#correlation-causation"><i class="fa fa-check"></i><b>32.1</b> Correlation != Causation</a></li>
<li class="chapter" data-level="32.2" data-path="correl.html"><a href="correl.html#correlation-in-multivariate-outcomes-and-paired-designs"><i class="fa fa-check"></i><b>32.2</b> Correlation in Multivariate Outcomes and Paired Designs</a></li>
<li class="chapter" data-level="32.3" data-path="correl.html"><a href="correl.html#correlation-coefficients"><i class="fa fa-check"></i><b>32.3</b> Correlation coefficients</a><ul>
<li class="chapter" data-level="32.3.1" data-path="correl.html"><a href="correl.html#pearsons-correlation-coefficient"><i class="fa fa-check"></i><b>32.3.1</b> Pearson’s correlation coefficient</a></li>
<li class="chapter" data-level="32.3.2" data-path="correl.html"><a href="correl.html#spearmans-rank-correlation"><i class="fa fa-check"></i><b>32.3.2</b> Spearman’s rank correlation</a></li>
<li class="chapter" data-level="32.3.3" data-path="correl.html"><a href="correl.html#kendalls-tau"><i class="fa fa-check"></i><b>32.3.3</b> Kendall’s tau</a></li>
<li class="chapter" data-level="32.3.4" data-path="correl.html"><a href="correl.html#which-correlation-method-to-use"><i class="fa fa-check"></i><b>32.3.4</b> Which correlation method to use?</a></li>
<li class="chapter" data-level="32.3.5" data-path="correl.html"><a href="correl.html#r-correlation-analysis-functions"><i class="fa fa-check"></i><b>32.3.5</b> R correlation analysis functions</a></li>
<li class="chapter" data-level="32.3.6" data-path="correl.html"><a href="correl.html#plot-the-correlations"><i class="fa fa-check"></i><b>32.3.6</b> Plot the correlations</a></li>
<li class="chapter" data-level="32.3.7" data-path="correl.html"><a href="correl.html#calculate-a-correlation-coefficient-and-posthoc-test"><i class="fa fa-check"></i><b>32.3.7</b> Calculate a correlation coefficient and posthoc test</a></li>
<li class="chapter" data-level="32.3.8" data-path="correl.html"><a href="correl.html#interpretation-of-correlation-output"><i class="fa fa-check"></i><b>32.3.8</b> Interpretation of correlation output</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="33" data-path="regress.html"><a href="regress.html"><i class="fa fa-check"></i><b>33</b> Linear Regression</a><ul>
<li class="chapter" data-level="33.1" data-path="regress.html"><a href="regress.html#the-linear-regression-model"><i class="fa fa-check"></i><b>33.1</b> The linear regression model</a></li>
<li class="chapter" data-level="33.2" data-path="regress.html"><a href="regress.html#least-squares-fitting"><i class="fa fa-check"></i><b>33.2</b> Least squares fitting</a></li>
<li class="chapter" data-level="33.3" data-path="regress.html"><a href="regress.html#the-practical-importance-of-linear-model-parameters"><i class="fa fa-check"></i><b>33.3</b> The practical importance of linear model parameters</a></li>
<li class="chapter" data-level="33.4" data-path="regress.html"><a href="regress.html#linear-model-standard-errors"><i class="fa fa-check"></i><b>33.4</b> Linear model standard errors</a></li>
<li class="chapter" data-level="33.5" data-path="regress.html"><a href="regress.html#linear-regression-in-r"><i class="fa fa-check"></i><b>33.5</b> Linear regression in R</a></li>
<li class="chapter" data-level="33.6" data-path="regress.html"><a href="regress.html#intepretation-1"><i class="fa fa-check"></i><b>33.6</b> Intepretation</a><ul>
<li class="chapter" data-level="33.6.1" data-path="regress.html"><a href="regress.html#residuals"><i class="fa fa-check"></i><b>33.6.1</b> Residuals</a></li>
<li class="chapter" data-level="33.6.2" data-path="regress.html"><a href="regress.html#coefficients"><i class="fa fa-check"></i><b>33.6.2</b> Coefficients</a></li>
<li class="chapter" data-level="33.6.3" data-path="regress.html"><a href="regress.html#degrees-of-freedom-1"><i class="fa fa-check"></i><b>33.6.3</b> Degrees of freedom</a></li>
<li class="chapter" data-level="33.6.4" data-path="regress.html"><a href="regress.html#r-squared"><i class="fa fa-check"></i><b>33.6.4</b> R-squared</a></li>
<li class="chapter" data-level="33.6.5" data-path="regress.html"><a href="regress.html#f-statistic"><i class="fa fa-check"></i><b>33.6.5</b> F-statistic</a></li>
<li class="chapter" data-level="33.6.6" data-path="regress.html"><a href="regress.html#plotting-regression-results"><i class="fa fa-check"></i><b>33.6.6</b> Plotting regression results</a></li>
<li class="chapter" data-level="33.6.7" data-path="regress.html"><a href="regress.html#visualizing-residuals"><i class="fa fa-check"></i><b>33.6.7</b> Visualizing residuals</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">JABSTB: Statistical Design and Analysis of Experiments with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="nonparametrics" class="section level1">
<h1><span class="header-section-number">Chapter 17</span> Nonparametric Statistical Tests</h1>
<p>Non-parametric statistical tests are versatile with respect to the dependent variables they tolerate.</p>
<p>They are typically applied to data sets involving ordered data. One of the nonparametric tests, the sign test, is used to assess simple proportions. They can also be for data on measured, equal interval scales, for which the normality and equal variance assumptions of parametric statistical testing are not satisfied or cannot be assumed.</p>
<p>Nonparametric statistics are parameter-less. They don’t compare means, or medians. Though people frequently treat nonparametrics as tests of medians, that is not strictly true. They don’t involve least squares calculations, or standard deviations, or variance, or SEMs.</p>
<p>They do compare distributions of data. This happens by transforming the data into a standardized measure of ranks–either signs, sign ranks or rank sums.</p>
<p><strong>The tests, essentially, evaluate whether the distribution of ranks in an experimental outcome differs from a null distribution of ranks, given a sample size. That can seem pretty abstract. But it’s actually a simple and elegant way to think about these tests.</strong></p>
<p>With the exception of the Sign Test, which has a probability as an effect size, strictly speaking there really isn’t an effect size that describes non-parametric outcomes other than the value of the test statistic.</p>
<p>However, it is possible to use confidence interval arguments in R’s tests to coerce them into providing effect size output as estimates of medians. This can be sometimes useful.</p>
<p>Non-parametric analogs exist for each of the major parametric statistical tests (t-tests and one-way anova and two-way. Which analog to use for a given data set analysis depends entirely upon the experimental design.</p>
<ul>
<li>Sign Test -&gt; analog to the binomial Test -&gt; when events are categorized as either successes or failures.</li>
<li>Wilcoxon Sign Rank Test for one group -&gt; analog to the one sample t-test -&gt; compare a one group data set to a standard value.</li>
<li>Mann Whitney Rank Sum Test for 2 independent groups -&gt; analog to the unpaired t test -&gt; for comparing two groups in a data set.</li>
<li>Wilcoxon Sign Rank Test for paired groups -&gt; analog to the paired t-test -&gt; comparing a group of paired outcomes in a data set to no effect null.</li>
<li>Kruskal-Wallis Test -&gt; analog to one way completely randomized ANOVA -&gt; comparing 3 or more groups</li>
<li>Friedman Test -&gt; analog to one way related measures ANOVA -&gt; comparing 3 or more groups.</li>
</ul>
<p>In R, the <code>wilcox.test</code>function is a work horse for non-parametric analysis. By simply changing the function’s arguments it can do either a WSRT, or MW, or a WSRT for paired groups analysis.</p>
<div id="experiments-involving-discrete-data" class="section level2">
<h2><span class="header-section-number">17.1</span> Experiments involving discrete data</h2>
<p>Discrete data can be either sorted or ordered. Discrete data arises from counting objects or events. They also occur when the meaurements taken from the experimental units are assigned discrete values. Counted objects are easy to spot—they are indivisible. They belong in one bucket or some other bucket(s). Dependent variables that have discrete values are also easy to spot. On scatter plots they exist as discrete rows. There is no continuum of values between the rows.</p>
<p>When planning an experiment ask whether the data will be sorted into categories on the basis of nominal characteristics (eg, dead vs alive, in vs out).</p>
<p>Or will the data be categorized on some ordered basis. For example, a score of 1 = the attribute, a score of 2 = more of the attribute, a score of 3= even more of the attribute, …and so on.</p>
<p>The discrete counts within one category of an ordered scale mean that they have more or less of some feature than do the counts in another category in the ordered group.</p>
<p>Thus, compared to nominal data, ordered data have more information. Whereas nominal events are just sorted into one bucket or another, ordered events are inherently categorized by rank.</p>
<p>Ordered data are common in survey instruments and polling. Certain experimental designs generate inherently ordered data as well.</p>
<p>For example, imagine a test that scores dermal inflammatory responses.</p>
<p>Given a subject, * Score 1 if we don’t see any signs of inflammation. * Score 2 if there was a faint red spot. * Score 3 for a raised pustule. * Score 4 for a large swollen area that feels hot to the touch. * Score 5 for anything worse than that, if it is possible!</p>
<p>Using that ordered scale system, we’d run experiments, for example, to compare a steroid treatment that might reduce inflammation compared to a vehicle control. Or we’d look at a gene knockout, or CRISP-R fix, or whatever, and score an outcome response compared to a control group. After an evaluation by a trained observer, each experimental unit receives a score from the scale.</p>
<p>In quantifying effect sizes for such studies, a mistake you often see is parametric analysis. The researcher uses parameters such as means, standard deviations, performs t-tests, and so forth on the score rank values.</p>
<p>This isn’t always bad, but it assumes a couple of things. First, that the distribution of the data is approximately normal, as is the population that was sampled. Second, the scoring scale is equal interval. That is to say, “the difference between inflammation scores of 1 and 2 is the same as the difference between scores 2 and 3, and so on…”.</p>
<p>Suffice to say that researchers should validate whether these assumptions are true before resorting to parametric tests. Or they can just use nonparametric tests and save themselves from all that validation work!</p>
<p>It happens the other way, too. Sometimes we take measurements of some variable on a perfectly good measurement scale, one that satisfies these assumptions, but then break the data out to some ordered scale.</p>
<p>Take blood pressure, for example, which is a continuous variable, usually in standardized units of mmHg. We might measure it’s value for each subject, but on the basis of that measurement sort the subjects into ordered categories of low, medium and high. Our scientific expertise drives what blood pressure values match those categories. And we should have good reasons to resort to a categorization because doing so tends to throw away perfect good scalar information.</p>
<p>It is on this ordered scale, of discrete events, rather than the original measurements on a continuous scale, that we might then run statistical tests.</p>
<p>My point for this latter example is, of course, that not all ordered scales are based upon subjective assessments.</p>
</div>
<div id="deviant-data" class="section level2">
<h2><span class="header-section-number">17.2</span> Deviant Data</h2>
<p>Any scale, whether discrete or continuous, can yield deviant data. What I mean by deviant data is non-normal, skewed, has unequal variances among groups, has outliers, and is just plain ugly.</p>
<p>When data are deviant there are two options:</p>
<ol style="list-style-type: decimal">
<li>Use reciprocal or log transform functions to transform the data distribution into something more normal-like. Run the statistical tests intended for normal data on the transformed values.</li>
<li>Run non-parametric statistical tests on the raw, untransformed data. These tests transform the data into a rank-based distribution. These (the sign rank and the rank sum distributions), are discrete normal-like, and can be coerced to cough up p-values.</li>
<li>Tossing outliers is almost always a bad and unnecessary option. Outlier tossing introduces bias! Because they are based on ranks, the nonparametric tests condense outliers back with the rest of the variables, providing a very slick way to deal with deviant data.</li>
</ol>
</div>
<div id="sign-test" class="section level2">
<h2><span class="header-section-number">17.3</span> Sign Test</h2>
<p>The Sign Test is a non-parametric way of saying a binomial test.</p>
<p>An experiment is conducted on a group of subjects, who are graded in some way for either passing (+) or failing (- ) some test. Did a cell depolarize, or not? Is a stain in the cell nucleus, or not? Did the animal move fast enough, or not? Did the subject meet some other threshold you’ve established as a success, or not?</p>
<p>Simply count the number that passed. Given them a “+” sign. The number that failed receive a “-” sign. Using scientific judgement, assume a probability for the frequency of successes under the null hypothesis. For example, the null might be to expect 50% successes. If after analyzing the data the proportion of successes differs from this null proportion, you may have a winner!</p>
<p>Here’s an analysis of a behavioral test, the latency to exit a dark chamber into a brief field, as an index of anxiety. Let’s say that exiting a chamber in less than 60 seconds is a threshold for what we’d consider “non-anxious” behavior. Scientific judgement sets that threshold value. Fifteen subjects are given an anti-anxiety drug.</p>
<p>The null probability of exiting the chamber is 0.5. Which is to say there is a 50/50 chance a mouse will, at random, exit the chamber at any given time before or after 60 sec. Or put another way, under the null, neither exiting nor remaining in the chamber by 60 seconds is favored.</p>
<p>Let’s imagine we have an alarm set to go off 60 seconds after placing the subject in the chamber. When the alarm sounds, we score the subject as either (+) or (-).</p>
<p>The results are that twelve exited the chamber in less than 60 seconds, and 5 did not. We have not recorded times.</p>
<p>Scientifically, we predict that experimental units on an anti-anxiety drug are more likely to exit before this mark.</p>
<p>This experiment tests the null hypothesis that the probability of successes are less than or equal to 50%. If something is not less than or equal to another, it can only be greater. Thus, we choose the “greater” for the alternative hypothesis argument in the binomial test function. We think on an anti-anxiety drug the probability is greater that the subjects will successfully exit the chamber!</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">binom.test</span>(<span class="dt">x=</span><span class="dv">12</span>, <span class="dt">n=</span><span class="dv">15</span>, <span class="dt">p=</span><span class="fl">0.5</span>, <span class="dt">alternative =</span><span class="st">&quot;greater&quot;</span>, <span class="dt">conf.level=</span><span class="fl">0.95</span> )</code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  12 and 15
## number of successes = 12, number of trials = 15, p-value = 0.01758
## alternative hypothesis: true probability of success is greater than 0.5
## 95 percent confidence interval:
##  0.5602156 1.0000000
## sample estimates:
## probability of success 
##                    0.8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">scoreci</span>(<span class="dt">x=</span><span class="dv">12</span>, <span class="dt">n=</span><span class="dv">15</span>, <span class="dt">conf.level =</span> <span class="fl">0.95</span>)</code></pre></div>
<pre><code>## 
## 
## 
## data:  
## 
## 95 percent confidence interval:
##  0.5481 0.9295</code></pre>
<div id="interpretation-1" class="section level3">
<h3><span class="header-section-number">17.3.1</span> Interpretation</h3>
<p>The effect size is 0.8, which represents the fraction of subjects that left the chamber prior to the 60 second threshold we set. The p-value is the probability of observing an effect size this large, if the null hypothesis is actually true. There is a 95% chance the true effect size is within the range of 0.56 to 1.</p>
<p>To get a clear sense of what’s going on, here is the distribution of the binomial function for the null hypothesis.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># I&#39;ll use the rbinom function to simulate </span>
data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">15</span>),<span class="dt">y=</span><span class="kw">dbinom</span>(<span class="kw">c</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">15</span>), <span class="dv">15</span>, <span class="dt">prob=</span><span class="fl">0.5</span>))
<span class="kw">ggplot</span>(data, <span class="kw">aes</span>(x, y))<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">fill=</span><span class="st">&quot;blue&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">&quot;exits before 60s&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">&quot;prob of that many exits&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">x=</span><span class="dv">1</span>, <span class="dt">y=</span>.<span class="dv">20</span>, <span class="dt">label=</span><span class="st">&quot;H0 distribution&quot;</span>))</code></pre></div>
<p><img src="jabstb_files/figure-html/unnamed-chunk-140-1.png" width="672" /></p>
<p>And here is the distribution for the alternate hypothesis:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">15</span>),<span class="dt">y=</span><span class="kw">dbinom</span>(<span class="kw">c</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">15</span>), <span class="dv">15</span>, <span class="dt">prob=</span><span class="fl">0.8</span>))
<span class="kw">ggplot</span>(data, <span class="kw">aes</span>(x, y))<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">fill=</span><span class="st">&quot;green&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">&quot;exits before 60s&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">&quot;prob of that many exits&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">x=</span><span class="dv">1</span>, <span class="dt">y=</span>.<span class="dv">20</span>, <span class="dt">label=</span><span class="st">&quot;H1 distribution&quot;</span>))</code></pre></div>
<p><img src="jabstb_files/figure-html/unnamed-chunk-141-1.png" width="672" /></p>
<p>This is to emphasize that the binomial distribution is used here as a model of the experimental effect. Thus, we might also conclude that our data is consistent with a binomial distribution of 15 trials wherein the probability of event success is 80%.</p>
<p>In effect, our p-value allows us to conclude this alternate distribution is a better model for the population than is the null distribution. This is subject to a 1.758% chance that this might be a false positive conclusion. Use your scientific judgement to decide whether that’s an acceptable risk of being wrong.</p>
<p>This also is a way to visualize the confidence interval, which says we should expect more than 8 successes 95% of the time…an assertion that covers all but two of the lower bins in this distribution!</p>
</div>
<div id="write-up-5" class="section level3">
<h3><span class="header-section-number">17.3.2</span> Write Up</h3>
<p><em>Drug treatment increases fearlessness (one-sided binomial test, p = 0.01759). The fraction exiting the chamber (0.8) is greater than expected for the null of 0.5 (95% CI = 0.55 to 1.0, Wilson’s CI)</em></p>
</div>
</div>
<div id="wilcoxon-sign-rank-test-for-one-group" class="section level2">
<h2><span class="header-section-number">17.4</span> Wilcoxon Sign Rank Test for One Group</h2>
<p>The test statistic for the Wilcoxon Sign Rank is determined as follows. 1. Calculate the difference between the theoretical median or threshold value and the values recorded for each independent replicate. 2. Rank those differences from lowest (rank = 1) to highest (rank = n). 3. Assign a negative value to the replicate values that are less than the median. 4. The test statistic <code>V</code> is the sum of the positive values. (software other than <code>wilcox.test</code> in R may calculate W, the sum of the positive and negative values).</p>
<p>The test statistic V has an approximately normal discrete distribution, whose cumulative function <code>psignrank</code> can be used to compute p-values.</p>
<div id="wilcoxon-sign-rank-experimental-designs" class="section level3">
<h3><span class="header-section-number">17.4.1</span> Wilcoxon Sign Rank Experimental Designs</h3>
<p>This experimental design is similar to the Sign Rank test except in one important detail: <strong>We actually measure the time it takes for the subjects to exit the chamber.</strong> No alarm sounds to end the game at 60 sec. If subjects dawdle about and take longer than 60 sec to exit, we wait and record that time!</p>
<p>Thus, because the data set is comprised of the actual values for the latency variable, rather than counts of a simple (+) or (-) score, the Wilcoxon Sign Rank design collects more information than does the Sign Rank Test.</p>
<p>Let’s say we have a chamber test on 7 subjects who’ve all been given an anti-anxiety drug. After placement in the chamber, their exit times (in seconds) are 3, 5, 8, 15, 19, 21 and 108. Based upon scientific judgement, we think exiting sooner than 60 would represent fearlessness (less anxiety).</p>
<p>This test ranks each subject’s performance relative to that reference time and then “signs” it as negative or positive based on whether it’s original value was below or above the 60 second threshold. In our data, only one subject exceeded that value…108 sec.</p>
<p>Our prediction is that less anxious subjects should exit the comfort of the dark chamber sooner than would be expected. The null hypothesis is that the “location”&quot; of the null distribution is greater than or equal to 60 seconds. The alternate is the location is “less” than 60 seconds, since less is everything that greater than or equal to cannot be.</p>
<p>We run the Wilcoxon Sign Rank test to test this hypothesis using the arguments below.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">wilcox.test</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">8</span>,<span class="dv">15</span>,<span class="dv">19</span>,<span class="dv">21</span>,<span class="dv">108</span>), <span class="dt">mu=</span><span class="dv">60</span>, <span class="dt">alternative =</span> <span class="st">&quot;less&quot;</span>, <span class="dt">conf.level =</span> <span class="fl">0.95</span>, <span class="dt">conf.int =</span> <span class="fl">0.95</span>)</code></pre></div>
<pre><code>## 
##  Wilcoxon signed rank test
## 
## data:  c(3, 5, 8, 15, 19, 21, 108)
## V = 4, p-value = 0.05469
## alternative hypothesis: true location is less than 60
## 95 percent confidence interval:
##  -Inf 61.5
## sample estimates:
## (pseudo)median 
##             14</code></pre>
</div>
<div id="interpretation-2" class="section level3">
<h3><span class="header-section-number">17.4.2</span> Interpretation</h3>
<p>The value of the test statistic, V is four. How extreme is that? It is pretty far to the left on the test statistic distribution (see below) for this sample size. The p-value is above the threshold of 5%. The evidence is not enough to reject the null hypothesis. Otherwise, the probability of making an error doing so would be 0.05469.</p>
<p>That V = 4 means it is the value corresponding to the sum of the positively signed ranks in the sample. The pseudo-median of the latency time is 14 seconds. The one-sided 95% confidence ranges from -infinity to 61.5.</p>
<p>Here’s a null signrank distribution for a sample size of 7. The values of the x scale are V, the test statistic. These are all the possible values that V can take on, given the sample size. For example, if all the signed ranks were positive…if every subject took longer than 60 sec to exit)…then V would equal 28. If all subjects exited before 60 sec, then V would equal zero.</p>
<p>Which is to say the location of this distribution is, by coincidence, also centered on 14. The value of 4 is less than this location, but not extremely-enough lower to be considered as belonging to some other distribution with a different location! The 95% confidence interval of the location on the V test statistic ranges from -infinity to 62.5.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">psignrank</span>(<span class="dt">q=</span><span class="dv">4</span>, <span class="dt">n=</span><span class="dv">7</span>)</code></pre></div>
<pre><code>## [1] 0.0546875</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">psignrank</span>(<span class="dt">q=</span><span class="dv">1</span>, <span class="dt">n=</span><span class="dv">7</span>)</code></pre></div>
<pre><code>## [1] 0.015625</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">upper &lt;-<span class="st"> </span><span class="dv">28</span>
n &lt;-<span class="st"> </span><span class="dv">7</span>
df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x=</span><span class="dv">0</span><span class="op">:</span>upper, <span class="dt">y=</span><span class="kw">dsignrank</span>(<span class="dv">0</span><span class="op">:</span>upper, n))
<span class="kw">ggplot</span>(df, (<span class="kw">aes</span>(x,y)))<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_col</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;V&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span>(<span class="kw">seq</span>(<span class="dv">0</span>,upper,<span class="dv">1</span>)))</code></pre></div>
<p><img src="jabstb_files/figure-html/unnamed-chunk-144-1.png" width="672" /></p>
</div>
<div id="write-up-6" class="section level3">
<h3><span class="header-section-number">17.4.3</span> Write Up</h3>
<p><em>Analysis of the chamber test results indicates the anti-anxiety drug has no effect (Wilcoxon Signed Rank test, V = 4, n = 7, p= 0.0547)</em></p>
</div>
</div>
<div id="wilcoxon-mann-whitney-rank-sum-test-for-2-independent-groups" class="section level2">
<h2><span class="header-section-number">17.5</span> Wilcoxon Mann Whitney Rank Sum Test for 2 independent groups</h2>
<p>This nonparametric test, often referred to simply as the Mann-Whitney test, is analogous to the parametric unpaired t-test.</p>
<p>It is for comparing two groups that receive either of 2 levels of a predictor variable. For example, in an experiment where one group of <code>m</code> independent replicates is exposed to some control or null condition, while a second group with <code>n</code> independent replicates is exposed to some treatment. More generally, the two groups represent two levels of a predictor variable given to <code>m+n</code>independent replicates.</p>
<p>The rank sum is calculated as follows:</p>
<ol style="list-style-type: decimal">
<li>The data are collected from any scale, combined into a single list, whose values are ranked from lowest (rank 1) to highest (rank <code>m+n</code>), irrespective of the level of the predictor variable.</li>
<li>Let <span class="math inline">\(R_1\)</span> represent the sum of the ranks for the one level of the predictor variable (eg, group2).</li>
<li>Let <span class="math inline">\(U_1\)</span> represent the number of times a data value from group2 is less than a data point from group1.</li>
<li><span class="math inline">\(U_1=m*n+\frac{m(m+1)}{2}-R_1\)</span></li>
<li>And <span class="math inline">\(U_2=m*n-U_1\)</span></li>
</ol>
<p>The rank sum test computes two test statistics, <span class="math inline">\(U_1\)</span> and <span class="math inline">\(U_2\)</span> that are complementary to each other.</p>
<p>Here’s another in the line of the mighty mouse experiments.</p>
<p>55 independent subjects were split into two groups. One group received an anti-anxiety drug and the second a vehicle as control. The subjects were run through the dark chamber test. The scientific prediction is the drug will reduce anxiety levels and so the drug treated mice will exit the chamber more quickly compared to the control mice.</p>
<p>Since this is a parameter-less test, the null hypothesis is that location of the distribution of the drug-treated population is greater than or equal to the location of the vehicle distribution. The alternative hypothesis is that the location of the distribution of the drug-treated population is less than that of the vehicle distribution. The alternative is consistent with our scientific prediction and represents an outcome that is exclusive and comprehensive of the null!</p>
<p>We choose the “less” option for the alternative argument in the test.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mightymouse &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;datasets/mightymouse.csv&quot;</span>)
<span class="kw">wilcox.test</span>(Time <span class="op">~</span><span class="st"> </span>Group, <span class="dt">data =</span> mightymouse, <span class="dt">alternative =</span><span class="st">&quot;less&quot;</span>, <span class="dt">conf.level=</span><span class="fl">0.95</span>, <span class="dt">conf.int=</span>T)</code></pre></div>
<pre><code>## 
##  Wilcoxon rank sum test
## 
## data:  Time by Group
## W = 55, p-value = 0.1804
## alternative hypothesis: true location shift is less than 0
## 95 percent confidence interval:
##  -Inf    6
## sample estimates:
## difference in location 
##                   -9.8</code></pre>
<div id="interpretation-3" class="section level3">
<h3><span class="header-section-number">17.5.1</span> Interpretation</h3>
<p>The test statistic you see in the output, W, warrants some discussion. W is equal to <span class="math inline">\(U_2\)</span> as defined above.</p>
<p>By default, R produces <span class="math inline">\(U_2\)</span> (labeled W!) as the test statistic. Most other software packages use <span class="math inline">\(U_1\)</span>, which in this case would be 88 (easy to compute in the console given <span class="math inline">\(U_2\)</span>).</p>
<p>Think of W as a value on the x axis of a rank sum distribution for a sample size of <code>m+n</code>. The rank sum distribution has a function in R called <code>dwilcox</code>. Here it is (note the large value this distribution can take on is <code>m*n</code> and the smallest is zero):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x=</span><span class="dv">0</span><span class="op">:</span><span class="dv">143</span>, <span class="dt">y=</span><span class="kw">dwilcox</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">143</span>, <span class="dv">11</span>, <span class="dv">13</span>))
<span class="kw">ggplot</span>(df, (<span class="kw">aes</span>(x,y)))<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_col</span>()<span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;W&quot;</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span><span class="kw">c</span>(<span class="dv">55</span>, <span class="dv">88</span>))</code></pre></div>
<p><img src="jabstb_files/figure-html/unnamed-chunk-146-1.png" width="672" /></p>
<p>All this can seem confusing, but it is very elegant. First, the rank sums of samples, like the rank signs of samples, take on symmetrical, normal-like distributions. The greater the sample sizes, the more normal-like they become.</p>
<p>Second, the bottom line is the same as for all other statistical tests: test statistic values at either extreme of these null distributions are associated with large effect sizes.</p>
<p>The non-extreme-ness of the test statistic value for our sample is illustrated in that plot. Clearly, W=55, it is well within the null distribution. I calculated it’s symmetrical counterpart, <span class="math inline">\(U_1\)</span> = 88, from the relationship above. As you can see, the value of the test statistic and 88 frame the central location of this null ranksum distribution null quite nicely:</p>
<p>The p-value for W=55 indicates that the probability of creating a false positive by rejecting the null is 18.04%, well above the 5% type1 error threshold. So we should not reject the null given we’d have a 1 in 5 chance of being wrong if we did!</p>
<p>The “effect size” is in the output is the magnitude of the difference between the location parameters (pseudo-medians) of the two groups, on the scale of the original data.</p>
<p>The 95% confidence interval indicates there is a 95% chance the difference in locations is between negative infinity and 6. Since the 95% confidence interval includes zero, the possibility exists that there is zero difference between the two locations. That provides additional statistical reasoning not to reject the null.</p>
</div>
<div id="write-up-7" class="section level3">
<h3><span class="header-section-number">17.5.2</span> Write Up</h3>
<p><em>There is no difference in performance using the closed chamber test between subjects randomized to anti-anxiety drug (n=11) or to vehicle (n=13) (Mann-Whitney test, W = 55, p = 0.1804).</em></p>
</div>
</div>
<div id="wilcoxon-sign-rank-test-for-paired-groups" class="section level2">
<h2><span class="header-section-number">17.6</span> Wilcoxon Sign Rank Test for paired groups</h2>
<p>The classic paired experimental design happens when two measurements are taken from a single independent subject.</p>
<p>For example, we take a mouse, give it a sham treatment, and measure it’s latency in the chamber test. Later on we take the same mouse, give it an anti-anxiety drug treatment, and then measure its latency once again.</p>
<p>This kind of design can control for confounding factors, like inter-subject variability. But it can also introduce other confounds. For example, what if the mouse “remembers” that there is no real risk of leaving the dark chamber?</p>
<p>Pairing can happen in many other ways. A classic pairing paradigm is the use of identical twins. Individuals of inbred mouse strains are all immortal clones. Two litter mates would be identical twins and would also be, essentially, clones of their parents and their brothers and sisters from prior litters! Two dishes of cultured cells, passed together and now side-by-side on a bench are intrinsically-linked. All of these can be treated, statistically, as pairs.</p>
<p>In this example, we take a pair of mice from each of 6 independent litters produced by mating two heterozygotes of a nogo receptor knockout. One of the pair is nogo(-/-). The other is nogo(+/+). We think the nogo receptor causes the animals to be fearful, and predict animals in which the receptor is knocked out will be more fearless.</p>
<p>The independent experimental unit in this design is a pair. We have six pairs, Therefore, the sample size is 6 (even though 12 animals will be used!)</p>
<p>We’ll measure latency in the dark chamber test. Our random variable will be the difference in latency time between the knockout and the wild type, for each pair.</p>
<p>Here’s the data, latency times are in sec units:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mmko &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">knockout=</span><span class="kw">c</span>(<span class="dv">19</span>, <span class="dv">24</span>, <span class="dv">4</span>, <span class="dv">22</span>, <span class="dv">15</span>, <span class="dv">18</span>), <span class="dt">wildtype=</span><span class="kw">c</span>(<span class="dv">99</span>, <span class="dv">81</span>, <span class="dv">70</span>, <span class="dv">62</span>, <span class="dv">120</span>, <span class="dv">55</span>))
<span class="co">#create a long data fram to do formula arguments in wilcox test</span>
mmkotidy &lt;-<span class="st"> </span><span class="kw">gather</span>(mmko, genotype, latency )</code></pre></div>
<p>Scientifically, we predict there will be a difference in latency times within the pairs. Specifically, the knockout will have lower times than their paired wild-type. The null hypothesis is that the difference within pairs will be greater than or equal to zero. The alternative hypothesis is the difference will be less than zero.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">wilcox.test</span>(latency <span class="op">~</span><span class="st"> </span>genotype, <span class="dt">data=</span>mmkotidy, <span class="dt">paired=</span>T, <span class="dt">conf.level=</span><span class="fl">0.95</span>, <span class="dt">conf.int=</span>T, <span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>)</code></pre></div>
<pre><code>## 
##  Wilcoxon signed rank test
## 
## data:  latency by genotype
## V = 0, p-value = 0.01563
## alternative hypothesis: true location shift is less than 0
## 95 percent confidence interval:
##  -Inf  -40
## sample estimates:
## (pseudo)median 
##          -61.5</code></pre>
<div id="interpretation-4" class="section level3">
<h3><span class="header-section-number">17.6.1</span> Interpretation</h3>
<p>Note that this is not a rank sum test as for the Mann-Whitney, but a signed rank test.</p>
<p>So we have seen the V test statistic before. It’s value of 0 is as extreme as can be had on the null distribution, as is evident in the distribution below! That happened because in each of the six pairs, the knockout had a lower latency time than its paired wildtype. All of the signed ranks were negative!</p>
<p>In terms of position differences, it is as strong of an effect size as possible.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">upper &lt;-<span class="st"> </span><span class="dv">21</span>
n &lt;-<span class="st"> </span><span class="dv">6</span>
df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x=</span><span class="dv">0</span><span class="op">:</span>upper, <span class="dt">y=</span><span class="kw">dsignrank</span>(<span class="dv">0</span><span class="op">:</span>upper, n))
<span class="kw">ggplot</span>(df, (<span class="kw">aes</span>(x,y)))<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_col</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;V&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span>(<span class="kw">seq</span>(<span class="dv">0</span>,upper,<span class="dv">1</span>)))</code></pre></div>
<p><img src="jabstb_files/figure-html/unnamed-chunk-149-1.png" width="672" /></p>
<p>The p-value is exact…and it can never be lower, given this sample size. We can reject the null since it is below our 5% threshold and it says the probably that we are accepting a type1 error is 1.563%.</p>
<p>The pseudo-median is in units of latency time. It represents the median for the differences in latency within the pairs. In other words, there are six values of differences, one difference value for each pair. -61.5 is the median of those 6 differences.</p>
<p>There is a 95% chance the true median of the differences lies between negative infinity and -40. Note that the 95% CI does not include the value of zero.</p>
</div>
<div id="write-up-8" class="section level3">
<h3><span class="header-section-number">17.6.2</span> Write up</h3>
<p><em>Dark chamber test latency differs markedly within pairs of knockout and wildtype subjects (Wilcoxon Signed Rank Test for pairs, n=6, V = 0, p=0.01563)</em></p>
</div>
</div>
<div id="kruskal-wallis" class="section level2">
<h2><span class="header-section-number">17.7</span> Kruskal-Wallis</h2>
<p>The <code>kruskal.test</code> is a non-parametric method for comparing 3 or more treatment groups. It serves as an omnibus test for the null hypothesis that each of the treatment groups belong to the same population. If the null is rejected, post hoc comparison tests are then used to determine which groups differ from each other.</p>
<p>A post hoc test for this purpose in base R is <code>pairwise.wilcox.test</code>. The <code>PMCMRplus</code> package has others. Documentation within the <code>PMCMR</code>package vignette provides excellent background and instructions for these tests.</p>
<p>The Kruskal-Wallis test statistic is computed as follows. Values of the outcome variables across the groups are first converted into ranks, from high to low. Tied values are rank-averaged. The test can be corrected for large numbers of tied values.</p>
<p>The Kruskal-Wallis rank sum test statistic is:</p>
<p><span class="math display">\[H=\frac{12}{n(n+1)}\sum_{i=1}^k\frac{R_{i}^2}{n_i}-3(n+1)\]</span></p>
<p><span class="math inline">\(n\)</span> is the total sample size, <span class="math inline">\(k\)</span> is the number of treatment groups, <span class="math inline">\(n_i\)</span> is the sample size in the <span class="math inline">\(ith\)</span> group and <span class="math inline">\(R_i^2\)</span> is the squared rank sum of the <span class="math inline">\(ith\)</span> group. Under the null, <span class="math inline">\(\bar{R_i} = (n+1)/2\)</span>.</p>
<p>The <code>H</code> statistic is approximated using the <span class="math inline">\(\chi^2\)</span> distribution with <span class="math inline">\(k-1\)</span> degrees of freedom to produce p-values.</p>
<p>Let’s analyze the InsectSprays data set, it comes with the <code>PMCMRplus</code> package. This is a multifactorial experiment in which insects were counted in agricultural field plots that had been sprayed with 1 of 6 different insecticides. Each row in the data set represents an independent field plot.</p>
<p>Do the insecticides differ?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(InsectSprays, <span class="kw">aes</span>(spray, count))<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_violin</span>()</code></pre></div>
<p><img src="jabstb_files/figure-html/unnamed-chunk-150-1.png" width="672" /></p>
<p>The violin plots (modern day versions of box plots) illustrate how the groups have unequal variance. Such data are appropriate for non-parametric analysis.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#insectsprays &lt;- read.csv(&quot;insectsprays.csv&quot;)</span>
<span class="kw">kruskal.test</span>(count <span class="op">~</span><span class="st"> </span>spray, <span class="dt">data=</span>InsectSprays)</code></pre></div>
<pre><code>## 
##  Kruskal-Wallis rank sum test
## 
## data:  count by spray
## Kruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(insectsprays)
<span class="kw">pairwise.wilcox.test</span>(InsectSprays<span class="op">$</span>count, InsectSprays<span class="op">$</span>spray, <span class="dt">p.adjust.method=</span><span class="st">&quot;bonferroni&quot;</span>, <span class="dt">alternative =</span><span class="st">&quot;two.sided&quot;</span>)</code></pre></div>
<pre><code>## 
##  Pairwise comparisons using Wilcoxon rank sum test 
## 
## data:  InsectSprays$count and InsectSprays$spray 
## 
##   A       B       C       D       E      
## B 1.00000 -       -       -       -      
## C 0.00058 0.00058 -       -       -      
## D 0.00117 0.00104 0.03977 -       -      
## E 0.00051 0.00051 0.78860 1.00000 -      
## F 1.00000 1.00000 0.00052 0.00105 0.00052
## 
## P value adjustment method: bonferroni</code></pre>
<p>We first do a Kruskal-Wallis rank sum omnibus test to test the null hypothesis that the locations of the groups within the data set are the same.</p>
<p>The null is rejected given the large <span class="math inline">\(\chi^2\)</span> test statistic, which has a p-value well below the threshold.</p>
<p>That’s followed by a pairwise Wilcoxon rank sum test…think of it as running a Mann-Whitney test on all possible pairs in the group. The number of pairwise tests for 6 groups is <code>choose(6, 2)</code>= 15.</p>
<p>Each pairwise test is a single hypothesis test associated with 5% type1 error risk. If we don’t make a correction for doing the multiple comparisons, the family-wise type1 error would inflate to <span class="math inline">\(15 x 5% = 75%\)</span>!</p>
<p>The Bonferroni adjustment is the most conservative and simple to understand. It multiples every unadjusted p-value by 15, the number of comparisons made. Thus, each of the p-values in the grid is 15X larger than had the adjustment not been made.</p>
<p>Every p-value less than 0.05 in the grid is therefore cause for rejecting the null hypothesis that the pair does not differ. The highest among these is the comparisons between sprays C and D, which has a p-value of 0.03977.</p>
<p>More generally, the Bonferroni correction is <span class="math inline">\(adjusted\ type1\ threshold = 0.05/C\)</span> where C is the number of comparisons to make.</p>
<div id="write-up-9" class="section level3">
<h3><span class="header-section-number">17.7.1</span> Write Up</h3>
<p><em>A non-parametric omnibus test establishes that the locations of the insecticide effects of the six sprays differ (Kruskal-Wallis, <span class="math inline">\(\Chi^2\)</span> = 54.69, df=5, p=1.511e-10). Posthoc pairwise multiple comparisons by the Mann-Whitney test (Bonferroni adjusted p-values) indicate the following sprays differ from each other: A v(0.00058), D(0.00117), E(0.0051), …and so on</em></p>
</div>
</div>
<div id="friedman-test" class="section level2">
<h2><span class="header-section-number">17.8</span> Friedman test</h2>
</div>
<div id="nonparametric-power-calculations" class="section level2">
<h2><span class="header-section-number">17.9</span> Nonparametric power calculations</h2>
<p>To my knowledge, there are no simple power functions in R designed for nonparametric testing. I assume the reason for that is that nonparametric tests can be performed on a wide variety of data types. As such, it’s hard to create one-size-fits all, plug and play functions.</p>
<p>The function below, <code>nonpara.pwr</code> is configured to simulate the power of nonparametric one- and two-group comparisons using the Wilcoxon test function of R.</p>
<p>The intended use of this function is to establish <em>a priori</em> the sample size needed to yield a level of power that you deem acceptable.</p>
<p>What the function does is simulate a long run of experimental results at a given sample size, from which it calculates the power. This is a Monte Carlo method. Thus, it simulate random values that mimic experimental results based upon “known” population parameters.</p>
<p>The function strictly takes the argument of a sample size value and returns an experimental power that sample size generates.</p>
<p>But it also requires that you customize your initialization. Do this by entering estimates for parameters of the population you expect to sample. All you need to do this is a pretty good guess of the values for the outcome variable you expect your experiment will produce.</p>
<div id="how-it-works" class="section level3">
<h3><span class="header-section-number">17.9.1</span> How it works</h3>
<p>Use the initializer to define values for the parameters of the population you’re sampling. These are passed into a function that randomly generate values for the outcome variable. A statistical test is performed on that outcome. A secondary ‘hit’ test asks whether the test result crosses a threshold. Here a ‘hit’ is counted if the p-value for the simulated test is less than 0.05.</p>
<p>Power is the franction of p-values that fall below the confidence level that you set. For example, if you set a confidence level of 95%, every p-value less than 0.05 will be scored as a hit. Power = hits/number of simulations.</p>
<p>The function is configured to repeat this simulation/testing/hit count process many times, hundreds or even thousands of times. The more times it simulates a result, the more accurate the power estimate.</p>
</div>
<div id="initialization-with-population-parameters" class="section level3">
<h3><span class="header-section-number">17.9.2</span> Initialization with population parameters</h3>
<p>Let’s focus for now on the thought process involved in how to intialize it.</p>
<p>What’s most important is to initialize the function using a random value generator that best simulates the type of data you expect to generate in your experiment. Using the random number generator functions of the various probability distributions is suitable for many cases.</p>
<p>For example, use <code>rnorm</code> for measured variables for which you believe you can predict means and standard deviations.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># simulate a sample size of 5 for a normally-distributed variable with mean of 100 units and standard deviation of 25 units</span>
control.<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">5</span>, <span class="dt">mean=</span><span class="dv">100</span>, <span class="dt">sd=</span><span class="dv">25</span>)
treatment.<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">5</span>, <span class="dt">mean=</span><span class="dv">150</span>, <span class="dt">sd=</span><span class="dv">25</span>)
sim.set &lt;-<span class="st"> </span><span class="kw">data.frame</span>(control.<span class="dv">1</span>, treatment.<span class="dv">1</span>); sim.set</code></pre></div>
<pre><code>##   control.1 treatment.1
## 1 123.78070    144.2373
## 2  54.59601    144.8087
## 3  88.29962    178.2538
## 4  97.86539    165.6107
## 5 109.42299    141.8250</code></pre>
<p>Use <code>rpois</code> to simulate variables that represent discrete events, such as frequencies.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#simulate 5 events, where each occurs at an average frequency of 7.</span>

control.<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">rpois</span>(<span class="dt">n=</span><span class="dv">5</span>, <span class="dt">lambda=</span><span class="dv">7</span>)
treatment.<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">rpois</span>(<span class="dt">n=</span><span class="dv">5</span>, <span class="dt">lambda=</span><span class="dv">10</span>)
sim.set2 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(control.<span class="dv">2</span>, treatment.<span class="dv">2</span>); sim.set2</code></pre></div>
<pre><code>##   control.2 treatment.2
## 1         7          11
## 2         8           9
## 3         9          10
## 4         8          12
## 5         3           9</code></pre>
<p>It’s even possible to simulate ordinal data, such as the outcome of likert tests. The <code>sample()</code> function can be configured for this purpose. Note how probability vector argument is used to cast expectd distributions of the values</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#simulate 6 replicates scored on a 5-unit ordinal scale, where 1 is the lowest level of an observed outcome and 5 is the highest.</span>

control &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>), <span class="dt">size=</span><span class="dv">6</span>, 
       <span class="dt">replace=</span>T, <span class="dt">prob=</span><span class="kw">c</span>(.<span class="dv">80</span>, .<span class="dv">15</span>, .<span class="dv">05</span>, <span class="dv">0</span>, <span class="dv">0</span>))
disease &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>), <span class="dt">size=</span><span class="dv">6</span>, 
       <span class="dt">replace=</span>T, <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="fl">0.05</span>, <span class="fl">0.80</span>, <span class="fl">0.15</span>))
results &lt;-<span class="st"> </span><span class="kw">data.frame</span>(control, disease); results</code></pre></div>
<pre><code>##   control disease
## 1       2       5
## 2       1       4
## 3       1       4
## 4       1       4
## 5       1       4
## 6       1       4</code></pre>
<p>If a more sophisticated/less-biased simulation of ordinal data is needed, you’ll find it is <a href="https://www.rdatagen.net/post/generating-and-displaying-likert-type-data/">doable but suprisingly not trivial</a>.</p>
<p>Please recognize that simulating data for these functions mostly depends upon your scientific understanding of the variables. You have to make scientific judgements about the values your variable will take on under control and treatment conditions.</p>
<p>To get started statistically, go back to the basics. Is the variable discrete or continuous. Is it measured or ordered or sorted? What means and standard deviations, or frequencies, or rank sizes should you estimate? Those are scientific judgements.</p>
<p>Either select the values you predict will occur, OR enter values that you believe would be a minimal, scientifically meaningful effect size.</p>
</div>
<div id="an-example" class="section level3">
<h3><span class="header-section-number">17.9.3</span> An example</h3>
<p>Let’s say we study mouse models of diabetes. In non-diabetic control subjects, mean plasma glucose concentration is typically ~100 mg/dL and the variability tends to be quite low (15 mg/dL).</p>
<p>Most everybody in the field agrees that average blood glucose concentration of 300 mg/dL represents successful induction of diabetes in these models.</p>
<p>However, experience shows these higher levels of glucose are associated with considerably greater variability (sd=150 mg/dL) than under normal states. Large differences in variability between two groups are called heteroscedaticity. The presence of heteroscedaticity can preclude the use of parametric statistical tests since it raises type1 error risk. Thus, nonparametric testing would be used when expected such outcomes.</p>
<p>Let’s say you want to test a new idea for diabetes induction. What sample size would be necessary, assuming an nonparametric testing and an unpaired design, to reliably detect a difference between these two groups at 80% power or better?</p>
<p>The function below calculates the power of experiments that might be expected to generate such results, at given sample sizes.</p>
</div>
<div id="nonpara.pwr" class="section level3">
<h3><span class="header-section-number">17.9.4</span> nonpara.pwr</h3>
<p>Running this first code chunk reads the function into the environment. There’s no output, yet. But read it line-by-line to see if you can follow the logic.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nonpara.pwr &lt;-<span class="st"> </span><span class="cf">function</span>(n){
  
<span class="co">#Intitializers. Place expected values for the means and standard deviations of two groups to be compared here.</span>
  
  m1=<span class="st"> </span><span class="dv">100</span> <span class="co">#mean of group 1</span>
  sd1=<span class="st"> </span><span class="dv">10</span> <span class="co">#standard deviation of group 1</span>
  
  m2=<span class="st"> </span><span class="dv">300</span> <span class="co">#mean of group 2</span>
  sd2=<span class="st"> </span><span class="dv">150</span> <span class="co">#standard deviation of group 2</span>
  
  
  <span class="co"># the monte carlo just repeats the random sampling i times. It runs a t-test on each sample, i, grabs the p-value and places it in a growing vector, p.values[i]</span>
  ssims=<span class="dv">1000</span>
  
  <span class="co">#The function below produced p-values. This empty vector will be filled with p-values as they are generated</span>
  
  p.values &lt;-<span class="st"> </span><span class="kw">c</span>()
  
  <span class="co">#This function inside a function repeats the simulation ssims times, collecting a p-value each time. Importantly, change the arguments for the statitical test to suit your experimental design. It </span>
  i &lt;-<span class="st"> </span><span class="dv">1</span>
  <span class="cf">repeat</span>{
    x=<span class="kw">rnorm</span>(n, m1, sd1); 
    y=<span class="kw">rnorm</span>(n, m2, sd2);
    p &lt;-<span class="st"> </span><span class="kw">wilcox.test</span>(x, y, 
                <span class="dt">paired=</span>F, 
                <span class="dt">alternative=</span><span class="st">&quot;two.sided&quot;</span>, 
                <span class="dt">var.equal=</span>F,
                <span class="dt">conf.level=</span><span class="fl">0.95</span>)<span class="op">$</span>p.value
    p.values[i] &lt;-<span class="st"> </span>p
    
    <span class="cf">if</span> (i<span class="op">==</span>ssims) <span class="cf">break</span>
    i =<span class="st"> </span>i<span class="op">+</span><span class="dv">1</span>
    <span class="co">#This calculates the power from the values in the p.value vector.</span>
    pwr &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">which</span>(p.values<span class="op">&lt;</span><span class="fl">0.05</span>))<span class="op">/</span>ssims
  }
  <span class="kw">return</span>(pwr)
  
}</code></pre></div>
<p>To get some output, pass a sample size of 5 per group into the function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="kw">nonpara.pwr</span>(<span class="dv">5</span>)</code></pre></div>
<pre><code>## [1] 0.626</code></pre>
<p>At this seed, the power is 62.6% for a sample size of 5 per group.</p>
<p>A slightly higher power would be desirable. Change the value of <code>n</code> in the code chunk to see what’s necessary to get 80% power.</p>
<p>Or, more easily, just run <code>nonpara.pwr</code> over a range of sample sizes, plotting a power vs sample size curve:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#frame is a data frame with only one variable, sample size</span>
frame &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">n=</span><span class="dv">2</span><span class="op">:</span><span class="dv">50</span>)
<span class="co">#data is a data frame with two variables, sample size and a power value for each</span>
data &lt;-<span class="st"> </span><span class="kw">bind_cols</span>(frame, 
                  <span class="dt">power=</span><span class="kw">apply</span>(frame, <span class="dv">1</span>, nonpara.pwr))

<span class="co">#plot</span>
<span class="kw">ggplot</span>(data, <span class="kw">aes</span>(n, power))<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks=</span><span class="kw">c</span>(<span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.1</span>)))<span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span><span class="kw">c</span>(<span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">50</span>,<span class="dv">2</span>)))</code></pre></div>
<p><img src="jabstb_files/figure-html/unnamed-chunk-157-1.png" width="672" /></p>
<p>This result shows that a sample size of 7, 8, or 9 per group would give ~85% power. Thus, a sample size of 7 per group would be the minimal size necessary to test the two-sided null that there is no difference between the groups, at a 95% confidence level.</p>
<p>The experimental design, and thus these scripts, can be reconfigured in many ways.</p>
</div>
</div>
<div id="summary" class="section level2">
<h2><span class="header-section-number">17.10</span> Summary</h2>
<p>If you’re used to comparing means of groups, nonparametrics can be somewhat disorienting. There are no parameters to compare! And the concept of location shifts or differences seems rather abstract.</p>
<p>The tests transform the values of experimental outcome variables into either sign rank or into rank sum units. That abstraction can be disorientating, too. But it is important to recognize that sign ranks and rank sum distributions are approximately normal.</p>
<p>Therefore, perhaps its best to think of nonparametrics as a way to transform non-normal data into more normal data.</p>
<p>The nonparametrics are powerful statistical tests that should be used more widely than they are.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chisquare.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="signrank.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["jabstb.pdf", "jabstb.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
